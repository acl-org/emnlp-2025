---
title: Panel
layout: single
excerpt: "EMNLP 2025 Conference Overview"
permalink: /program/panel/
toc: true
toc_sticky: true
toc_icon: "cog" 
sidebar: 
    nav: program
---

## Advancing our Reach: Do's, Don'ts and Lessons learned in Interdisciplinary Research

Large Language Models are a knowledge resource, but not a panacea. This panel brings disciplinary and interdisciplinary voices together to take a reflective look at the best work of this community represented at the 2025 conference and raise challenges to step forward in directions that strengthen our impact both within our community and more universally.

## Date
Thursday, November 6th, 15:00-16:00, Located in B301

## Panelists

### Heng Ji
![Heng Ji](/assets/images/keynotes/hengji.png){: .align-center .speaker-photo}

**Bio**: Heng Ji is a Professor of Computer Science at Siebel School of Computing and Data Science, and a faculty member affiliated with Electrical and Computer Engineering Department, Coordinated Science Laboratory, and Carl R. Woese Institute for Genomic Biology of University of Illinois Urbana-Champaign. She is an Amazon Scholar. She is the Founding Director of Amazon-Illinois Center on AI for Interactive Conversational Experiences (AICE), and the Founding Director of CapitalOne-Illinois Center on AI Safety and Knowledge Systems (ASKS). She received Ph.D. in Computer Science from New York University. Her research interests focus on Natural Language Processing, especially on Multimedia Multilingual Information Extraction, Knowledge-enhanced Large Language Models and Vision-Language Models, AI for Science, and Science-inspired AI. The awards she received include Outstanding Paper Award at ACL2024, two Outstanding Paper Awards at NAACL2024, "Young Scientist" by the World Laureates Association in 2023 and 2024, "Young Scientist" and a member of the Global Future Council on the Future of Computing by the World Economic Forum in 2016 and 2017, "Women Leaders of Conversational AI" (Class of 2023) by Project Voice, "AI's 10 to Watch" Award by IEEE Intelligent Systems in 2013, NSF CAREER award in 2009, PACLIC2012 Best paper runner-up, "Best of ICDM2013" paper award, "Best of SDM2013" paper award, ACL2018 Best Demo paper nomination, ACL2020 Best Demo Paper Award, NAACL2021 Best Demo Paper Award, Google Research Award in 2009 and 2014, IBM Watson Faculty Award in 2012 and 2014 and Bosch Research Award in 2014-2018. She has coordinated the NIST TAC Knowledge Base Population task 2010-2020. She served as the associate editor for IEEE/ACM Transaction on Audio, Speech, and Language Processing, and the Program Committee Co-Chair of many conferences including NAACL-HLT2018 and AACL-IJCNLP2022. She was elected as the North American Chapter of the Association for Computational Linguistics (NAACL) secretary 2020-2023.

### Jana Diesner
![Jana Diesner](/assets/images/keynotes/jana.png){: .align-center .speaker-photo}

**Bio**: Jana Diesner is a Full Professor at the Technical University of Munich, School of Social Science and Technology, with a joint appointment at the School of Computation, Information and Technology. She leads the Human-Centered Computing group. Her group works on methods from network science, natural language processing, machine learning, and AI, and integrates them with theories from the social sciences and humanities to advance our understanding of theories and patterns of complex societal systems. Their work also considers cultural contexts and ethical concerns to advance responsibility in computational sciences. Before joining TUM in 2024, Jana was a tenured professor at the University of Illinois Urbana Champaign. School of Information Sciences. She earned her Ph.D. at Carnegie Mellon, School of Computer Science.


### Hannaneh Hajishirzi
![Hannaneh Hajishirzi](/assets/images/keynotes/hanna.png){: .align-center .speaker-photo}

**Bio**: [Hanna Hajishirzi](https://hannaneh.ai/) is a Professor of Computer Science at the University of Washington and a Senior Director of AI at AI2. Her research spans generative AI and natural language processing, with a focus on building pioneering, open-science AI solutions. She co-leads the OLMo and Tulu projects, advancing fully open language and reasoning models to accelerate the science of AI, empower the research community, and champion openness as a driver of innovation. These models have been downloaded more than 10 million times as of 2025 and were recognized with GeekWire's Innovation of the Year award. She is a co-PI of a $152M NSF- and NVIDIA-supported grant to develop the next generation of open multimodal models. 
She is a recipient of the Sloan Fellowship (2021), the Uncommon Thinker Award (2025), the NSF CAREER Award (2021), Torode family Career development professorship (2022), the Allen Distinguished Investigator Award (2014), the UIUC Alumni Award (2024), and was a finalist for the VentureBeat Women in AI Award (2024, 2025). Her research has earned recognition at leading venues, with papers receiving or being finalists for awards at ACL 2025, CVPR 2025, ACL 2024 (Best Paper and Best Resource Paper), CVPR 2022, AKBC 2020, and SIGDIAL 2012.


### Iryna Gurevych
![Iryna Gurevych](https://raw.githubusercontent.com/acl-org/emnlp-2025/main/assets/images/keynotes/gurevych.png){: .align-center .speaker-photo}

**Bio**: Iryna Gurevych is a Professor at the Technical University of Darmstadt in Germany, with appointments at MBZUAI and INSAIT.  Her recent research emphasizes real world impact in Language Understanding, AI Safety, and Expert-AI Cooperation.  She served as President of ACL in 2023 and has been a fellow of the ACL since 2020.  She is also an ELLIS Fellow, the first ATHENE Distinguished Professor of Cybersecurity and holds a LOEWE Chair of Excellence.

---

### Junyang Lin
![Junyang Lin](https://raw.githubusercontent.com/acl-org/emnlp-2025/main/assets/images/keynotes/junyang.png){: .align-center .speaker-photo}

**Bio**: Junyang Lin is the Tech Lead of the Qwen Team at Alibaba Group.  His research focuses on Large foundation models, generative models, coding models, and reasoning.  . He is responsible for building Qwen, the large language model and multimodal model series.  He is also in charge of the opensource version of the models.  Previously, he did research in large scale pretraining and multimodal pretraining and led the development of OFA, Chinese-CLIP, M6, etc.

## Moderator
Carolyn Rose Carnegie Mellon University (CMU)
