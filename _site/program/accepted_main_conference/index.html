<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Main Conference - EMNLP 2025</title>
<meta name="description" content="The Accepted Main Conference Papers of EMNLP 2024">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="EMNLP 2025">
<meta property="og:title" content="Main Conference">
<meta property="og:url" content="http://0.0.0.0:4000/program/accepted_main_conference/">


  <meta property="og:description" content="The Accepted Main Conference Papers of EMNLP 2024">





  <meta name="twitter:site" content="@emnlpmeeting">
  <meta name="twitter:title" content="Main Conference">
  <meta name="twitter:description" content="The Accepted Main Conference Papers of EMNLP 2024">
  <meta name="twitter:url" content="http://0.0.0.0:4000/program/accepted_main_conference/">

  
    <meta name="twitter:card" content="summary">
    
  

  







  

  


<link rel="canonical" href="http://0.0.0.0:4000/program/accepted_main_conference/">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "emnlp",
      "url": "http://0.0.0.0:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="_pages/home.md" type="application/atom+xml" rel="alternate" title="EMNLP 2025 Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="57x57" href="/assets/images/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/images/apple-touch-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/images/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/images/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/images/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/images/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/images/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/images/apple-touch-icon-152x152.png">
<link rel="icon" type="image/png" href="/assets/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/assets/images/favicon-16x16.png" sizes="16x16">
<link rel="mask-icon" href="/assets/images/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#2b5797">
<meta name="msapplication-TileImage" content="/assets/images/mstile-144x144.png">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    
<style type="text/css">
.tmp-disable{
color:#CCCCCC
}
</style>

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logos/emnlp_2025_logo_v0.1.png" alt=""></a>
        
        <a class="site-title" href="/">          </a>
        <ul class="visible-links"></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <ul class="nav__items">
    
  </ul>
</nav>
    
  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Main Conference">
    <meta itemprop="description" content="The Accepted Main Conference Papers of EMNLP 2024">
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Main Conference
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-cog"></i> On this page</h4></header>
              
            </nav>
          </aside>
        
        <p><strong>UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation</strong><br />Juhwan Choi, Yeonghwa Kim, Seunguk Yu, JungMin Yun, YoungBin Kim</p>

<p><strong>Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation</strong><br />Juhwan Choi, JungMin Yun, Kyohoon Jin, YoungBin Kim</p>

<p><strong>FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document</strong><br />Joonho Yang, Seunghyun Yoon, ByeongJeong Kim, Hwanhee Lee</p>

<p><strong>Prompts have evil twins</strong><br />Rimon Melamed, Lucas Hurley McCabe, Tanay Wakhare, Yejin Kim, H. Howie Huang, Enric Boix-Adserà</p>

<p><strong>Table Question Answering for Low-resourced Indic Languages</strong><br />Vaishali Pal, Evangelos Kanoulas, Andrew Yates, Maarten de Rijke</p>

<p><strong>ImageInWords: Unlocking Hyper-Detailed Image Descriptions</strong><br />Roopal Garg, Andrea Burns, Burcu Karagol Ayan, Yonatan Bitton, Ceslee Montgomery, Yasumasa Onoe, Andrew Bunner, Ranjay Krishna, Jason Michael Baldridge, Radu Soricut</p>

<p><strong>LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay</strong><br />Yihuai Lan, Zhiqiang Hu, Lei Wang, Yang Wang, Deheng Ye, Peilin Zhao, Ee-Peng Lim, Hui Xiong, Hao Wang</p>

<p><strong>When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection</strong><br />Xiangyu Zhang, Hexin Liu, Kaishuai Xu, Qiquan Zhang, Daijiao Liu, Beena Ahmed, Julien Epps</p>

<p><strong>Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model</strong><br />Xiangyu Zhang, Daijiao Liu, Hexin Liu, Qiquan Zhang, Hanyu Meng, Leibny Paola Garcia Perera, EngSiong Chng, Lina Yao</p>

<p><strong>Hateful Word in Context Classification</strong><br />Sanne Hoeken, Sina Zarrieß, Özge Alacam</p>

<p><strong>Eyes Don’t Lie: Subjective Hate Annotation and Detection with Gaze</strong><br />Özge Alacam, Sanne Hoeken, Sina Zarrieß</p>

<p><strong>NumeroLogic: Number Encoding for Enhanced LLMs’ Numerical Reasoning</strong><br />Eli Schwartz, Leshem Choshen, Joseph Shtok, Sivan Doveh, Leonid Karlinsky, Assaf Arbelle</p>

<p><strong>Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models</strong><br />Shaz Furniturewala, Surgan Jandial, Abhinav Java, Pragyan Banerjee, Simra Shahid, Sumit Bhatia, Kokil Jaidka</p>

<p><strong>A Usage-centric Take on Intent Understanding in E-Commerce</strong><br />Wendi Zhou, Tianyi Li, Pavlos Vougiouklis, Mark Steedman, Jeff Z. Pan</p>

<p><strong>Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs</strong><br />Oded Ovadia, Menachem Brief, Moshik Mishaeli, Oren Elisha</p>

<p><strong>Systematic Biases in LLM Simulations of Debates</strong><br />Amir Taubenfeld, Yaniv Dover, Roi Reichart, Ariel Goldstein</p>

<p><strong>Studying and Mitigating Biases in Sign Language Understanding Models</strong><br />Katherine Atwell, Danielle Bragg, Malihe Alikhani</p>

<p><strong>Uncertainty in Language Models: Assessment through Rank-Calibration</strong><br />Xinmeng Huang, Shuo Li, Mengxin Yu, Matteo Sesia, Hamed Hassani, Insup Lee, Osbert Bastani, Edgar Dobriban</p>

<p><strong>RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning</strong><br />Junjie Ye, Yilong Wu, Songyang Gao, Caishuang Huang, Sixian Li, Guanyu Li, Xiaoran Fan, Qi Zhang, Tao Gui, Xuanjing Huang</p>

<p><strong>Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing</strong><br />Fangkai Jiao, Chengwei Qin, Zhengyuan Liu, Nancy F. Chen, Shafiq Joty</p>

<p><strong>Scaling Properties of Speech Language Models</strong><br />Santiago Cuervo, Ricard Marxer</p>

<p><strong>“We Demand Justice!”: Towards Social Context Grounding of Political Texts</strong><br />Rajkumar Pujari, Chengfei Wu, Dan Goldwasser</p>

<p><strong>An Experimental Analysis on Evaluating Patent Citations</strong><br />Rabindra Nath Nandi, Suman Maity, Brian Uzzi, Sourav Medya</p>

<p><strong>Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?</strong><br />Dawei Zhu, Pinzhen Chen, Miaoran Zhang, Barry Haddow, Xiaoyu Shen, Dietrich Klakow</p>

<p><strong>Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing</strong><br />Le Yan, Zhen Qin, Honglei Zhuang, Rolf Jagerman, Xuanhui Wang, Michael Bendersky, Harrie Oosterhuis</p>

<p><strong>Strength Lies in Differences! Towards Effective Non-collaborative Dialogues via Tailored Strategy Planning</strong><br />Tong Zhang, Chen Huang, Yang Deng, Hongru Liang, Jia Liu, zujie wen, Wenqiang Lei, Tat-Seng Chua</p>

<p><strong>Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation</strong><br />Saiful Islam Salim, Rubin Yuchan Yang, Alexander Cooper, Suryashree Ray, Saumya Debray, Sazzadur Rahaman</p>

<p><strong>Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation</strong><br />Yuan Ge, Yilun Liu, Chi Hu, Weibin Meng, shimin tao, Xiaofeng Zhao, Mahongxia, Zhang Li, Boxing Chen, Hao Yang, Bei Li, Tong Xiao, JingBo Zhu</p>

<p><strong>On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models</strong><br />Abhilasha Sancheti, Haozhe An, Rachel Rudinger</p>

<p><strong>EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models</strong><br />Maureen de Seyssel, Antony D’Avirro, Adina Williams, Emmanuel Dupoux</p>

<p><strong>On Fake News Detection with LLM Enhanced Semantics Mining</strong><br />Xiaoxiao Ma, Yuchen Zhang, Kaize Ding, Jian Yang, Jia Wu, Hao Fan</p>

<p><strong>On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices</strong><br />Branislav Pecher, Ivan Srba, Maria Bielikova</p>

<p><strong>Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection</strong><br />Zekun Li, Baolin Peng, Pengcheng He, Xifeng Yan</p>

<p><strong>A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers</strong><br />Valentin Barriere, Sebastian Cifuentes</p>

<p><strong>Mitigating the Alignment Tax of RLHF</strong><br />Yong Lin, Hangyu Lin, Wei Xiong, Shizhe Diao, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, Hanning Zhang, Hanze Dong, Renjie Pi, Han Zhao, Nan Jiang, Heng Ji, Yuan Yao, Tong Zhang</p>

<p><strong>Evaluating Readability and Faithfulness of Concept-based Explanations</strong><br />Meng Li, Haoran Jin, Ruixuan HUANG, Zhihao Xu, Defu Lian, Zijia Lin, Di ZHANG, Xiting Wang</p>

<p><strong>Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems</strong><br />Zhengyuan Liu, Stella Xin Yin, Geyu Lin, Nancy F. Chen</p>

<p><strong>MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making</strong><br />Dayuan Fu, Biqing Qi, Yihuai Gao, Che Jiang, Guanting Dong, Bowen Zhou</p>

<p><strong>CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds</strong><br />Min-Hsuan Yeh, Ruyuan Wan, Ting-Hao Kenneth Huang</p>

<p><strong>Tokenization Is More Than Compression</strong><br />Craig W Schmidt, Varshini Reddy, Haoran Zhang, Alec Alameddine, Omri Uzan, Yuval Pinter, Chris Tanner</p>

<p><strong>FLIRT: Feedback Loop In-context Red Teaming</strong><br />Ninareh Mehrabi, Palash Goyal, Christophe Dupuy, Qian Hu, Shalini Ghosh, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta</p>

<p><strong>Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections</strong><br />Lingjun Zhao, Khanh Xuan Nguyen, Hal Daumé III</p>

<p><strong>Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks</strong><br />Haoyuan WU, Haisheng Zheng, Zhuolun He, Bei Yu</p>

<p><strong>GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation</strong><br />Shihao Cai, Keqin Bao, Hangyu Guo, Jizhi Zhang, Jun Song, Bo Zheng</p>

<p><strong>Improved Learned Sparse Retrieval with Entity Vocabulary</strong><br />Thong Nguyen, Shubham Chatterjee, Sean MacAvaney, Iain Mackie, Jeff Dalton, Andrew Yates</p>

<p><strong>Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models</strong><br />Zihan Wang, Deli Chen, Damai Dai, Runxin Xu, Zhuoshu Li, Yu Wu</p>

<p><strong>LongEmbed: Extending Embedding Models for Long Context Retrieval</strong><br />Dawei Zhu, Liang Wang, Nan Yang, Yifan Song, Wenhao Wu, Furu Wei, Sujian Li</p>

<p><strong>Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences</strong><br />Xiangyang Liu, Junliang He, Xipeng Qiu</p>

<p><strong>Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue</strong><br />Xianlong Luo, Yihao Wang, Meng Yang</p>

<p><strong>Integrating Plutchik’s Theory with Mixture of Experts for Enhancing Emotion Classification</strong><br />Dongjun LIM, Yun-Gyung Cheong</p>

<p><strong>In-context Contrastive Learning for Event Causality Identification</strong><br />梁超, Wei Xiang, Bang Wang</p>

<p><strong>What’s Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs</strong><br />Anna Wegmann, Tijs A. van den Broek, Dong Nguyen</p>

<p><strong>Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs</strong><br />Kanishka Misra, Kyle Mahowald</p>

<p><strong>Large Language Models for Data Annotation: A Survey</strong><br />Zhen Tan, Dawei Li, Song Wang, Alimohammad Beigi, Bohan Jiang, Amrita Bhattacharjee, Mansooreh Karami, Jundong Li, Lu Cheng, huan liu</p>

<p><strong>Chain-of-Dictionary Prompting Elicits Translation in Large Language Models</strong><br />Hongyuan Lu, HAORAN YANG, Haoyang Huang, Dongdong Zhang, Wai Lam, Furu Wei</p>

<p><strong>AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning</strong><br />Yifan Yang, Kai Zhen, Ershad Banijamali, Athanasios Mouchtaris, Zheng Zhang</p>

<p><strong>RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning</strong><br />Haoyu Wang, Tianci Liu, Ruirui Li, Monica Xiao Cheng, Tuo Zhao, Jing Gao</p>

<p><strong>BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering</strong><br />Haoyu Wang, Ruirui Li, Haoming Jiang, Jinjin Tian, Zhengyang Wang, chen luo, Xianfeng Tang, Monica Xiao Cheng, Tuo Zhao, Jing Gao</p>

<p><strong>HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs</strong><br />Jocelyn J Shen, Joel Mire, Hae Won Park, Cynthia Breazeal, Maarten Sap</p>

<p><strong>Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence</strong><br />Junru Lu, Jiazheng Li, Siyu An, Meng Zhao, Yulan He, di yin, Xing Sun</p>

<p><strong>Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval</strong><br />Tianyi Hu, Maria Maistro, Daniel Hershcovich</p>

<p><strong>RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models</strong><br />Peng Xia, Kangyu Zhu, Haoran Li, Hongtu Zhu, Yun Li, Gang Li, Linjun Zhang, Huaxiu Yao</p>

<p><strong>A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading</strong><br />Yuan Li, Bingqiao Luo, Qian Wang, Nuo Chen, Xu Liu, Bingsheng He</p>

<p><strong>A Survey on In-context Learning</strong><br />Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu, Baobao Chang, Xu Sun, Lei Li, Zhifang Sui</p>

<p><strong>DocHieNet: A Large and Diverse Dataset for Document Hierarchy Parsing</strong><br />Hangdi Xing, Changxu Cheng, Feiyu Gao, Zirui Shao, Zhi Yu, Jiajun Bu, Qi Zheng, Cong Yao</p>

<p><strong>AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation</strong><br />Ziyang Luo, Xin Li, Hongzhan Lin, Jing Ma, Lidong Bing</p>

<p><strong>EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models</strong><br />Shangyu Xing, Fei Zhao, Zhen Wu, Tuo An, Weihao Chen, Chunhui Li, Jianbing Zhang, Xinyu Dai</p>

<p><strong>Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization</strong><br />Sungbin Shin, Wonpyo Park, Jaeho Lee, Namhoon Lee</p>

<p><strong>LLMs Are Zero-Shot Context-Aware Simultaneous Translators</strong><br />Roman Koshkin, Katsuhito Sudoh, Satoshi Nakamura</p>

<p><strong>AgentReview: Exploring Peer Review Dynamics with LLM Agents</strong><br />Yiqiao Jin, Qinlin Zhao, Yiyang Wang, Hao Chen, Kaijie Zhu, Yijia Xiao, Jindong Wang</p>

<p><strong>ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval</strong><br />Kelong Mao, Chenlong Deng, Haonan Chen, Fengran Mo, Zheng Liu, Tetsuya Sakai, Zhicheng Dou</p>

<p><strong>Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments</strong><br />Han Zhou, Xingchen Wan, Yinhong Liu, Nigel Collier, Ivan Vulić, Anna Korhonen</p>

<p><strong>Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation</strong><br />Chenlong Deng, Kelong Mao, Zhicheng Dou</p>

<p><strong>Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process</strong><br />Peng Wang, Xiaobin Wang, Chao Lou, Shengyu Mao, Pengjun Xie, Yong Jiang</p>

<p><strong>Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation</strong><br />Yuhui Zhang, Brandon McKinzie, Zhe Gan, Vaishaal Shankar, Alexander T Toshev</p>

<p><strong>QUDSELECT: Selective Decoding for Questions Under Discussion Parsing</strong><br />Ashima Suvarna, Xiao Liu, Tanmay Parekh, Kai-Wei Chang, Nanyun Peng</p>

<p><strong>Mitigating Language Bias of LMMs in Social Intelligence Understanding with Virtual Counterfactual Calibration</strong><br />Peng Chen, Xiao-Yu Guo, Yuan-Fang Li, Xiaowang Zhang, Zhiyong Feng</p>

<p><strong>Model Balancing Helps Low-data Training and Fine-tuning</strong><br />Zihang Liu, Yuanzhe Hu, Tianyu Pang, Yefan Zhou, Pu Ren, Yaoqing Yang</p>

<p><strong>Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment</strong><br />Zhaofeng Wu, Ananth Balashankar, Yoon Kim, Jacob Eisenstein, Ahmad Beirami</p>

<p><strong>Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment</strong><br />Kun Luo, Minghao Qin, Zheng Liu, Shitao Xiao, Jun Zhao, Kang Liu</p>

<p><strong>A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning</strong><br />Zhongwu Chen, Long Bai, Zixuan Li, Zhen Huang, Xiaolong Jin, Yong Dou</p>

<p><strong>Towards Tool Use Alignment of Large Language Models</strong><br />Zhi-Yuan Chen, Shiqi Shen, Guangyao Shen, Gong Zhi, Xu Chen, Yankai Lin</p>

<p><strong>DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models</strong><br />Ranchi Zhao, Zhen Leng Thai, Yifan Zhang, Shengding Hu, Jie Zhou, Yunqi Ba, Jie Cai, Zhiyuan Liu, Maosong Sun</p>

<p><strong>Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps</strong><br />Yung-Sung Chuang, Linlu Qiu, Cheng-Yu Hsieh, Ranjay Krishna, Yoon Kim, James R. Glass</p>

<p><strong>Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment</strong><br />Yiju Guo, Ganqu Cui, Lifan Yuan, Ning Ding, Zexu Sun, Bowen Sun, Huimin Chen, Ruobing Xie, Jie Zhou, Yankai Lin, Zhiyuan Liu, Maosong Sun</p>

<p><strong>Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation</strong><br />Yongsen Zheng, Ruilin Xu, Guohua Wang, Liang Lin</p>

<p><strong>Advancing Event Causality Identification via Heuristic Semantic Dependency Inquiry Network</strong><br />Haoran Li, Qiang Gao, Hongmei Wu, Li Huang</p>

<p><strong>Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors</strong><br />Wenjian Ding, YAO ZHANG, Jun Wang, Adam Jatowt, Zhenglu Yang</p>

<p><strong>UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation</strong><br />Xiangyu Zhao, Yuehan Zhang, zhangwenlong, Xiao-Ming Wu</p>

<p><strong>Tracking the perspectives of interacting language models</strong><br />Hayden Helm, Brandon Duderstadt, Youngser Park, Carey Priebe</p>

<p><strong>MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering</strong><br />Zhengxuan Zhang, Yin WU, Yuyu Luo, Nan Tang</p>

<p><strong>Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?</strong><br />Zhe Yang, Yichang Zhang, Tianyu Liu, Jian Yang, Junyang Lin, Chang Zhou, Zhifang Sui</p>

<p><strong>Watch Every Step! LLM Agent Learning via Iterative Step-level Process Refinement</strong><br />Weimin Xiong, Yifan Song, Xiutian Zhao, Wenhao Wu, Xun Wang, Ke Wang, Cheng LI, Wei Peng, Sujian Li</p>

<p><strong>Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation</strong><br />Joseph Marvin Imperial, Gail Forey, Harish Tayyar Madabushi</p>

<p><strong>Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective</strong><br />Zhihao Zhang, Sophia Yat Mei Lee, Junshuang Wu, Dong Zhang, Shoushan Li, Erik Cambria, Guodong Zhou</p>

<p><strong>“Glue pizza and eat rocks” - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models</strong><br />Zhen Tan, Chengshuai Zhao, Raha Moraffah, Yifan Li, Song Wang, Jundong Li, Tianlong Chen, huan liu</p>

<p><strong>Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement</strong><br />Yuxuan Wang, Xiaoyuan Liu</p>

<p><strong>SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation</strong><br />Xiaoze Liu, Ting Sun, Tianyang Xu, Feijie Wu, Cunxiang Wang, Xiaoqian Wang, Jing Gao</p>

<p><strong>MatchTime: Towards Automatic Soccer Game Commentary Generation</strong><br />Jiayuan Rao, Haoning Wu, Chang Liu, Yanfeng Wang, Weidi Xie</p>

<p><strong>Rethinking Token Reduction for State Space Models</strong><br />Zheng Zhan, Yushu Wu, Zhenglun Kong, Changdi Yang, Yifan Gong, Xuan Shen, Xue Lin, Pu Zhao, Yanzhi Wang</p>

<p><strong>Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering</strong><br />Chang Zong, Yuchen Yan, Weiming Lu, Jian Shao, Yongfeng Huang, Heng Chang, Yueting Zhuang</p>

<p><strong>MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic</strong><br />Yuyan Zhou, Liang Song, Bingning Wang, weipeng chen</p>

<p><strong>Event Causality Identification with Synthetic Control</strong><br />Haoyu Wang, Fengze Liu, Jiayao Zhang, Dan Roth, Kyle Richardson</p>

<p><strong>Retrieved Sequence Augmentation for Protein Representation Learning</strong><br />Chang Ma, Haiteng Zhao, Lin Zheng, Jiayi Xin, Qintong Li, Lijun Wu, Zhihong Deng, Yang Young Lu, Qi Liu, Sheng Wang, Lingpeng Kong</p>

<p><strong>HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding</strong><br />Fan Yuan, Chi Qin, Xiaogang Xu, Piji Li</p>

<p><strong>TopViewRS: Vision-Language Models as Top-View Spatial Reasoners</strong><br />Chengzu Li, Caiqi Zhang, Han Zhou, Nigel Collier, Anna Korhonen, Ivan Vulić</p>

<p><strong>DA$^3$: A Distribution-Aware Adversarial Attack against Language Models</strong><br />Yibo Wang, Xiangjue Dong, James Caverlee, Philip S. Yu</p>

<p><strong>Evaluating Psychological Safety of Large Language Models</strong><br />Xingxuan Li, Yutong Li, Lin Qiu, Shafiq Joty, Lidong Bing</p>

<p><strong>An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification</strong><br />Zhuowei Chen, Lianxi Wang, Yuben Wu, Xinfeng Liao, Yujia Tian, Junyang Zhong</p>

<p><strong>Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering</strong><br />Dongze Hao, Qunbo Wang, Longteng Guo, Jie Jiang, Jing Liu</p>

<p><strong>PsFuture: A Pseudo-Future-based Zero-Shot Adaptive Policy for Simultaneous Machine Translation</strong><br />Libo Zhao, Jing Li, Ziqian Zeng</p>

<p><strong>TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging</strong><br />Liang Zhang, Anwen Hu, Haiyang Xu, Ming Yan, Yichen Xu, Qin Jin, Ji Zhang, Fei Huang</p>

<p><strong>Do We Need Language-Specific Fact-Checking Models? The Case of Chinese</strong><br />Caiqi Zhang, Zhijiang Guo, Andreas Vlachos</p>

<p><strong>Enhancing Advanced Visual Reasoning Ability of Large Language Models</strong><br />Zhiyuan Li, Dongnan Liu, Chaoyi Zhang, Heng Wang, Tengfei Xue, Weidong Cai</p>

<p><strong>CMD: a framework for Context-aware Model self-Detoxification</strong><br />Zecheng Tang, Keyan Zhou, Juntao Li, Yuyang Ding, Pinzheng Wang, Yan Bowen, Renjie Hua, Min Zhang</p>

<p><strong>Embedding and Gradient Say Wrong: A White-Box Method for Hallucination Detection</strong><br />Xiaomeng Hu, Yiming Zhang, Ru Peng, Haozhe Zhang, Chenwei Wu, Gang Chen, Junbo Zhao</p>

<p><strong>TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control</strong><br />Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao</p>

<p><strong>Be Helpful but Don’t Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support</strong><br />LI Junlin, Bo Peng, Yu-Yin Hsu, Chu-Ren Huang</p>

<p><strong>Aligning Language Models to Explicitly Handle Ambiguity</strong><br />Hyuhng Joon Kim, Youna Kim, Cheonbok Park, Junyeob Kim, Choonghyun Park, Kang Min Yoo, Sang-goo Lee, Taeuk Kim</p>

<p><strong>Tag-grounded Visual Instruction Tuning with Retrieval Augmentation</strong><br />Daiqing Qi, Handong Zhao, Zijun Wei, Sheng Li</p>

<p><strong>GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models</strong><br />Xuanchang Zhang, Zhuosheng Zhang, hai zhao</p>

<p><strong>Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information</strong><br />Runze Xia, Congchi Yin, Piji Li</p>

<p><strong>Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models</strong><br />Rui Li, Qi Liu, Liyang He, Zheng Zhang, Hao Zhang, Shengyu Ye, Junyu Lu, Zhenya Huang</p>

<p><strong>Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models</strong><br />Yongjin Yang, Jongwoo Ko, Se-Young Yun</p>

<p><strong>Advancing Process Verification for Large Language Models via Tree-Based Preference Learning</strong><br />Mingqian He, Yongliang Shen, Wenqi Zhang, Zeqi Tan, Weiming Lu</p>

<p><strong>An Inversion Attack Against Obfuscated Embedding Matrix in Language Model Inference</strong><br />Yu Lin, Qizhi Zhang, Quanwei Cai, Jue Hong, Wu Ye, Huiqi Liu, Bing Duan</p>

<p><strong>MantisScore: A Reliable Fine-grained Metric for Video Generation</strong><br />Xuan He, Dongfu Jiang, Ge Zhang, Max Ku, Achint Soni, Sherman Siu, Haonan Chen, Abhranil Chandra, Ziyan Jiang, Aaran Arulraj, Kai Wang, Quy Duc Do, Yuansheng Ni, Bohan Lyu, Yaswanth Narsupalli, Rongqi Fan, Zhiheng Lyu, Bill Yuchen Lin, Wenhu Chen</p>

<p><strong>A ∧ B ⇔ B ∧ A: Evaluating and Improving Logical Reasoning Ability of Large Language Models</strong><br />Yuxuan WAN, Wenxuan Wang, Yiliu Yang, Youliang Yuan, Jen-tse Huang, Pinjia He, Wenxiang Jiao, Michael Lyu</p>

<p><strong>Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training</strong><br />Xiaoyang Yi, Yuru Bao, Jian Zhang, Yifang Qin, Faxin Lin</p>

<p><strong>FuseGen: PLM Fusion for Data-generation based Zero-shot Learning</strong><br />Tianyuan Zou, Yang Liu, Peng Li, Jianqing Zhang, Jingjing Liu, Ya-Qin Zhang</p>

<p><strong>I Need Help! Evaluating LLM’s Ability to Ask for Users’ Support: A Case Study on Text-to-SQL Generation</strong><br />Cheng-Kuang Wu, Zhi Rui Tam, Chao-Chung Wu, Chieh-Yen Lin, Hung-yi Lee, Yun-Nung Chen</p>

<p><strong>Oddballs and Misfits: Detecting Implicit Abuse in Which Identity Groups are Depicted as Deviating from the Norm</strong><br />Michael Wiegand, Josef Ruppenhofer</p>

<p><strong>By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting</strong><br />Hyungjun Yoon, Biniyam Aschalew Tolera, Taesik Gong, Kimin Lee, Sung-Ju Lee</p>

<p><strong>Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization</strong><br />Seungwoo Son, Wonpyo Park, Woohyun Han, Kyuyeun Kim, Jaeho Lee</p>

<p><strong>CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search</strong><br />Fengran Mo, Abbas Ghaddar, Kelong Mao, Mehdi Rezagholizadeh, Boxing Chen, Qun Liu, Jian-Yun Nie</p>

<p><strong>Towards Low-Resource Harmful Meme Detection with LMM Agents</strong><br />Jianzhao Huang, Hongzhan Lin, ZiyanLiu, Ziyang Luo, Guang Chen, Jing Ma</p>

<p><strong>VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values</strong><br />Zhe Hu, Yixiao Ren, Jing Li, Yu Yin</p>

<p><strong>Direct Multi-Turn Preference Optimization for Language Agents</strong><br />Wentao Shi, Mengqi Yuan, Junkang Wu, Qifan Wang, Fuli Feng</p>

<p><strong>Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models</strong><br />Leonardo Ranaldi, Andre Freitas</p>

<p><strong>In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search</strong><br />Huihan Li, Yuting Ning, Zeyi Liao, Siyuan Wang, Xiang Lorraine Li, Ximing Lu, Wenting Zhao, Faeze Brahman, Yejin Choi, Xiang Ren</p>

<p><strong>AutoScraper: A Progressive Understanding Web Agent for Web Scraper Generation</strong><br />Wenhao Huang, Zhouhong Gu, Chenghao Peng, Jiaqing Liang, Zhixu Li, Yanghua Xiao, liqian wen, Zulong Chen</p>

<p><strong>Backward Lens: Projecting Language Model Gradients into the Vocabulary Space</strong><br />Shahar Katz, Yonatan Belinkov, Mor Geva, Lior Wolf</p>

<p><strong>Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding</strong><br />Jiwan Chung, Sungjae Lee, Minseo Kim, Seungju Han, Ashkan Yousefpour, Jack Hessel, Youngjae Yu</p>

<p><strong>Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!</strong><br />Jiwan Chung, Seungwon Lim, Jaehyun Jeon, Seungbeen Lee, Youngjae Yu</p>

<p><strong>Reusing Transferable Weight Increments for Low-resource Style Generation</strong><br />Chunzhen Jin, Eliot Huang, Heng Chang, Yaqi Wang, Peng Cao, Osmar Zaiane</p>

<p><strong>Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course</strong><br />Cheng-Han Chiang, Wei-Chih Chen, Chun-Yi Kuan, Chienchou Yang, Hung-yi Lee</p>

<p><strong>Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?</strong><br />Neeladri Bhuiya, Viktor Schlegel, Stefan Winkler</p>

<p><strong>Instruction Pre-Training: Language Models are Supervised Multitask Learners</strong><br />Daixuan Cheng, Yuxian Gu, Shaohan Huang, Junyu Bi, Minlie Huang, Furu Wei</p>

<p><strong>LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models</strong><br />Renzhi Wang, Piji Li</p>

<p><strong>Collaborative Performance Prediction for Large Language Models</strong><br />Qiyuan Zhang, Fuyuan Lyu, Xue Liu, Chen Ma</p>

<p><strong>Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese</strong><br />Yuqi Chen, Sixuan Li, Ying Li, Mohammad Atari</p>

<p><strong>Knowledge Verification to Nip Hallucination in the Bud</strong><br />Fanqi Wan, Xinting Huang, Leyang Cui, Xiaojun Quan, Wei Bi, Shuming Shi</p>

<p><strong>QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios</strong><br />Timo Pierre Schrader, Lukas Lange, Simon Razniewski, Annemarie Friedrich</p>

<p><strong>African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification</strong><br />Gregor Geigle, Radu Timofte, Goran Glavaš</p>

<p><strong>Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models</strong><br />Hongbang Yuan, Pengfei Cao, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao</p>

<p><strong>To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models</strong><br />Bastien Liétard, Pascal Denis, Mikaela Keller</p>

<p><strong>ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings</strong><br />Hao Wang, Hao Li, Minlie Huang, Lei Sha</p>

<p><strong>An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making</strong><br />Xiutian Zhao, Ke Wang, Wei Peng</p>

<p><strong>Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?</strong><br />Gregor Geigle, Radu Timofte, Goran Glavaš</p>

<p><strong>Take Off the Training Wheels! Progressive In-Context Learning for Effective Alignment</strong><br />zhenyu liu, Dongfang Li, Xinshuo Hu, Xinping Zhao, Yibin Chen, Baotian Hu, Min zhang</p>

<p><strong>MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning</strong><br />Yufei Ma, Zihan Liang, Huangyu Dai, Ben Chen, Dehong Gao, Zhuoran Ran, ZihanWang, Linbo Jin, Wen Jiang, Guannan Zhang, Xiaoyan Cai, Libin Yang</p>

<p><strong>Message Passing on Semantic-Anchor-Graphs for Fine-grained Emotion Representation Learning and Classification</strong><br />Pinyi Zhang, Jingyang Chen, Junchen Shen, Zijie Zhai, Ping Li, Jie Zhang, Kai Zhang</p>

<p><strong>PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study</strong><br />Yuqing Zhang, Baoyi He, Yihan Chen, Hangqi Li, Han Yue, Shengyu Zhang, Huaiyong Dou, Junchi Yan, Zemin Liu, Yongquan Zhang, Fei Wu</p>

<p><strong>Alignment-Enhanced Decoding: Defending via Token-Level Adaptive Refining of Probability Distributions</strong><br />Quan Liu, Zhenhong Zhou, Longzhu He, Yi Liu, Wei Zhang, Sen Su</p>

<p><strong>MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction</strong><br />Qiao Sun, Liujia Yang, Minghao Ma, Nanyang Ye, Qinying Gu</p>

<p><strong>Evaluating Large Language Models via Linguistic Profiling</strong><br />Alessio Miaschi, Felice Dell’Orletta, Giulia Venturi</p>

<p><strong>With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models</strong><br />Tyler Loakman, YUCHENG LI, Chenghua Lin</p>

<p><strong>KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases</strong><br />Jiajie Zhang, Shulin Cao, Linmei Hu, Ling Feng, Lei Hou, Juanzi Li</p>

<p><strong>Understanding Higher-Order Correlations Among Semantic Components in Embeddings</strong><br />Momose Oyama, Hiroaki Yamagiwa, Hidetoshi Shimodaira</p>

<p><strong>DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection</strong><br />Zhihong Zhu, Kefan Shen, Zhaorun Chen, Yunyan Zhang, Yuyan Chen, Xiaoqi Jiao, Zhongwei Wan, Wei Liu, Xian Wu, Shaorong Xie, Yefeng Zheng</p>

<p><strong>Evaluating D-MERIT of Partial-annotation on Information Retrieval</strong><br />Royi Rassin, Yaron Fairstein, Oren Kalinsky, Guy Kushilevitz, Nachshon Cohen, Alexander Libov, Yoav Goldberg</p>

<p><strong>Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving</strong><br />XIN QUAN, Marco Valentino, Louise A. Dennis, Andre Freitas</p>

<p><strong>Calibrating the Confidence of Large Language Models by Eliciting Fidelity</strong><br />Mozhi Zhang, Mianqiu Huang, Rundong Shi, Linsen Guo, Chong Peng, Peng Yan, Yaqian Zhou, Xipeng Qiu</p>

<p><strong>Exploring Reward Model Strength’s Impact on Language Models</strong><br />Yanjun Chen, Dawei Zhu, Yirong Sun, Xinghao Chen, Wei Zhang, Xiaoyu Shen</p>

<p><strong>How Hard is this Test Set? NLI Characterization by Exploiting Training Dynamics</strong><br />Adrian Cosma, Stefan Ruseti, Mihai Dascalu, Cornelia Caragea</p>

<p><strong>Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection</strong><br />Gaetan Lopez Latouche, Marc-André Carbonneau, Benjamin Swanson</p>

<p><strong>CUTE: Measuring LLMs’ Understanding of Their Tokens</strong><br />Lukas Edman, Helmut Schmid, Alexander Fraser</p>

<p><strong>SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation</strong><br />Xinping Zhao, Dongfang Li, Yan Zhong, Boren Hu, Yibin Chen, Baotian Hu, Min zhang</p>

<p><strong>On The Role of Context in Reading Time Prediction</strong><br />Andreas Opedal, Eleanor Chodroff, Ryan Cotterell, Ethan Wilcox</p>

<p><strong>BC-Prover: Backward Chaining Prover for Formal Theorem Proving</strong><br />Yuhang He, Jihai Zhang, Jianzhu Bao, Fangquan Lin, Cheng Yang, Bing Qin, Ruifeng Xu, Wotao Yin</p>

<p><strong>From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP</strong><br />Marius Mosbach, Vagrant Gautam, Tomás Vergara Browne, Dietrich Klakow, Mor Geva</p>

<p><strong>Dual Modalities of Text: Visual and Textual Generative Pre-Training</strong><br />Yekun Chai, Qingyi Liu, Jingwu Xiao, Shuohuan Wang, Yu Sun, Hua Wu</p>

<p><strong>On Training Data Influence of GPT Models</strong><br />Qingyi Liu, Yekun Chai, Shuohuan Wang, Yu Sun, Qiwei Peng, Hua Wu</p>

<p><strong>Understanding “Democratization” in NLP and ML Research</strong><br />Arjun Subramonian, Vagrant Gautam, Dietrich Klakow, Zeerak Talat</p>

<p><strong>DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models</strong><br />Sungnyun Kim, Haofu Liao, Srikar Appalaraju, Peng Tang, Zhuowen Tu, Ravi Kumar Satzoda, R. Manmatha, Vijay Mahadevan, Stefano Soatto</p>

<p><strong>Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages</strong><br />Seonjeong Hwang, Yunsu Kim, Gary Lee</p>

<p><strong>ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws</strong><br />Ruihang Li, Yixuan Wei, Miaosen Zhang, Nenghai Yu, Han Hu, Houwen Peng</p>

<p><strong>Word Alignment as Preference for Machine Translation</strong><br />Qiyu Wu, Masaaki Nagata, Zhongtao Miao, Yoshimasa Tsuruoka</p>

<p><strong>Improving Multi-party Dialogue Generation via Topic and Rhetorical Coherence</strong><br />Yaxin FAN, PEIFENG LI, Qiaoming Zhu</p>

<p><strong>SEEKR: Selective Attention-Guided Knowledge Retention for Continual Learning of Large Language Models</strong><br />Jinghan He, Haiyun Guo, Kuan Zhu, Zihan Zhao, Ming Tang, Jinqiao Wang</p>

<p><strong>Neuron-Level Knowledge Attribution in Large Language Models</strong><br />ZEPING YU, Sophia Ananiadou</p>

<p><strong>How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning</strong><br />ZEPING YU, Sophia Ananiadou</p>

<p><strong>Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis</strong><br />ZEPING YU, Sophia Ananiadou</p>

<p><strong>Pixology: Probing the Linguistic and Visual Knowledge of Pixel-based Language Models</strong><br />Kushal Tatariya, Vladimir Araujo, Thomas Bauwens, Miryam de Lhoneux</p>

<p><strong>GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory</strong><br />Wei Fan, Haoran Li, Zheye Deng, Weiqi Wang, Yangqiu Song</p>

<p><strong>Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature</strong><br />ALI ALLAITH, Daniel Hershcovich, Jens Bjerring-Hansen, Jakob Ingemann Parby, Alexander Conroy, Timothy R Tangherlini</p>

<p><strong>QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models</strong><br />Saleh Ashkboos, Ilia Markov, Elias Frantar, Tingxuan Zhong, Xincheng Wang, Jie Ren, Torsten Hoefler, Dan Alistarh</p>

<p><strong>Fine-Grained Prediction of Reading Comprehension from Eye Movements</strong><br />Omer Shubi, Yoav Meiri, Cfir Avraham Hadar, Yevgeni Berzak</p>

<p><strong>Efficient Retriever for Multi-Hop Retrieval Question Answerin</strong><br />Ziyuan Zhuang, Zhiyang Zhang, Sitao Cheng, Fangkai Yang, Jia Liu, Shujian Huang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</p>

<p><strong>Unsupervised Human Preference Learning</strong><br />Sumuk Shashidhar, Abhinav Chinta, Vaibhav Sahai, Dilek Hakkani Tur</p>

<p><strong>Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering</strong><br />Helena Bonaldi, Greta Damo, Nicolás Benjamín Ocampo, Elena Cabrio, Serena Villata, Marco Guerini</p>

<p><strong>Leading Whitespaces of Language Models’ Subword Vocabulary Poses a Confound for Calculating Word Probabilities</strong><br />Byung-Doh Oh, William Schuler</p>

<p><strong>LLM4Decompile: Decompiling Binary Code with Large Language Models</strong><br />Hanzhuo Tan, Qi Luo, Jing Li, Yuqun Zhang</p>

<p><strong>From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning</strong><br />Jihao Gu, Zelin Wang, Yibo Zhang, Ziji Zhang, Ping Gong</p>

<p><strong>CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering</strong><br />Yike Wu, Yi Huang, Nan Hu, YUNCHENG HUA, Guilin Qi, Jiaoyan Chen, Jeff Z. Pan</p>

<p><strong>MTLS: Making Texts into Linguistic Symbols</strong><br />Wenlong Fei, Xiaohua Wang, Min Hu, Qingyu Zhang, Hongbo Li</p>

<p><strong>D2R: Dual-Branch Dynamic Routing Network for Multimodal Sentiment Detection</strong><br />Yifan Chen, Kuntao Li, Weixing Mai, Qiaofeng Wu, Yun Xue, Fenghuan Li</p>

<p><strong>A Generic Method for Fine-grained Category Discovery in Natural Language Texts</strong><br />Chang Tian, Matthew B. Blaschko, Wenpeng Yin, Mingzhe Xing, Yinliang Yue, Marie-Francine Moens</p>

<p><strong>Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method</strong><br />Yang Trista Cao, Lovely-Frances Domingo, Sarah Gilbert, Michelle L. Mazurek, Katherine Shilton, Hal Daumé III</p>

<p><strong>A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models</strong><br />Jiayin Wang, Fengran Mo, Weizhi Ma, Peijie Sun, Min Zhang, Jian-Yun Nie</p>

<p><strong>Decompose and Compare Consistency: Measuring VLMs’ Answer Reliability via Task-Decomposition Consistency Comparison</strong><br />Qian Yang, Weixiang Yan, Aishwarya Agrawal</p>

<p><strong>Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism</strong><br />Lang Cao</p>

<p><strong>VGBench: A Comprehensive Benchmark of Vector Graphics Understanding and Generation for Large Language Models</strong><br />Bocheng Zou, Mu Cai, Jianrui Zhang, Yong Jae Lee</p>

<p><strong>What do large language models need for machine translation evaluation?</strong><br />Shenbin Qian, Archchana Sindhujan, Minnie Kabra, Diptesh Kanojia, Constantin Orasan, Tharindu Ranasinghe, Fred Blain</p>

<p><strong>Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale</strong><br />Flavio Di Palo, Prateek Singhi, Bilal H Fadlallah</p>

<p><strong>External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models</strong><br />Debela Gemechu, Chris Reed</p>

<p><strong>C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits</strong><br />Maaz Bin Musa, Rishab Nithyanand, Padmini Srinivasan, Mihailis E. Diamantis, Steven M. Winston, Garrison Allen, Jacob Schiller, Kevin Moore, Sean Quick, Johnathan Melvin</p>

<p><strong>MPT: Multimodal Prompt Tuning for Zero-shot Instruction Learning</strong><br />Taowen Wang, Yiyang Liu, James Chenhao Liang, junhan zhao, Yiming Cui, Yuning Mao, Shaoliang Nie, Jiahao Liu, Fuli Feng, Zenglin Xu, Cheng Han, Lifu Huang, Qifan Wang, Dongfang Liu</p>

<p><strong>Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification</strong><br />Letian Peng, Yi Gu, Chengyu Dong, Zihan Wang, Jingbo Shang</p>

<p><strong>Incubating Text Classifiers Following User Instruction with Nothing but LLM</strong><br />Letian Peng, Zilong Wang, Jingbo Shang</p>

<p><strong>PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL</strong><br />Ruilin Luo, Liyuan Wang, Binghuai Lin, Zicheng Lin, Yujiu Yang</p>

<p><strong>Conditional and Modal Reasoning in Large Language Models</strong><br />Wesley H. Holliday, Matthew Mandelkern, Cedegao E. Zhang</p>

<p><strong>Advancing Large Language Model Attribution through Self-Improving</strong><br />Lei Huang, Xiaocheng Feng, Weitao Ma, Liang Zhao, Yuchun Fan, Weihong Zhong, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin</p>

<p><strong>AlignCap: Aligning Speech Emotion Captioning to Human Preferences</strong><br />Ziqi Liang, Haoxiang Shi, Hanhui Chen</p>

<p><strong>Interpretability-based Tailored Knowledge Editing in Transformers</strong><br />Yihuai Hong, Aldo Lipani</p>

<p><strong>PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling</strong><br />Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang, Nicholas Roy, Chuchu Fan</p>

<p><strong>Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting</strong><br />Chen Cai, Zheng Wang, Jianjun Gao, Wenyang Liu, Ye Lu, Runzhong Zhang, Kim-Hui Yap</p>

<p><strong>Dissecting Fine-Tuning Unlearning in Large Language Models</strong><br />Yihuai Hong, Yuelin Zou, Lijie Hu, Ziqian Zeng, Di Wang, Haiqin Yang</p>

<p><strong>Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models</strong><br />Zhengxuan Wu, Yuhao Zhang, Peng Qi, Yumo Xu, Rujun Han, Yian Zhang, Jifan Chen, Bonan Min, zhiheng huang</p>

<p><strong>Where is the signal in tokenization space?</strong><br />Renato Geh, Honghua Zhang, Kareem Ahmed, Benjie Wang, Guy Van den Broeck</p>

<p><strong>Private Language Models via Truncated Laplacian Mechanism</strong><br />Tianhao Huang, Tao Yang, Ivan Habernal, Lijie Hu, Di Wang</p>

<p><strong>Estimating Knowledge in Large Language Models Without Generating a Single Token</strong><br />Daniela Gottesman, Mor Geva</p>

<p><strong>Consistent Autoformalization for Constructing Mathematical Libraries</strong><br />Lan Zhang, XIN QUAN, Andre Freitas</p>

<p><strong>Contextual and Parametric Knowledge: More Context, More Focus</strong><br />Yufei Tao, Adam Hiatt, Erik Haake, Antonie J. Jetter, Ameeta Agrawal</p>

<p><strong>Semantic Training Signals Promote Hierarchical Syntactic Generalization in Transformers</strong><br />Aditya Yedetore, Najoung Kim</p>

<p><strong>When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages</strong><br />Tyler A. Chang, Catherine Arnett, Zhuowen Tu, Ben Bergen</p>

<p><strong>Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use</strong><br />Jiajun Xi, Yinong He, Jianing Yang, Yinpei Dai, Joyce Chai</p>

<p><strong>MiTTenS: A Dataset for Evaluating Gender Mistranslation</strong><br />Kevin Robinson, Sneha Kudugunta, Romina Stella, Sunipa Dev, Jasmijn Bastings</p>

<p><strong>Teaching LLMs to Abstain across Languages via Multilingual Feedback</strong><br />Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Orevaoghene Ahia, Shuyue Stella Li, Vidhisha Balachandran, Sunayana Sitaram, Yulia Tsvetkov</p>

<p><strong>Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration</strong><br />Shangbin Feng, Taylor Sorensen, Yuhan Liu, Jillian Fisher, Chan Young Park, Yejin Choi, Yulia Tsvetkov</p>

<p><strong>StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements</strong><br />Jillian Fisher, Skyler Hallinan, Ximing Lu, Mitchell L Gordon, Zaid Harchaoui, Yejin Choi</p>

<p><strong>I Could’ve Asked That: Reformulating Unanswerable Questions</strong><br />Wenting Zhao, Ge Gao, Claire Cardie, Alexander M Rush</p>

<p><strong>STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions</strong><br />Robert Morabito, Sangmitra Madhusudan, Tyler McDonald, Ali Emami</p>

<p><strong>Hidden Persuaders: How LLM Political Bias Could Sway Our Elections</strong><br />Yujin Potter, Shiyang Lai, Junsol Kim, James Evans, Dawn Song</p>

<p><strong>SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning</strong><br />Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu</p>

<p><strong>When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives</strong><br />Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Wenlin Yao, Hassan Foroosh, Dong Yu, Fei Liu</p>

<p><strong>An Analysis of Multilingual FActScore</strong><br />Vu Trong Kim, Michael Krumdick, Varshini Reddy, Franck Dernoncourt, Viet Dac Lai</p>

<p><strong>Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models</strong><br />Seungone Kim, Juyoung Suk, Shayne Longpre, Bill Yuchen Lin, Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, Minjoon Seo</p>

<p><strong>RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering</strong><br />Rujun Han, Yuhao Zhang, Peng Qi, Yumo Xu, Jenyuan Wang, Lan Liu, William Yang Wang, Bonan Min, Vittorio Castelli</p>

<p><strong>PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval</strong><br />Shengyao Zhuang, Xueguang Ma, Bevan Koopman, Jimmy Lin, Guido Zuccon</p>

<p><strong>Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects</strong><br />Orevaoghene Ahia, Anuoluwapo Aremu, Diana Abagyan, Hila Gonen, David Ifeoluwa Adelani, Daud Abolade, Noah A. Smith, Yulia Tsvetkov</p>

<p><strong>ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback</strong><br />Ju-Seung Byun, Jiyun Chun, Jihyung Kil, Andrew Perrault</p>

<p><strong>Order of Magnitude Speedups for LLM Membership Inference</strong><br />Rongting Zhang, Martin Andres Bertran, Aaron Roth</p>

<p><strong>VIMI: Grounding Video Generation through Multi-modal Instruction</strong><br />Yuwei Fang, Willi Menapace, Aliaksandr Siarohin, Tsai-Shien Chen, Kuan-Chieh Wang, Ivan Skorokhodov, Graham Neubig, Sergey Tulyakov</p>

<p><strong>F$^2$RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation</strong><br />Haiyang Wang, Yuchen Pan, Xin Song, Xuechen Zhao, Minghao Hu, Bin Zhou</p>

<p><strong>Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning</strong><br />Chang Yang, Peng Zhang, Hui Gao, Jing Zhang</p>

<p><strong>Visual Prompting in LLMs for Enhancing Emotion Recognition</strong><br />Qixuan Zhang, Zhifeng Wang, Dylan Zhang, Yang Liu, Zhenyue Qin, Wenjia Niu, Sabrina Caldwell, Tom Gedeon</p>

<p><strong>IDEAW: Robust Neural Audio Watermarking with Invertible Dual-Embedding</strong><br />Pengcheng Li, Xulong Zhang, Jing Xiao, Jianzong Wang</p>

<p><strong>Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset</strong><br />Che Wei Tsai, Yen-Hao Huang, Tsu-keng Liao, Didier Fernando Salazar Estrada, Retnani Latifah, Yi-Shin Chen</p>

<p><strong>Outcome-Constrained Large Language Models for Countering Hate Speech</strong><br />Lingzi Hong, Pengcheng Luo, Eduardo Blanco, Xiaoying Song</p>

<p><strong>Multiple Sources are Better Than One: Incorporating External Knowledge in Low-Resource Glossing</strong><br />Changbing Yang, Garrett Nicolai, Miikka Silfverberg</p>

<p><strong>Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks</strong><br />Ao Wang, Xinghao Yang, Chen Li, Bao-di Liu, Weifeng Liu</p>

<p><strong>Bootstrapped Policy Learning for Task-oriented Dialogue through Goal Shaping</strong><br />Yangyang Zhao, Ben Niu, Mehdi Dastani, Shihan Wang</p>

<p><strong>PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling</strong><br />Huachuan Qiu, Lizhi Ma, Zhenzhong Lan</p>

<p><strong>World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering</strong><br />Jiacong Wang, Bohong Wu, Haiyong Jiang, Haoyuan Guo, Xin Xiao, zhou Xun, Jun Xiao</p>

<p><strong>DVD: Dynamic Contrastive Decoding for Knowledge Amplification in Multi-Document Question Answering</strong><br />Jing Jin, Houfeng Wang, Hao Zhang, Xiaoguang Li, Zhijiang Guo</p>

<p><strong>How Do Humans Write Code? Large Models Do It the Same Way Too</strong><br />Long Li, Xuzheng He, Haozhe Wang, Linlin Wang, Liang He</p>

<p><strong>Retrospex: Language Agent Meets Offline Reinforcement Learning Critic</strong><br />Yufei Xiang, Yiqun Shen, Yeqin Zhang, Nguyen Cam-Tu</p>

<p><strong>Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-Context Models</strong><br />Xinyu Liu, Runsong Zhao, Pengcheng Huang, Chunyang Xiao, Bei Li, Jingang Wang, Tong Xiao, JingBo Zhu</p>

<p><strong>Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation</strong><br />Yuanjie Lyu, Zihan Niu, Zheyong Xie, Chao Zhang, Tong Xu, Yang Wang, Enhong Chen</p>

<p><strong>CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation</strong><br />Renhao Li, Minghuan Tan, Derek F. Wong, Min Yang</p>

<p><strong>A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners</strong><br />Bowen Jiang, Yangxinyu Xie, Zhuoqun Hao, Xiaomeng Wang, Tanwi Mallick, Weijie J Su, Camillo Jose Taylor, Dan Roth</p>

<p><strong>Bayesian Calibration of Win Rate Estimation with LLM Evaluators</strong><br />Yicheng Gao, Gonghan Xu, Zhe Wang, Arman Cohan</p>

<p><strong>MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning</strong><br />Shuo Yin, Weihao You, Zhilong Ji, Guoqiang Zhong, Jinfeng Bai</p>

<p><strong>Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients</strong><br />Weijun Li, Qiongkai Xu, Mark Dras</p>

<p><strong>RWKV-CLIP: A Robust Vision-Language Representation Learner</strong><br />Tiancheng Gu, Kaicheng Yang, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai, Jiankang Deng</p>

<p><strong>KidLM: Advancing Language Models for Children – Early Insights and Future Directions</strong><br />Mir Tafseer Nayeem, Davood Rafiei</p>

<p><strong>Using Language Models to Disambiguate Lexical Choices in Translation</strong><br />Josh Barua, Sanjay Subramanian, Kayo Yin, Alane Suhr</p>

<p><strong>How Does the Disclosure of AI Assistance Affect the Perceptions of Writing?</strong><br />Zhuoyan Li, Chen Liang, Jing Peng, Ming Yin</p>

<p><strong>An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records</strong><br />Joakim Edin, Maria Maistro, Lars Maaløe, Lasse Borgholt, Jakob Drachmann Havtorn, Tuukka Ruotsalo</p>

<p><strong>Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs</strong><br />Zheng Wang, Zhongyang Li, Jiang Zeren, Dandan Tu, Wei Shi</p>

<p><strong>EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation</strong><br />Jiateng Liu, Pengfei Yu, Yuji Zhang, Sha Li, Zixuan Zhang, Ruhi Sarikaya, Kevin Small, Heng Ji</p>

<p><strong>Predicting Nonnative Sentence Processing with L2LMs</strong><br />Tatsuya Aoyama, Nathan Schneider</p>

<p><strong>From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis</strong><br />Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan</p>

<p><strong>Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs</strong><br />Shadi Iskander, Sofia Tolmach, Ori Shapira, Nachshon Cohen, Zohar Karnin</p>

<p><strong>Cross-Domain Audio Deepfake Detection: Dataset and Analysis</strong><br />Yuang Li, Min Zhang, Mengxin Ren, Xiaosong Qiao, Miaomiao Ma, Daimeng Wei, Hao Yang</p>

<p><strong>MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension</strong><br />Ting Liu, Zunnan Xu, Zhiqiang Wang, Yue Hu, Liangtao Shi, Quanjun Yin</p>

<p><strong>Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning</strong><br />Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo</p>

<p><strong>Aligning Translation-Specific Understanding to General Understanding in Large Language Models</strong><br />Yichong Huang, Baohang Li, Xiaocheng Feng, Wenshuai Huo, Chengpeng Fu, Ting Liu, Bing Qin</p>

<p><strong>FOOL ME IF YOU CAN! An Adversarial Dataset to Investigate the Robustness of LMs in Word Sense Disambiguation</strong><br />Mohamad Ballout, Anne Dedert, Nohayr Muhammad Abdelmoneim, Ulf Krumnack, Gunther Heidemann, Kai-Uwe Kühnberger</p>

<p><strong>Concept-skill Transferability-based Data Selection for Large Vision-Language Models</strong><br />Jaewoo Lee, Boyang Li, Sung Ju Hwang</p>

<p><strong>LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing</strong><br />Jiangshu Du, Yibo Wang, Wenting Zhao, Zhongfen Deng, Shuaiqi LIU, Renze Lou, Henry Peng Zou, Pranav Narayanan Venkit, Nan Zhang, Mukund Srinath, Haoran Ranran Zhang, Vipul Gupta, Yinghui Li, Tao Li, Fei Wang, Qin Liu, Tianlin Liu, Pengzhi Gao, Congying Xia, Chen Xing, Cheng Jiayang, Zhaowei Wang, Ying Su, Raj Sanjay Shah, Ruohao Guo, Jing Gu, Haoran Li, Kangda Wei, Zihao Wang, Lu Cheng, Surangika Ranathunga, Meng Fang, Jie Fu, Fei Liu, Ruihong Huang, Eduardo Blanco, Yixin Cao, Rui Zhang, Philip S. Yu, Wenpeng Yin</p>

<p><strong>Academics Can Contribute to Domain-Specialized Language Models</strong><br />Mark Dredze, Genta Indra Winata, Prabhanjan Kambadur, Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, David S Rosenberg, Sebastian Gehrmann</p>

<p><strong>Beyond Reference: Evaluating High Quality Translations Better than Human References</strong><br />Keonwoong Noh, Seokjin Oh, Woohwan Jung</p>

<p><strong>Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement</strong><br />Pengwei Zhan, Zhen Xu, Qian Tan, Jie Song, Ru Xie</p>

<p><strong>SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages</strong><br />Holy Lovenia, Rahmad Mahendra, Salsabil Maulana Akbar, Lester James Validad Miranda, Jennifer Santoso, Elyanah Aco, Akhdan Fadhilah, Jonibek Mansurov, Joseph Marvin Imperial, Onno P. Kampman, Joel Ruben Antony Moniz, Muhammad Ravi Shulthan Habibi, Frederikus Hudi, Jann Railey Montalan, Ryan Ignatius Hadiwijaya, Joanito Agili Lopo, William Nixon, Börje F. Karlsson, James Jaya, Ryandito Diandaru, Yuze GAO, Patrick Amadeus Irawan, Bin Wang, Jan Christian Blaise Cruz, Chenxi Whitehouse, Ivan Halim Parmonangan, Maria Khelli, Wenyu Zhang, Lucky Susanto, Reynard Adha Ryanda, Sonny Lazuardi Hermawan, Dan John Velasco, Muhammad Dehan Al Kautsar, Willy Fitra Hendria, Yasmin Moslem, Noah Flynn, Muhammad Farid Adilazuarda, Haochen Li, Johanes Lee, R. Damanhuri, Shuo Sun, Muhammad Reza Qorib, Amirbek Djanibekov, Wei Qi Leong, Quyet V. Do, Niklas Muennighoff, Tanrada Pansuwan, Ilham Firdausi Putra, Yan Xu, Tai Ngee Chia, Ayu Purwarianti, Sebastian Ruder, William Chandra Tjhi, Peerat Limkonchotiwat, Alham Fikri Aji, Sedrick Keh, Genta Indra Winata, Ruochen Zhang, Fajri Koto, Zheng Xin Yong, Samuel Cahyawijaya</p>

<p><strong>Induct-Learn: Short Phrase Prompting with Instruction Induction</strong><br />Po-Chun Chen, Sheng-Lun Wei, Hen-Hsen Huang, Hsin-Hsi Chen</p>

<p><strong>Multi-Granularity History and Entity Similarity Learning for Temporal Knowledge Graph Reasoning</strong><br />Shi Mingcong, Chunjiang Zhu, Detian Zhang, Shiting Wen, Qing Li</p>

<p><strong>LUQ: Long-text Uncertainty Quantification for LLMs</strong><br />Caiqi Zhang, Fangyu Liu, Marco Basaldella, Nigel Collier</p>

<p><strong>Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method</strong><br />Weichao Zhang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng</p>

<p><strong>Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars</strong><br />Damien Sileo</p>

<p><strong>Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach</strong><br />Maxime Poli, Emmanuel Chemla, Emmanuel Dupoux</p>

<p><strong>Safely Learning with Private Data: A Federated Learning Framework for Large Language Model</strong><br />Jia-Ying Zheng, Hainan Zhang, Lingxiang Wang, Wangjie Qiu, Hong-Wei Zheng, Zhi-Ming Zheng</p>

<p><strong>Formality Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge</strong><br />Jiahuan Li, Yiqing Cao, Shujian Huang, Jiajun Chen</p>

<p><strong>How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?</strong><br />Yang Luo, Zangwei Zheng, Zirui Zhu, Yang You</p>

<p><strong>How Far Can We Extract Diverse Perspectives from Large Language Models?</strong><br />Shirley Anugrah Hayati, Minhwa Lee, Dheeraj Rajagopal, Dongyeop Kang</p>

<p><strong>EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning</strong><br />Kiran Purohit, Venktesh V, Raghuram Devalla, Krishna Mohan Yerragorla, Sourangshu Bhattacharya, Avishek Anand</p>

<p><strong>An LLM Feature-based Framework for Dialogue Constructiveness Assessment</strong><br />Lexin Zhou, Youmna Farag, Andreas Vlachos</p>

<p><strong>Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System</strong><br />Zhanpeng Chen, Zhihong Zhu, Wanshi Xu, Xianwei Zhuang, Yuexian Zou</p>

<p><strong>Dialog2Flow: Pre-training Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction</strong><br />Sergio Burdisso, Srikanth Madikeri, Petr Motlicek</p>

<p><strong>Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation</strong><br />Raphael Tang, Crystina Zhang, Lixinyu Xu, Yao Lu, Wenyan Li, Pontus Stenetorp, Jimmy Lin, Ferhan Ture</p>

<p><strong>Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024</strong><br />Ilias Chalkidis</p>

<p><strong>Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning</strong><br />Mayi Xu, Yongqi Li, Ke Sun, Tieyun Qian</p>

<p><strong>LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations</strong><br />Shengda Fan, Yanting Wang, Shasha Mo, Jianwei Niu</p>

<p><strong>Concept Space Alignment in Multilingual LLMs</strong><br />Qiwei Peng, Anders Søgaard</p>

<p><strong>Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model</strong><br />Chenhan Yuan, Fei Huang, Ru Peng, Keming Lu, Bowen Yu, Chang Zhou, Jingren Zhou</p>

<p><strong>NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian</strong><br />Peng Liu, Lemei Zhang, Terje Farup, Even W. Lauvrak, Jon Espen Ingvaldsen, Simen Eide, Jon Atle Gulla, Zhirong Yang</p>

<p><strong>RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework</strong><br />Yifan Wang, Vera Demberg</p>

<p><strong>Scaling Laws Across Model Architectures: A Comparative Analysis of Dense and MoE Models in Large Language Models</strong><br />Siqi Wang, Zhengyu Chen, Bei Li, Keqing He, Min Zhang, Jingang Wang</p>

<p><strong>Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems</strong><br />Vishal Vivek Saley, Rocktim Jyoti Das, Dinesh Raghu, Mausam .</p>

<p><strong>REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering</strong><br />Yuhao Wang, Ruiyang Ren, Junyi Li, Xin Zhao, Jing Liu, Ji-Rong Wen</p>

<p><strong>Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA</strong><br />Minzheng Wang, Longze Chen, ChengFu, Liaoshengyi, Xinghua Zhang, Bingliwu, Haiyang Yu, Nan Xu, Lei Zhang, Run Luo, Yunshui Li, Min Yang, Fei Huang, Yongbin Li</p>

<p><strong>On Mitigating Performance Disparities in Multilingual Speech Recognition</strong><br />Monorama Swain, Anna Katrine van Zee, Anders Søgaard</p>

<p><strong>Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting</strong><br />Stephen Meisenbacher, Florian Matthes</p>

<p><strong>From Coarse to Fine: Impacts of Feature-Preserving and Feature-Compressing Connectors on Perception in Multimodal Models</strong><br />Junyan Lin, Haoran Chen, Dawei Zhu, Xiaoyu Shen</p>

<p><strong>What is ‘‘Typological Diversity’’ in NLP?</strong><br />Esther Ploeger, Wessel Poelman, Miryam de Lhoneux, Johannes Bjerva</p>

<p><strong>The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse</strong><br />Xiaobo Guo, Neil Potnis, Melody Yu, Nabeel Gillani, Soroush Vosoughi</p>

<p><strong>Consistent Bidirectional Language Modelling: Expressive Power and Representational Conciseness</strong><br />Georgi Shopov, Stefan Gerdjikov</p>

<p><strong>Benchmarking Vision Language Models for Cultural Understanding</strong><br />Shravan Nayak, Kanishk Jain, Rabiul Awal, Siva Reddy, Sjoerd van Steenkiste, Lisa Anne Hendricks, Karolina Stanczak, Aishwarya Agrawal</p>

<p><strong>Methods of Automatic Matrix Language Determination for Code-Switched Speech</strong><br />Olga Iakovenko, Thomas Hain</p>

<p><strong>Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts</strong><br />Jaewook Lee, Yeajin Jang, Hongjin KIM, Woojin Lee, Harksoo Kim</p>

<p><strong>Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models</strong><br />Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Sarath Chandar</p>

<p><strong>Teaching Small Language Models Reasoning through Counterfactual Distillation</strong><br />FengTao, Yicheng Li, Li Chenglin, Hao Chen, Fei Yu, Yin Zhang</p>

<p><strong>Do Not Worry if You Do Not Have Data: Building Pretrained Language Models Using Translationese</strong><br />Meet Doshi, Raj Dabre, Pushpak Bhattacharyya</p>

<p><strong>Quantifying the Gap Between Machine Translation and Native Language in Training for Multimodal, Multilingual Retrieval</strong><br />Kyle Buettner, Adriana Kovashka</p>

<p><strong>MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval</strong><br />Qixi Lu, Gongbo Tang</p>

<p><strong>Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates</strong><br />Aida Kostikova, Dominik Beese, Benjamin Paassen, Ole Pütz, Gregor Wiedemann, Steffen Eger</p>

<p><strong>CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling</strong><br />Yu Bai, Xiyuan Zou, Heyan Huang, Sanxing Chen, Marc-Antoine Rondeau, Yang Gao, Jackie CK Cheung</p>

<p><strong>Story Embeddings — Narrative-Focused Representations of Fictional Stories</strong><br />Hans Ole Hatzel, Chris Biemann</p>

<p><strong>C-LLM: Learn to Check Chinese Spelling Errors Character by Character</strong><br />Kunting Li, Yong Hu, Liang He, Fandong Meng, Jie Zhou</p>

<p><strong>PSC: Extending Context Window of Large Language Models via Phase Shift Calibration</strong><br />Wenqiao Zhu, Chao Xu, Lulu Wang, Jun Wu</p>

<p><strong>Video-LLaVA: Learning United Visual Representation by Alignment Before Projection</strong><br />Bin Lin, Yang Ye, Bin Zhu, Jiaxi Cui, Munan Ning, Peng Jin, Li Yuan</p>

<p><strong>SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales</strong><br />Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze Liu, Xingyao Wang, Yangyi Chen, Jing Gao</p>

<p><strong>Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing</strong><br />Richard Diehl Martinez, Zebulon Goriely, Andrew Caines, Paula Buttery, Lisa Beinborn</p>

<p><strong>ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations</strong><br />Yunze Xiao, Yujia Hu, Kenny Tsu Wei Choo, Roy Ka-Wei Lee</p>

<p><strong>Boosting Scientific Concepts Understanding: Can Analogies from Teacher Models Empower Student Models?</strong><br />Siyu Yuan, Cheng Jiayang, Lin Qiu, Deqing Yang</p>

<p><strong>Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation</strong><br />Jirui Qi, Gabriele Sarti, Raquel Fernández, Arianna Bisazza</p>

<p><strong>Do Large Language Models Know How Much They Know?</strong><br />Gabriele Prato, Jerry Huang, Prasanna Parthasarathi, Shagun Sodhani, Sarath Chandar</p>

<p><strong>Investigating Mysteries of CoT-Augmented Distillation</strong><br />Somin Wadhwa, Silvio Amir, Byron C Wallace</p>

<p><strong>SciPrompt: Knowledge-Augmented Prompting for Fine-Grained Categorization of Scientific Topics</strong><br />Zhiwen You, Kanyao Han, Haotian Zhu, Bertram Ludaescher, Jana Diesner</p>

<p><strong>Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP</strong><br />Samyadeep Basu, Shell Xu Hu, Maziar Sanjabi, Daniela Massiceti, Soheil Feizi</p>

<p><strong>Learning from Natural Language Explanations for Generalizable Entity Matching</strong><br />Somin Wadhwa, ADIT KRISHNAN, Runhui Wang, Byron C Wallace, Luyang Kong</p>

<p><strong>Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation</strong><br />Zhuohang Li, Jiaxin Zhang, Chao Yan, Kamalika Das, Sricharan Kumar, Murat Kantarcioglu, Bradley A. Malin</p>

<p><strong>On the Reliability of Psychological Scales on Large Language Models</strong><br />Jen-tse Huang, Wenxuan Wang, Man Ho LAM, Eric John Li, Wenxiang Jiao, Michael Lyu</p>

<p><strong>Contrastive Entity Coreference and Disambiguation for Historical Texts</strong><br />Abhishek Arora, Emily Silcock, Melissa Dell, Leander Heldring</p>

<p><strong>Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models</strong><br />Jeonghwan Kim, Heng Ji</p>

<p><strong>Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts</strong><br />Sumit Asthana, Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata</p>

<p><strong>VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment</strong><br />Lei Li, Zhihui Xie, Mukai Li, Shunian Chen, Peiyi Wang, Liang Chen, Yazheng Yang, Benyou Wang, Lingpeng Kong, Qi Liu</p>

<p><strong>Focused Large Language Models are Stable Many-Shot Learners</strong><br />Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Heda Wang, Yao Hu, Kan Li</p>

<p><strong>Reconsidering Sentence-Level Sign Language Translation</strong><br />Garrett Tanzer, Maximus Shengelia, Ken Harrenstien, David Uthus</p>

<p><strong>GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities</strong><br />Sreyan Ghosh, Sonal Kumar, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, S Sakshi, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha</p>

<p><strong>Verba volant, scripta volant? Don’t worry! There are computational solutions for protoword reconstruction</strong><br />Liviu P Dinu, Ana Sabina Uban, Alina Maria Cristea, Ioan-Bogdan Iordache, Teodor-George Marchitan, Simona Georgescu, Laurentiu Zoicas</p>

<p><strong>ChatGPT Doesn’t Trust LA Chargers Fans: Guardrail Sensitivity in Context</strong><br />Victoria R Li, Yida Chen, Naomi Saphra</p>

<p><strong>Personas as a Way to Model Truthfulness in Language Models</strong><br />Nitish Joshi, Javier Rando, Abulhair Saparov, Najoung Kim, He He</p>

<p><strong>Satyrn: A Platform for Analytics Augmented Generation</strong><br />Marko Sterbentz, Cameron Barrie, Shubham Shahi, Abhratanu Dutta, Donna Hooshmand, Harper Pack, Kristian J Hammond</p>

<p><strong>EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning</strong><br />Ashish Seth, Ramaneswaran S, S Sakshi, Sonal Kumar, Sreyan Ghosh, Dinesh Manocha</p>

<p><strong>EPO: Hierarchical LLM Agents with Environment Preference Optimization</strong><br />Qi Zhao, Haotian Fu, Chen Sun, George Konidaris</p>

<p><strong>Detection and Measurement of Syntactic Templates in Generated Text</strong><br />Chantal Shaib, Yanai Elazar, Junyi Jessy Li, Byron C Wallace</p>

<p><strong>UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models</strong><br />Xinyu Pi, Mingyuan Wu, Jize Jiang, Haozhen Zheng, Beitong Tian, ChengXiang Zhai, Klara Nahrstedt, Zhiting Hu</p>

<p><strong>Optimized Speculative Sampling for GPU Hardware Accelerators</strong><br />Dominik Wagner, Seanie Lee, Ilja Baumann, Philipp Seeberger, Korbinian Riedhammer, Tobias Bocklet</p>

<p><strong>Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts</strong><br />Zhaoxuan Tan, Zheyuan Liu, Meng Jiang</p>

<p><strong>Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning</strong><br />Zhaoxuan Tan, Qingkai Zeng, Yijun Tian, Zheyuan Liu, Bing Yin, Meng Jiang</p>

<p><strong>Unifying Multimodal Retrieval via Document Screenshot Embedding</strong><br />Xueguang Ma, Sheng-Chieh Lin, Minghan Li, Wenhu Chen, Jimmy Lin</p>

<p><strong>Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation</strong><br />Shaomu Tan, Di Wu, Christof Monz</p>

<p><strong>An Audit on the Perspectives and Challenges of Hallucinations in NLP</strong><br />Pranav Narayanan Venkit, Tatiana Chakravorti, Vipul Gupta, Heidi Biggs, Mukund Srinath, Koustava Goswami, Sarah Rajtmajer, Shomir Wilson</p>

<p><strong>Discovering Knowledge-Critical Subnetworks in Pretrained Language Models</strong><br />Deniz Bayazit, Negar Foroutan, Zeming Chen, Gail Weiss, Antoine Bosselut</p>

<p><strong>Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models</strong><br />Junjie Chu, Zeyang Sha, Michael Backes, Yang Zhang</p>

<p><strong>Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering</strong><br />Armin Toroghi, Willis Guo, Mohammad Mahdi Abdollah Pour, Scott Sanner</p>

<p><strong>Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution</strong><br />Armin Toroghi, Willis Guo, Ali Pesaranghader, Scott Sanner</p>

<p><strong>Understanding and Mitigating Language Confusion in LLMs</strong><br />Kelly Marchisio, Wei-Yin Ko, Alexandre Berard, Théo Dehaze, Sebastian Ruder</p>

<p><strong>Can Large Language Models Learn Independent Causal Mechanisms?</strong><br />Gael Gendron, Bao Trung Nguyen, Alex Yuxuan Peng, Michael Witbrock, Gillian Dobbie</p>

<p><strong>MirrorStories: Reflecting Diversity through Personalized Narrative Generation with Large Language Models</strong><br />Sarfaroz Yunusov, Hamza Sidat, Ali Emami</p>

<p><strong>InterIntent: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context</strong><br />Ziyi Liu, Abhishek Anand, Pei Zhou, Jen-tse Huang, Jieyu Zhao</p>

<p><strong>Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia</strong><br />Farhan Samir, Chan Young Park, Vered Shwartz, Anjalie Field, Yulia Tsvetkov</p>

<p><strong>From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models</strong><br />Mehar Bhatia, Sahithya Ravi, Aditya Chinchure, EunJeong Hwang, Vered Shwartz</p>

<p><strong>Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation</strong><br />Karin De Langis, Ryan Koo, Dongyeop Kang</p>

<p><strong>MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model</strong><br />Jiahao Huo, Yibo Yan, Boren Hu, Yutao Yue, Xuming Hu</p>

<p><strong>Learning to Extract Structured Entities Using Language Models</strong><br />Haolun Wu, Ye Yuan, Liana Mikaelyan, Alexander Meulemans, Xue Liu, James Hensman, Bhaskar Mitra</p>

<p><strong>Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons</strong><br />Adian Liusie, Vatsal Raina, Yassir Fathullah, Mark Gales</p>

<p><strong>A Survey of AMR Applications</strong><br />Shira Wein, Juri Opitz</p>

<p><strong>Beyond Embeddings: The Promise of Visual Table in Visual Reasoning</strong><br />Yiwu Zhong, Zi-Yuan Hu, Michael Lyu, Liwei Wang</p>

<p><strong>CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation</strong><br />Shahla Farzana, Ivana Lucero, Vivian Villegas, Vera C Kaelin, Mary Khetani, Natalie Parde</p>

<p><strong>Secured Weight Release for Large Language Models via Taylor Expansion</strong><br />Guanchu Wang, Yu-Neng Chuang, Ruixiang Tang, Shaochen Zhong, Jiayi Yuan, Hongye Jin, Zirui Liu, Vipin Chaudhary, Shuai Xu, James Caverlee, Xia Hu</p>

<p><strong>TimeR$^4$ : Time-aware Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering</strong><br />Xinying Qian, Ying Zhang, Yu Zhao, Baohang Zhou, Xuhui Sui, Li Zhang, Kehui Song</p>

<p><strong>Knowledge-Centric Hallucination Detection</strong><br />Xiangkun Hu, Dongyu Ru, Lin Qiu, Qipeng Guo, Tianhang Zhang, Yang Xu, Yun Luo, Pengfei Liu, Yue Zhang, Zheng Zhang</p>

<p><strong>Revealing the Parallel Multilingual Learning within Large Language Models</strong><br />Yongyu Mu, Peinan Feng, Zhiquan Cao, Yuzhang Wu, Bei Li, Chenglong Wang, Tong Xiao, Kai Song, Tongran Liu, Chunliang Zhang, JingBo Zhu</p>

<p><strong>Automatic Instruction Evolving for Large Language Models</strong><br />Weihao Zeng, Can Xu, Yingxiu Zhao, Jian-Guang Lou, Weizhu Chen</p>

<p><strong>RepEval: Effective Text Evaluation with LLM Representation</strong><br />Shuqian Sheng, Yi Xu, Tianhang Zhang, Zanwei Shen, Luoyi Fu, Jiaxin Ding, Lei Zhou, Xiaoying Gan, Xinbing Wang, Chenghu Zhou</p>

<p><strong>Generative Models for Automatic Medical Decision Rule Extraction from Text</strong><br />Yuxin He, Buzhou Tang, Xiaoling Wang</p>

<p><strong>Encoding and Controlling Global Semantics for Long-form Video Question Answering</strong><br />Thong Thanh Nguyen, Zhiyuan Hu, Xiaobao Wu, Cong-Duy T Nguyen, See-Kiong Ng, Anh Tuan Luu</p>

<p><strong>Towards Understanding Jailbreak Attacks in LLMs: A Representation Space Analysis</strong><br />Yuping Lin, Pengfei He, Han Xu, Yue Xing, Makoto Yamada, Hui Liu, Jiliang Tang</p>

<p><strong>Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs</strong><br />Cheng Gao, Chaojun Xiao, Zhenghao Liu, Huimin Chen, Zhiyuan Liu, Maosong Sun</p>

<p><strong>Does Large Language Model Contain Task-Specific Neurons?</strong><br />Ran Song, Shizhu He, Shuting Jiang, Yantuan Xian, Shengxiang Gao, Kang Liu, Zhengtao Yu</p>

<p><strong>Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models</strong><br />Philipp Mondorf, Barbara Plank</p>

<p><strong>Advancing Test-Time Adaptation in Wild Acoustic Test Settings</strong><br />Hongfu Liu, Hengguan Huang, Ye Wang</p>

<p><strong>Learning to Retrieve Iteratively for In-Context Learning</strong><br />Yunmo Chen, Tongfei Chen, Harsh Jhamtani, Patrick Xia, Richard Shin, Jason Eisner, Benjamin Van Durme</p>

<p><strong>Taxonomy-guided Semantic Indexing for Academic Paper Search</strong><br />SeongKu Kang, Yunyi Zhang, Pengcheng Jiang, Dongha Lee, Jiawei Han, Hwanjo Yu</p>

<p><strong>Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts</strong><br />Xianzhen Luo, Qingfu Zhu, Zhiming Zhang, Libo Qin, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che</p>

<p><strong>Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models</strong><br />Hongfu Liu, Yuxi Xie, Ye Wang, Michael Shieh</p>

<p><strong>Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation</strong><br />Zhiyu Cao, PEIFENG LI, Yaxin FAN, Qiaoming Zhu</p>

<p><strong>FRoG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in LLMs</strong><br />Yiyuan Li, Shichao Sun, Pengfei Liu</p>

<p><strong>Aligning Large Language Models with Diverse Political Viewpoints</strong><br />Dominik Stammbach, Philine Widmer, Eunjung Cho, Caglar Gulcehre, Elliott Ash</p>

<p><strong>“You Gotta be a Doctor, Lin” : An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations</strong><br />Huy Nghiem, John Prindle, Jieyu Zhao, Hal Daumé III</p>

<p><strong>Extending Context Window of Large Language Models from a Distributional Perspective</strong><br />Yingsheng Wu, Yuxuan Gu, Xiaocheng Feng, Weihong Zhong, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin</p>

<p><strong>Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions</strong><br />Hakyung Sung, Kristopher Kyle</p>

<p><strong>MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration</strong><br />Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, See-Kiong Ng, Jiashi Feng</p>

<p><strong>Position Engineering: Boosting Large Language Models through Positional Information Manipulation</strong><br />Zhiyuan He, Huiqiang Jiang, Zilong Wang, Yuqing Yang, Luna K. Qiu, Lili Qiu</p>

<p><strong>Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale</strong><br />Junying Chen, Chi Gui, OuyangRuyi, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Zhenyang Cai, Ke Ji, Xiang Wan, Benyou Wang</p>

<p><strong>ADELIE: Aligning Large Language Models on Information Extraction</strong><br />Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li</p>

<p><strong>Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons</strong><br />Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun Zeng</p>

<p><strong>Lexically Grounded Subword Segmentation</strong><br />Jindřich Libovický, Jindřich Helcl</p>

<p><strong>EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees</strong><br />Yuhui Li, Fangyun Wei, Chao Zhang, Hongyang Zhang</p>

<p><strong>Do Text-to-Vis Benchmarks Test Real Use of Visualizations?</strong><br />Hy Nguyen, Xuefei He, Andrew Reeson, Cecile Paris, Josiah Poon, Jonathan K. Kummerfeld</p>

<p><strong>Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs</strong><br />Chengyuan Liu, Shihang Wang, Lizhi Qing, Kun Kuang, Yangyang Kang, Changlong Sun, Fei Wu</p>

<p><strong>Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning</strong><br />Jingyu Hu, Weiru Liu, Mengnan Du</p>

<p><strong>Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges</strong><br />Nguyen Van Dinh, Thanh Chi Dang, Luan Thanh Nguyen, Kiet Van Nguyen</p>

<p><strong>Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment</strong><br />Vyas Raina, Adian Liusie, Mark Gales</p>

<p><strong>Rethinking the Reversal Curse of LLMs: a Prescription from Human Knowledge Reversal</strong><br />Zhicong Lu, Li Jin, PeiguangLi, Yu Tian, Linhao Zhang, Sirui Wang, Guangluan Xu, Changyuan Tian, Xunliang Cai</p>

<p><strong>More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs</strong><br />Chengyuan Liu, Shihang Wang, Yangyang Kang, Lizhi Qing, Fubang Zhao, Chao Wu, Changlong Sun, Kun Kuang, Fei Wu</p>

<p><strong>Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models</strong><br />Vyas Raina, Rao Ma, Charles McGhee, Kate Knill, Mark Gales</p>

<p><strong>GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation</strong><br />Georgios Katsimpras, Georgios Paliouras</p>

<p><strong>XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs</strong><br />Zichen Chen, Jianda Chen, Ambuj Singh, Misha Sra</p>

<p><strong>Divide and Conquer Radiology Report Generation via Observation Level Fine-grained Pretraining and Prompt Tuning</strong><br />Yuanpin Zhou, Huogen Wang</p>

<p><strong>SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information</strong><br />Jiashuo Sun, Jihai Zhang, Yucheng Zhou, Zhaochen Su, Xiaoye Qu, Yu Cheng</p>

<p><strong>UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models</strong><br />Zhanyue Qin, Haochuan Wang, Deyuan Liu, Ziyang Song, Cunhang Fan, Zhao Lv, Jinlin Wu, Zhen Lei, Zhiying Tu, Dianhui Chu, Xiaoyan Yu, Dianbo Sui</p>

<p><strong>Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments</strong><br />Yu Gu, Yiheng Shu, Hao Yu, Xiao Liu, Yuxiao Dong, Jie Tang, Jayanth Srinivasa, Hugo Latapie, Yu Su</p>

<p><strong>MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space</strong><br />Yihong Tang, Bo Wang, Dongming Zhao, Jinxiaojia, Zhangjijun, Ruifang He, Yuexian Hou</p>

<p><strong>KnowledgeSG: Privacy-Preserving Synthetic Text Generation With Knowledge Distillation From Server</strong><br />WenHao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang</p>

<p><strong>DAMRO: Dive into the Attention Mechanism of LVLM to Reduce Object Hallucination</strong><br />Xuan Gong, Tianshi Ming, Xinpeng Wang, Zhihua Wei</p>

<p><strong>Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models</strong><br />Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao</p>

<p><strong>Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale</strong><br />Wenzhen Zheng, Wenbo Pan, Xu Xu, Libo Qin, Li Yue, Ming Zhou</p>

<p><strong>An Empirical Study of Multilingual Reasoning Distillation for Question Answering</strong><br />Patomporn Payoungkhamdee, Peerat Limkonchotiwat, Jinheon Baek, Potsawee Manakul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong</p>

<p><strong>Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?</strong><br />Gal Yona, Roee Aharoni, Mor Geva</p>

<p><strong>Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</strong><br />Zorik Gekhman, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, Jonathan Herzig</p>

<p><strong>Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning</strong><br />Ming Shan Hee, Aditi Kumaresan, Roy Ka-Wei Lee</p>

<p><strong>MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding</strong><br />Baixuan Xu, Weiqi Wang, Haochen Shi, Wenxuan Ding, Huihao JING, Tianqing Fang, Jiaxin Bai, Xin Liu, Changlong Yu, Zheng Li, Chen Luo, Qingyu Yin, Bing Yin, Long Chen, Yangqiu Song</p>

<p><strong>ECON: On the Detection and Resolution of Evidence Conflicts</strong><br />Cheng Jiayang, Qianqian Zhuang, Chunkit Chan, Lin Qiu, Tianhang Zhang, Tengxiao Liu, Yangqiu Song, Yue Zhang, Pengfei Liu, Zheng Zhang</p>

<p><strong>“Image, Tell me your story!” Predicting the original meta-context of visual misinformation</strong><br />Jonathan Tonglet, Marie-Francine Moens, Iryna Gurevych</p>

<p><strong>Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning</strong><br />Zhili Shen, Pavlos Vougiouklis, Chenxin Diao, Kaustubh Vyas, Yuanyi Ji, Jeff Z. Pan</p>

<p><strong>Mixture-of-Subspaces in Low-Rank Adaptation</strong><br />Taiqiang Wu, Jiahao Wang, Zhe Zhao, Ngai Wong</p>

<p><strong>A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data</strong><br />Ishaan Watts, Varun Gumma, Aditya Yadavalli, Vivek Seshadri, Manohar Swaminathan, Sunayana Sitaram</p>

<p><strong>LawBench: Benchmarking Legal Knowledge of Large Language Models</strong><br />Zhiwei Fei, Xiaoyu Shen, Dawei Zhu, Fengzhe Zhou, Zhuo Han, Alan Huang, Songyang Zhang, Kai Chen, Zhixin Yin, Zongwen Shen, Jidong Ge, Vincent Ng</p>

<p><strong>Efficient Performance Tracking: Leveraging Large Language Models for Automated Construction of Scientific Leaderboards</strong><br />Furkan Şahinuç, Thy Thy Tran, Yulia Grishina, Yufang Hou, Bei Chen, Iryna Gurevych</p>

<p><strong>Efficient Vision-Language pre-training via domain-specific learning for human activities</strong><br />Adrian Bulat, Yassine Ouali, Ricardo Guerrero, Brais Martinez, Georgios Tzimiropoulos</p>

<p><strong>Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training</strong><br />Wenbo Li, Guohao Li, Zhibin Lan, Xue Xu, Wanru Zhuang, Jiachen Liu, Xinyan Xiao, Jinsong Su</p>

<p><strong>Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works</strong><br />Xinfeng Yuan, Siyu Yuan, Yuhan Cui, Tianhe Lin, Xintao Wang, Rui Xu, Jiangjie Chen, Deqing Yang</p>

<p><strong>Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners</strong><br />Shimao Zhang, Changjiang Gao, Wenhao Zhu, Jiajun Chen, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Shujian Huang</p>

<p><strong>AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning</strong><br />Hao Sun, Jiayi Wu, Hengyi Cai, Xiaochi Wei, Yue Feng, Bo Wang, Shuaiqiang Wang, Yan Zhang, Dawei Yin</p>

<p><strong>CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models</strong><br />Zi Gong, Hang Yu, Cong Liao, Bingchang Liu, Chaoyu Chen, Jianguo Li</p>

<p><strong>mDPO: Conditional Preference Optimization for Multimodal Large Language Models</strong><br />Fei Wang, Wenxuan Zhou, James Y. Huang, Nan Xu, Sheng Zhang, Hoifung Poon, Muhao Chen</p>

<p><strong>Data Advisor: Data Curation with Foresight for Safety Alignment of Large Language Models</strong><br />Fei Wang, Ninareh Mehrabi, Palash Goyal, Rahul Gupta, Kai-Wei Chang, Aram Galstyan</p>

<p><strong>Language-to-Code Translation with a Single Labeled Example</strong><br />Kaj Bostrom, Harsh Jhamtani, Hao Fang, Sam Thomson, Richard Shin, Patrick Xia, Benjamin Van Durme, Jason Eisner, Jacob Andreas</p>

<p><strong>Attribute or Abstain: Large Language Models as Long Document Assistants</strong><br />Jan Buchmann, Xiao Liu, Iryna Gurevych</p>

<p><strong>FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models</strong><br />Xiaochen Wang, Jiaqi Wang, Houping Xiao, Jinghui Chen, Fenglong Ma</p>

<p><strong>Retrieved In-Context Principles from Previous Mistakes</strong><br />Hao Sun, Yong Jiang, Bo Wang, Yingyan Hou, Yan Zhang, Pengjun Xie, Fei Huang</p>

<p><strong>EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control</strong><br />Haozhe Chen, Run Chen, Julia Hirschberg</p>

<p><strong>VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models</strong><br />Yifei Liu, Jicheng Wen, Yang Wang, Shengyu Ye, Li Lyna Zhang, Ting Cao, Cheng Li, Mao Yang</p>

<p><strong>Deterministic Weighted L* Algorithm</strong><br />Clemente Pasti, Talu Karagöz, Franz Nowak, Anej Svete, Ryan Cotterell</p>

<p><strong>Towards Verifiable Text Generation with Evolving Memory and Self-Reflection</strong><br />Hao Sun, Hengyi Cai, Bo Wang, Yingyan Hou, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, Dawei Yin</p>

<p><strong>Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification</strong><br />Pritish Sahu, Karan Sikka, Ajay Divakaran</p>

<p><strong>Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes</strong><br />Yusuke Hirota, Jerone Andrews, Dora Zhao, Orestis Papakyriakopoulos, Apostolos Modas, Yuta Nakashima, Alice Xiang</p>

<p><strong>RealVul: Can We Detect Vulnerabilities in Web Applications with LLM?</strong><br />Di Cao, Yong Liao, Xiuwei Shang</p>

<p><strong>Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel</strong><br />Brendan King, Jeffrey Flanigan</p>

<p><strong>Humans or LLMs as the Judge? A Study on Judgement Bias</strong><br />Guiming Hardy Chen, Shunian Chen, Ziche Liu, Feng Jiang, Benyou Wang</p>

<p><strong>WPO: Enhancing RLHF with Weighted Preference Optimization</strong><br />Wenxuan Zhou, Ravi Agrawal, Shujian Zhang, Sathish Reddy Indurthi, Sanqiang Zhao, Kaiqiang Song, Silei Xu, Chenguang Zhu</p>

<p><strong>Walking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias</strong><br />Rongwu Xu, Zian Zhou, Tianwei Zhang, Zehan Qi, SU YAO, Ke Xu, Wei Xu, Han Qiu</p>

<p><strong>MetaReflection: Learning Instructions for Language Agents using Past Reflections</strong><br />Priyanshu Gupta, Shashank Kirtania, Ananya Singha, Sumit Gulwani, Arjun Radhakrishna, Gustavo Soares, Sherry Shi</p>

<p><strong>Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors</strong><br />Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan</p>

<p><strong>On Eliciting Syntax from Language Models via Hashing</strong><br />Yiran Wang, Masao Utiyama</p>

<p><strong>CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios</strong><br />Zetian Ouyang, Yishuai Qiu, Linlin Wang, Gerard de Melo, Ya Zhang, Yanfeng Wang, Liang He</p>

<p><strong>The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples</strong><br />Heng Yang</p>

<p><strong>CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages</strong><br />Pretam Ray, Jivnesh Sandhan, Amrith Krishna, Pawan Goyal</p>

<p><strong>Perceptions of Linguistic Uncertainty by Language Models and Humans</strong><br />Catarina G Belém, Markelle Kelly, Mark Steyvers, Sameer Singh, Padhraic Smyth</p>

<p><strong>Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM</strong><br />Haw-Shiuan Chang, Nanyun Peng, Mohit Bansal, Anil Ramakrishna, Tagyoung Chung</p>

<p><strong>Zero-shot Cross-domain Dialogue State Tracking via Context-aware Auto-prompting and Instruction-following Contrastive Decoding</strong><br />Xiaoyu DONG, Yujie Feng, ZEXIN LU, Guangyuan SHI, Xiao-Ming Wu</p>

<p><strong>Knowledge Conflicts for LLMs: A Survey</strong><br />Rongwu Xu, Zehan Qi, Zhijiang Guo, Cunxiang Wang, Hongru WANG, Yue Zhang, Wei Xu</p>

<p><strong>Generative AI in the Era of “Alternative Facts”</strong><br />Saadia Gabriel, Liang Lyu, James Siderius, Marzyeh Ghassemi, Jacob Andreas, Asuman E. Ozdaglar</p>

<p><strong>MEANT: Multimodal Encoder for Antecedent Information</strong><br />Benjamin Irving, Annika Marie Schoene</p>

<p><strong>A Thorough Examination of Decoding Methods in the Era of LLMs</strong><br />Chufan Shi, HAORAN YANG, Deng Cai, Zhisong Zhang, Yifan Wang, Yujiu Yang, Wai Lam</p>

<p><strong>AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings</strong><br />Revanth Gangi Reddy, Omar Attia, Yunyao Li, Heng Ji, Saloni Potdar</p>

<p><strong>FIRST: Faster Improved Listwise Reranking with Single Token Decoding</strong><br />Revanth Gangi Reddy, JaeHyeok Doo, Yifei Xu, Md Arafat Sultan, Deevya Swain, Avirup Sil, Heng Ji</p>

<p><strong>Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights</strong><br />Hongjin KIM, Jai-Eun Kim, Harksoo Kim</p>

<p><strong>ReCaLL: Membership Inference via Relative Conditional Log-Likelihoods</strong><br />Roy Xie, Junlin Wang, Ruomin Huang, Minxing Zhang, Rong Ge, Jian Pei, Neil Zhenqiang Gong, Bhuwan Dhingra</p>

<p><strong>“Flex Tape Can’t Fix That”: Bias and Misinformation in Edited Language Models</strong><br />Karina H Halevy, Anna Sotnikova, Badr AlKhamissi, Syrielle Montariol, Antoine Bosselut</p>

<p><strong>Revisiting Who’s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective</strong><br />Yujian Liu, Yang Zhang, Tommi Jaakkola, Shiyu Chang</p>

<p><strong>LIONs: An Empirically Optimized Approach to Align Language Models</strong><br />Xiao Yu, Qingyang Wu, Yu Li, Zhou Yu</p>

<p><strong>Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing</strong><br />Haochen Zhang, Yuyang Dong, Chuan Xiao, Masafumi Oyamada</p>

<p><strong>A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery</strong><br />Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shuiwang Ji, Wei Wang, Jiawei Han</p>

<p><strong>MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents</strong><br />Liyan Tang, Philippe Laban, Greg Durrett</p>

<p><strong>Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning</strong><br />John Wu, David Wu, Jimeng Sun</p>

<p><strong>MOSEL: Inference Serving Using Dynamic Modality Selection</strong><br />Bodun Hu, Le Xu, Jeongyoon Moon, Neeraja J Yadwadkar, Aditya Akella</p>

<p><strong>From RAG to Riches: Retrieval Interlaced with Sequence Generation</strong><br />Palak Jain, Livio Baldini Soares, Tom Kwiatkowski</p>

<p><strong>Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition</strong><br />Hsuan Su, Hua Farn, Fan-Yun Sun, Shang-Tse Chen, Hung-yi Lee</p>

<p><strong>Learning to Correct for QA Reasoning with Black-box LLMs</strong><br />Jaehyung Kim, Dongyoung Kim, Yiming Yang</p>

<p><strong>AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?</strong><br />Ori Yoran, Samuel Joseph Amouyal, Chaitanya Malaviya, Ben Bogin, Ofir Press, Jonathan Berant</p>

<p><strong>PostMark: A Robust Blackbox Watermark for Large Language Models</strong><br />Yapei Chang, Kalpesh Krishna, Amir Houmansadr, John Frederick Wieting, Mohit Iyyer</p>

<p><strong>Assessing “Implicit” Retrieval Robustness of Large Language Models</strong><br />Xiaoyu Shen, Rexhina Blloshmi, Dawei Zhu, Jiahuan Pei, Wei Zhang</p>

<p><strong>On the Relationship between Truth and Political Bias in Language Models</strong><br />Suyash Fulay, William Brannon, Shrestha Mohanty, Cassandra Overney, Elinor Poole-Dayan, Deb Roy, Jad Kabbara</p>

<p><strong>Can Active Label Correction Improve LLM-based Modular AI Systems?</strong><br />Karan Taneja, Ashok Goel</p>

<p><strong>Statistical Uncertainty in Word Embeddings: GloVe-V</strong><br />Andrea Vallebueno, Cassandra Handan-Nader, Christopher D Manning, Daniel E. Ho</p>

<p><strong>Annotation alignment: Comparing LLM and human annotations of conversational safety</strong><br />Rajiv Movva, Pang Wei Koh, Emma Pierson</p>

<p><strong>DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions</strong><br />Nigel Fernandez, Alexander Scarlatos, Digory Smith, Simon Woodhead, Nancy Otero Ornelas, Andrew Lan</p>

<p><strong>The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention</strong><br />Yixin Wan, Di Wu, Haoran Wang, Kai-Wei Chang</p>

<p><strong>CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models</strong><br />Yuetai Li, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Dinuka Sahabandu, Bhaskar Ramasubramanian, Radha Poovendran</p>

<p><strong>Enhancing Reinforcement Learning with Intrinsic Rewards from Language Model Critique</strong><br />Meng Cao, Lei Shu, Lei Yu, Yun Zhu, Nevan Wichers, Yinxiao Liu, Lei Meng</p>

<p><strong>Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models</strong><br />Layla Bouzoubaa, Elham Aghakhani, Shadi Rezapour</p>

<p><strong>Efficient Sequential Decision Making with Large Language Models</strong><br />Dingyang Chen, Qi Zhang, Yinglun Zhu</p>

<p><strong>SignCLIP: Connecting Text and Sign Language by Contrastive Learning</strong><br />Zifan Jiang, Gerard Sant, Amit Moryossef, Mathias Müller, Rico Sennrich, Sarah Ebling</p>

<p><strong>APPLS: Evaluating Evaluation Metrics for Plain Language Summarization</strong><br />Yue Guo, Tal August, Gondy Leroy, Trevor Cohen, Lucy Lu Wang</p>

<p><strong>Ontologically Faithful Generation of Non-Player Character Dialogues</strong><br />Nathaniel Weir, Ryan Thomas, Randolph d’Amore, Kellie Hill, Benjamin Van Durme, Harsh Jhamtani</p>

<p><strong>LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives</strong><br />Luísa Shimabucoro, Sebastian Ruder, Julia Kreutzer, Marzieh Fadaee, Sara Hooker</p>

<p><strong>RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs</strong><br />Ekaterina Taktasheva, Maxim Bazhukov, Kirill Koncha, Alena Fenogenova, Ekaterina Artemova, Vladislav Mikhailov</p>

<p><strong>Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction</strong><br />Zheye Deng, Chunkit Chan, Weiqi Wang, Yuxi Sun, Wei Fan, Tianshi Zheng, Yauwai Yim, Yangqiu Song</p>

<p><strong>Toward Compositional Behavior in Neural Models: A Survey of Current Views</strong><br />Kate McCurdy, Paul Soulos, Paul Smolensky</p>

<p><strong>Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs</strong><br />Krista Opsahl-Ong, Michael J Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, Omar Khattab</p>

<p><strong>Reverse-Engineering the Reader</strong><br />Samuel Kiegeland, Ethan Wilcox, Afra Amini, David Robert Reich, Ryan Cotterell</p>

<p><strong>Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation</strong><br />Di Wu, Jia-Chen Gu, Fan Yin, Nanyun Peng, Kai-Wei Chang</p>

<p><strong>Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text</strong><br />Kewei Cheng, Nesreen K. Ahmed, Theodore L. Willke, Yizhou Sun</p>

<p><strong>Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning</strong><br />David Schulte, Felix Hamborg, Alan Akbik</p>

<p><strong>The effects of distance on NPI illusive effects in BERT</strong><br />So Young Lee, Mai Ha Vu</p>

<p><strong>Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic</strong><br />Nathaniel Weir, Kate Sanders, Orion Weller, Shreya Sharma, Dongwei Jiang, Zhengping Jiang, Bhavana Dalvi Mishra, Oyvind Tafjord, Peter Jansen, Peter Clark, Benjamin Van Durme</p>

<p><strong>Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the US</strong><br />Christabel Acquaye, Haozhe An, Rachel Rudinger</p>

<p><strong>Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding</strong><br />Yue Fan, Lei Ding, Ching-Chen Kuo, Shan Jiang, Yang Zhao, Xinze Guan, Jie Yang, Yi Zhang, Xin Eric Wang</p>

<p><strong>Ranking Manipulation for Conversational Search Engines</strong><br />Samuel Pfrommer, Yatong Bai, Tanmay Gautam, Somayeh Sojoudi</p>

<p><strong>Fast Forwarding Low-Rank Training</strong><br />Adir Rahamim, Naomi Saphra, Sara Kangaslahti, Yonatan Belinkov</p>

<p><strong>Precise Model Benchmarking with Only a Few Observations</strong><br />Riccardo Fogliato, Pratik Patil, Nil-Jana Akpinar, Mathew Monfort</p>

<p><strong>Attribute Diversity Determines the Systematicity Gap in VQA</strong><br />Ian Berlot-Attwell, Kumar Krishna Agrawal, Annabelle Michael Carrell, Yash Sharma, Naomi Saphra</p>

<p><strong>“Rows, Columns and Values, Oh My!” Synthesizing Scientific Literature into Tables using Language Models</strong><br />Benjamin Newman, Yoonjoo Lee, Aakanksha Naik, Pao Siangliulue, Raymond Fok, Juho Kim, Daniel S Weld, Joseph Chee Chang, Kyle Lo</p>

<p><strong>Development of Cognitive Intelligence in Pre-trained Language Models</strong><br />Raj Sanjay Shah, Khushi Bhardwaj, Sashank Varma</p>

<p><strong>Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding</strong><br />Chong Zhang, Yi Tu, Yixi Zhao, Chenshu Yuan, Huan Chen, Yue Zhang, Mingxu Chai, Ya Guo, Huijia Zhu, Qi Zhang, Tao Gui</p>

<p><strong>Birdie: Advancing State Space Models with a Minimalist Architecture and Novel Pre-training Objectives</strong><br />Sam Blouir, Jimmy T.H. Smith, Antonios Anastasopoulos, Amarda Shehu</p>

<p><strong>Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?</strong><br />Pinzhen Chen, Simon Yu, Zhicheng Guo, Barry Haddow</p>

<p><strong>Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs</strong><br />Sheridan Feucht, David Atkinson, Byron C Wallace, David Bau</p>

<p><strong>TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering</strong><br />Chuyi Shang, Amos You, Sanjay Subramanian, Trevor Darrell, Roei Herzig</p>

<p><strong>Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding</strong><br />Biswesh Mohapatra, Manav Nitin Kapadnis, Laurent Romary, Justine Cassell</p>

<p><strong>Unlocking Memorization in Large Language Models with Dynamic Soft Prompting</strong><br />Zhepeng Wang, Runxue Bao, Yawen Wu, Jackson Taylor, Cao Xiao, Feng Zheng, Weiwen Jiang, Shangqian Gao, Yanfu Zhang</p>

<p><strong>If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions</strong><br />Reza Esfandiarpoor, Cristina Menghini, Stephen Bach</p>

<p><strong>Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction</strong><br />Bowen Zhang, Harold Soh</p>

<p><strong>MQuinE: a Cure for “Z-paradox” in Knowledge Graph Embedding</strong><br />Yang Liu, Huang Fang, Yunfeng Cai, Mingming Sun</p>

<p><strong>Can Transformer Language Models Learn $n$-gram Language Models?</strong><br />Anej Svete, Nadav Borenstein, Mike Zhou, Ryan Cotterell</p>

<p><strong>StablePrompt : Automatic Prompt Tuning using Reinforcement Learning for Large Language Model</strong><br />Minchan Kwon, Gaeun Kim, Jongsuk Kim, Haeil Lee, Junmo Kim</p>

<p><strong>Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems</strong><br />Philippe Laban, Alexander Fabbri, Caiming Xiong, Chien-Sheng Wu</p>

<p><strong>Multi-pass Decoding for Grammatical Error Correction</strong><br />Xiaoying Wang, Lingling Mu, Jingyi Zhang, Hongfei Xu</p>

<p><strong>Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations</strong><br />Yucheng Jiang, Yijia Shao, Dekun Ma, Sina Semnani, Monica Lam</p>

<p><strong>SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation</strong><br />Chenming Tang, Zhixiang Wang, Yunfang Wu</p>

<p><strong>Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge</strong><br />Yuxuan Wang, Yueqian Wang, Pengfei Wu, Jianxin Liang, Dongyan Zhao, Yang Liu, Zilong Zheng</p>

<p><strong>STORYSUMM: Evaluating Faithfulness in Story Summarization</strong><br />Melanie Subbiah, Faisal Ladhak, Akankshya Mishra, Griffin Thomas Adams, Lydia Chilton, Kathleen McKeown</p>

<p><strong>MMOE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts</strong><br />Haofei Yu, Zhengyang Qi, Lawrence Keunho Jang, Russ Salakhutdinov, Louis-Philippe Morency, Paul Pu Liang</p>

<p><strong>OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer</strong><br />Lu Zhang, Tiancheng Zhao, Heting Ying, Yibo Ma, Kyusong Lee</p>

<p><strong>Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension</strong><br />Lin Ai, Zheng Hui, Zizhou Liu, Julia Hirschberg</p>

<p><strong>CommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions</strong><br />Jun Rao, Xuebo Liu, Lian Lian, shengjun cheng, Yunjie Liao, Min Zhang</p>

<p><strong>ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers</strong><br />Yuzhe Gu, Enmao Diao</p>

<p><strong>Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models</strong><br />Jaeseong Lee, seung-won hwang, Wonpyo Park, Mingi Ji</p>

<p><strong>Detecting Subtle Differences between Human and Model Languages Using Spectrum of Relative Likelihood</strong><br />Yang Xu, Yu Wang, Hao An, Yongyuan Li, Zhichen Liu</p>

<p><strong>Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning</strong><br />Jiahui Li, Hanlin Zhang, Fengda Zhang, Tai-Wei Chang, Kun Kuang, Long Chen, JUN ZHOU</p>

<p><strong>Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models</strong><br />XiaoHua Feng, Chaochao Chen, Yuyuan Li, Zibin Lin</p>

<p><strong>ARM: An Alignment-and-Replacement Module for Chinese Spelling Check Based on LLMs</strong><br />Changchun Liu, Kai Zhang, Junzhe Jiang, Zirui Liu, Hanqing Tao, Min Gao, Enhong Chen</p>

<p><strong>On the In-context Generation of Language Models</strong><br />Zhongtao Jiang, Yuanzhe Zhang, Kun Luo, Xiaowei Yuan, Jun Zhao, Kang Liu</p>

<p><strong>Atomic Inference for NLI with Generated Facts as Atoms</strong><br />Joe Stacey, Pasquale Minervini, Haim Dubossarsky, Oana-Maria Camburu, Marek Rei</p>

<p><strong>Towards Robust Speech Representation Learning for Thousands of Languages</strong><br />William Chen, Wangyou Zhang, Yifan Peng, Xinjian Li, Jinchuan Tian, Jiatong Shi, Xuankai Chang, Soumi Maiti, Karen Livescu, Shinji Watanabe</p>

<p><strong>I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses</strong><br />Xuan Ren, Biao Wu, Lingqiao Liu</p>

<p><strong>PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment</strong><br />Jiahuan Li, Shujian Huang, Aarron Ching, Xinyu Dai, Jiajun Chen</p>

<p><strong>An image speaks a thousand words, but can everyone listen? On image transcreation for cultural relevance</strong><br />Simran Khanuja, Sathyanarayanan Ramamoorthy, Yueqi Song, Graham Neubig</p>

<p><strong>When Parts are Greater Than Sums: Individual LLM Components Can Outperform Full Models</strong><br />Ting-Yun Chang, Jesse Thomason, Robin Jia</p>

<p><strong>Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference</strong><br />Jianxing Yu, Shiqi Wang, Han Yin, Zhenlong Sun, Ruobing Xie, Bo zhang, Yanghui Rao</p>

<p><strong>Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions</strong><br />Jinsung Yoon, Rajarishi Sinha, Sercan O Arik, Tomas Pfister</p>

<p><strong>KNN-Instruct: Automatic Instruction Construction with K Nearest Neighbor Deduction</strong><br />Jianshang Kou, Benfeng Xu, Chiwei Zhu, Zhendong Mao</p>

<p><strong>Contextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation</strong><br />Zhen Lin, Shubhendu Trivedi, Jimeng Sun</p>

<p><strong>$\texttt{MixGR}$: Enhancing Retriever Generalization for Scientific Domain through Complementary Granularity</strong><br />Fengyu Cai, Xinran Zhao, Tong Chen, Sihao Chen, Hongming Zhang, Iryna Gurevych, Heinz Koeppl</p>

<p><strong>CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction</strong><br />Tuan Dung Nguyen, Thanh Trung Huynh, Minh Hieu Phan, Quoc Viet Hung Nguyen, Phi Le Nguyen</p>

<p><strong>“In-Dialogues We Learn”: Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning</strong><br />Chuanqi Cheng, Quan Tu, Wei Wu, Shuo Shang, Cunli Mao, Zhengtao Yu, Rui Yan</p>

<p><strong>Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective</strong><br />Hanqi Yan, Yanzheng Xiang, Guangyi Chen, Yifei Wang, Lin Gui, Yulan He</p>

<p><strong>Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding</strong><br />Xin Liu, Farima Fatahi Bayat, Lu Wang</p>

<p><strong>Reasoning Robustness of LLMs to Adversarial Typographical Errors</strong><br />Esther Gan, Yiran Zhao, Liying Cheng, Mao Yancan, Anirudh Goyal, Kenji Kawaguchi, Min-Yen Kan, Michael Shieh</p>

<p><strong>InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance</strong><br />Pengyu Wang, Dong Zhang, Linyang Li, Chenkun Tan, Xinghao Wang, Mozhi Zhang, Ke Ren, Botian Jiang, Xipeng Qiu</p>

<p><strong>Belief Revision: The Adaptability of Large Language Models Reasoning</strong><br />Bryan Wilie, Samuel Cahyawijaya, Etsuko Ishii, Junxian He, Pascale Fung</p>

<p><strong>Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models</strong><br />Ji Liu, Jiaxiang Ren, Ruoming Jin, Zijie Zhang, Yang Zhou, Patrick Valduriez, Dejing Dou</p>

<p><strong>Bio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints</strong><br />Minjia Wang, Fangzhou Liu, Xiuxing Li, Bowen Dong, Zhenyu Li, Tengyu Pan, Jianyong Wang</p>

<p><strong>Decoding Matters: Addressing Amplification Bias and Homogeneity Issue in Recommendations for Large Language Models</strong><br />Keqin Bao, Jizhi Zhang, Yang Zhang, Xinyue Huo, Chong Chen, Fuli Feng</p>

<p><strong>LLMs Are Prone to Fallacies in Causal Inference</strong><br />Nitish Joshi, Abulhair Saparov, Yixin Wang, He He</p>

<p><strong>Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles</strong><br />Ryan Louie, Ananjan Nandi, William Fang, Cheng Chang, Emma Brunskill, Diyi Yang</p>

<p><strong>The Lou Dataset - Exploring the Impact of Gender-Fair Language in German Text Classification</strong><br />Andreas Waldis, Joel Birrer, Anne Lauscher, Iryna Gurevych</p>

<p><strong>When Generative Adversarial Networks Meet Sequence Labeling Challenges</strong><br />Yu Tong, Ge Chen, Guokai Zheng, Rui Li, Jiang Dazhi</p>

<p><strong>Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering</strong><br />Sungho Ko, Hyunjin Cho, Hyungjoo Chae, Jinyoung Yeo, Dongha Lee</p>

<p><strong>Speechworthy Instruction-tuned Language Models</strong><br />Hyundong Justin Cho, Nicolaas Paul Jedema, Leonardo F. R. Ribeiro, Karishma Sharma, Pedro Szekely, Alessandro Moschitti, Ruben Janssen, Jonathan May</p>

<p><strong>Data, Data Everywhere: A Guide for Pretraining Dataset Construction</strong><br />Jupinder Parmar, Shrimai Prabhumoye, Joseph Jennings, Bo Liu, Aastha Jhunjhunwala, Zhilin Wang, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro</p>

<p><strong>Fine-Tuning and Prompt Optimization: Two Good Steps that Work Better Together</strong><br />Dilara Soylu, Christopher Potts, Omar Khattab</p>

<p><strong>Demystifying Verbatim Memorization in Large Language Models</strong><br />Jing Huang, Diyi Yang, Christopher Potts</p>

<p><strong>AmbigNLG: Addressing Task Ambiguity in Instruction for NLG</strong><br />Ayana Niwa, Hayate Iso</p>

<p><strong>Distributional Properties of Subword Regularization</strong><br />Marco Cognetta, Vilém Zouhar, Naoaki Okazaki</p>

<p><strong>DataTales: A Benchmark for Real-World Intelligent Data Narration</strong><br />Yajing Yang, Qian Liu, Min-Yen Kan</p>

<p><strong>Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters</strong><br />Euiin Yi, Taehyeon Kim, Hongseok Jeung, Du-Seong Chang, Se-Young Yun</p>

<p><strong>GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization</strong><br />Yangfan Ye, Xiachong Feng, Xiaocheng Feng, Weitao Ma, Libo Qin, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin</p>

<p><strong>Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models</strong><br />Terra Blevins, Tomasz Limisiewicz, Suchin Gururangan, Margaret Li, Hila Gonen, Noah A. Smith, Luke Zettlemoyer</p>

<p><strong>More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation</strong><br />Wencke Liermann, Jin-Xia Huang, Yohan Lee, Kong Joo Lee</p>

<p><strong>Stable Language Model Pre-training by Reducing Embedding Variability</strong><br />Woojin Chung, Jiwoo Hong, Na Min An, James Thorne, Se-Young Yun</p>

<p><strong>What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations</strong><br />Kavya Manohar, Leena G Pillai</p>

<p><strong>Diversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets</strong><br />Benjamin Schiller, Johannes Daxenberger, Andreas Waldis, Iryna Gurevych</p>

<p><strong>Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas</strong><br />Seungjong Sun, Eungu Lee, Seo Yeon Baek, Seunghyun Hwang, Lee wonbyung, Dongyan Nan, Bernard J Jansen, Jang Hyun Kim</p>

<p><strong>ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented Generator</strong><br />Junda Zhu, Lingyong Yan, Haibo Shi, Dawei Yin, Lei Sha</p>

<p><strong>Dynamic Multi-granularity Attribution Network for Aspect-based Sentiment Analysis</strong><br />Yanjiang Chen, Kai Zhang, hufeng, Xianquan Wang, Ruikang li, Qi Liu</p>

<p><strong>Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization</strong><br />Shahed Masoudian, Markus Frohmann, Navid Rekabsaz, Markus Schedl</p>

<p><strong>Large Language Models Know What is Key Visual Entity: An LLM-assisted Multimodal Retrieval for VQA</strong><br />Pu Jian, Donglei Yu, Jiajun Zhang</p>

<p><strong>Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights</strong><br />Hao Yang, Lizhen Qu, Ehsan Shareghi, Reza Haf</p>

<p><strong>Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations</strong><br />Milan BHAN, Jean-Noël Vittaut, Nicolas CHESNEAU, Marie-Jeanne Lesot</p>

<p><strong>What are the Generator Preferences for End-to-end Task-Oriented Dialog System?</strong><br />Wanshi Xu, Xianwei Zhuang, Zhanpeng Chen, Zhihong Zhu, Xuxin Cheng, Yuexian Zou</p>

<p><strong>Paraphrase Types Elicit Prompt Engineering Capabilities</strong><br />Jan Philip Wahle, Terry Ruas, Yang Xu, Bela Gipp</p>

<p><strong>VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models</strong><br />Jingtao Cao, Zhang Zheng, Hongru WANG, Kam-Fai Wong</p>

<p><strong>Towards Online Continuous Sign Language Recognition and Translation</strong><br />Ronglai Zuo, Fangyun Wei, Brian Mak</p>

<p><strong>Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment</strong><br />Yiwei Dai, Hengrui Gu, Ying Wang, Xin Wang</p>

<p><strong>Split and Merge: Aligning Position Biases in LLM-based Evaluators</strong><br />Zongjie Li, Chaozheng Wang, Pingchuan Ma, Daoyuan Wu, Shuai Wang, Cuiyun Gao, Yang Liu</p>

<p><strong>Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation</strong><br />Sougata Saha, Rohini Srihari</p>

<p><strong>BPO: Supercharging Online Preference Learning by Adhering to the Proximity of Behavior LLM</strong><br />Wenda Xu, Jiachen Li, William Yang Wang, Lei Li</p>

<p><strong>One2Set + Large Language Model: Best Partners for Keyphrase Generation</strong><br />Liangying Shao, Liang Zhang, Minlong Peng, Guoqi Ma, Hao Yue, Mingming Sun, Jinsong Su</p>

<p><strong>Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering</strong><br />Yifei Yuan, Yang Deng, Anders Søgaard, Mohammad Aliannejadi</p>

<p><strong>ORPO: Monolithic Preference Optimization without Reference Model</strong><br />Jiwoo Hong, Noah Lee, James Thorne</p>

<p><strong>A Multi-Perspective Analysis of Memorization in Large Language Models</strong><br />Bowen Chen, Namgi Han, Yusuke Miyao</p>

<p><strong>Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations</strong><br />Nicolò Penzo, Maryam Sajedinia, Bruno Lepri, Sara Tonelli, Marco Guerini</p>

<p><strong>Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs</strong><br />Haritz Puerto, Martin Tutek, Somak Aditya, Xiaodan Zhu, Iryna Gurevych</p>

<p><strong>Unveiling the Role of Pretraining in Direct Speech Translation</strong><br />Belen Alastruey, Gerard I. Gállego, Marta R. Costa-jussà</p>

<p><strong>PCQPR: Proactive Conversational Question Planning with Reflection</strong><br />Shasha Guo</p>

<p><strong>CodeAgent: Autonomous Communicative Agents for Code Review</strong><br />Xunzhu Tang, KISUB KIM, Yewei Song, Cedric Lothritz, Bei Li, Saad Ezzini, Haoye Tian, Jacques Klein, Tegawendé F. Bissyandé</p>

<p><strong>TroL: Traversal of Layers for Large Language and Vision Models</strong><br />Byung-Kwan Lee, Sangyun Chung, Chae Won Kim, Beomchan Park, Yong Man Ro</p>

<p><strong>MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language</strong><br />Shun Wang, Ge Zhang, Han Wu, Tyler Loakman, Wenhao Huang, Chenghua Lin</p>

<p><strong>Revisiting Supertagging for faster HPSG parsing</strong><br />Olga Zamaraeva, Carlos Gómez-Rodríguez</p>

<p><strong>Improve Dense Passage Retrieval with Entailment Tuning</strong><br />Lu Dai, Hao Liu, Hui Xiong</p>

<p><strong>ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models</strong><br />Yuxiang Zhang, Jing Chen, Junjie Wang, Yaxin Liu, Cheng Yang, Chufan Shi, Xinyu Zhu, Zihao Lin, Hanwen WAN, Yujiu Yang, Tetsuya Sakai, Tian Feng, Hayato Yamana</p>

<p><strong>TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models</strong><br />Rodolfo Zevallos, Núria Bel, Mireia Farrús</p>

<p><strong>DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting</strong><br />Xuanming Zhang, Anthony Diaz, Zixun Chen, Qingyang Wu, Kun Qian, Erik Voss, Zhou Yu</p>

<p><strong>Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback</strong><br />Fatemeh Pesaran zadeh, Juyeon Kim, Jin-Hwa Kim, Gunhee Kim</p>

<p><strong>PrExMe: Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation</strong><br />Christoph Leiter, Steffen Eger</p>

<p><strong>Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning</strong><br />Shuai Zhao, Meihuizi Jia, Anh Tuan Luu, Fengjun Pan, Jinming Wen</p>

<p><strong>Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models</strong><br />Javier Chiyah-Garcia, Alessandro Suglia, Arash Eshghi</p>

<p><strong>Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models</strong><br />Xinrong Zhang, Yingfa Chen, Shengding Hu, Xu Han, Zihang Xu, Yuanwei Xu, Weilin Zhao, Maosong Sun, Zhiyuan Liu</p>

<p><strong>Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations</strong><br />Matthias Lindemann, Alexander Koller, Ivan Titov</p>

<p><strong>Puzzle Solving using Reasoning of Large Language Models: A Survey</strong><br />Panagiotis Giadikiaroglou, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou</p>

<p><strong>SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading</strong><br />Tu Anh Dinh, Carlos Mullov, Leonard Bärmann, Zhaolin Li, Danni Liu, Simon Reiß, Jueun Lee, Nathan Lerzer, Jianfeng Gao, Fabian Peller-Konrad, Alexander Waibel, Tamim Asfour, Michael Beigl, Rainer Stiefelhagen, Carsten Dachsbacher, Klemens Böhm, Jan Niehues</p>

<p><strong>Red Teaming Language Models for Processing Contradictory Dialogues</strong><br />Xiaofei Wen, Bangzheng Li, Tenghao Huang, Muhao Chen</p>

<p><strong>Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models</strong><br />Sander Land, Max Bartolo</p>

<p><strong>Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs</strong><br />Houman Mehrafarin, Arash Eshghi, Ioannis Konstas</p>

<p><strong>Don’t Underestimate the Octopus - Why The Symbol Grounding Problem Does Not Apply to LLMs</strong><br />Reto Gubelmann</p>

<p><strong>Major Entity Identification: A Generalizable Alternative to Coreference Resolution</strong><br />Kawshik Manikantan, Shubham Toshniwal, Makarand Tapaswi, Vineet Gandhi</p>

<p><strong>Enhancing High-order Interaction Awareness in LLM-based Recommender Model</strong><br />Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki</p>

<p><strong>What Are the Odds? Language Models Are Capable of Probabilistic Reasoning</strong><br />Akshay Paruchuri, Jake Garrison, shun liao, John B Hernandez, Jacob Sunshine, Tim Althoff, Xin Liu, Daniel McDuff</p>

<p><strong>MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction</strong><br />Han Jiang, Junwen Duan, Zhe Qu, Jianxin Wang</p>

<p><strong>LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models</strong><br />Hayder Elesedy, Pedro M Esperanca, Silviu Vlad Oprea, Mete Ozay</p>

<p><strong>“A good pun is its own reword”: Can Large Language Models Understand Puns?</strong><br />Zhijun Xu, Siyu Yuan, Lingjie Chen, Deqing Yang</p>

<p><strong>QGEval: Benchmarking Multi-dimensional Evaluation for Question Generation</strong><br />Weiping Fu, Bifan Wei, Jianxiang Hu, Zhongmin Cai, Jun Liu</p>

<p><strong>Dependency Graph Parsing as Sequence Labeling</strong><br />Ana Ezquerro, David Vilares, Carlos Gómez-Rodríguez</p>

<p><strong>NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data</strong><br />Sergei Bogdanov, Alexandre Constantin, Timothée Bernard, Benoit Crabbé, Etienne P Bernard</p>

<p><strong>Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs</strong><br />John Pavlopoulos, Panos Louridas, Panagiotis Filos</p>

<p><strong>Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications</strong><br />Weize Liu, Yinlong Xu, Hongxia Xu, Jintai Chen, Xuming Hu, Jian Wu</p>

<p><strong>Advancing Semantic Textual Similarity Modeling: A Regression Framework with Translated ReLU and Smooth K2 Loss</strong><br />Bowen Zhang, Chunping Li</p>

<p><strong>Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training</strong><br />Marc Felix Brinner, Sina Zarrieß</p>

<p><strong>Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation</strong><br />Markus Frohmann, Igor Sterner, Ivan Vulić, Benjamin Minixhofer, Markus Schedl</p>

<p><strong>Applying Contrastive Learning to Code Vulnerability Type Classification</strong><br />Chen Ji, Su Yang, Hongyu Sun, Yuqing Zhang</p>

<p><strong>TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts</strong><br />Ruida WANG, Jipeng Zhang, Yizhen Jia, Rui Pan, Shizhe Diao, Renjie Pi, Tong Zhang</p>

<p><strong>Multi-Level Cross-Modal Alignment for Speech Relation Extraction</strong><br />Liang Zhang, Zhen Yang, Biao Fu, Ziyao Lu, Liangying Shao, Shiyu Liu, Fandong Meng, Jie Zhou, Xiaoli Wang, Jinsong Su</p>

<p><strong>Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models</strong><br />Christopher Schröder, Gerhard Heyer</p>

<p><strong>PANDA: Persona Attributes Navigation for Detecting and Alleviating Overuse Problem in Large Language Models</strong><br />Jinsung Kim, Seonmin Koo, Heuiseok Lim</p>

<p><strong>The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm</strong><br />Aakanksha, Arash Ahmadian, Beyza Ermis, Seraphina Goldfarb-Tarrant, Julia Kreutzer, Marzieh Fadaee, Sara Hooker</p>

<p><strong>Subword Segmentation in LLMs: Looking at Inflection and Consistency</strong><br />Marion Di Marco, Alexander Fraser</p>

<p><strong>Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments</strong><br />Omar Sharif, Joseph Gatto, MADHUSUDAN BASAK, Sarah Masud Preum</p>

<p><strong>Let Me Teach You: Pedagogical Foundations of Feedback for Language Models</strong><br />Beatriz Borges, Niket Tandon, Tanja Käser, Antoine Bosselut</p>

<p><strong>Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data</strong><br />Jean-Flavien Bussotti, Luca Ragazzi, Giacomo Frisoni, Gianluca Moro, Paolo Papotti</p>

<p><strong>TL-CL: Task And Language Incremental Continual Learning</strong><br />Shrey Satapara, P. K. Srijith</p>

<p><strong>Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?</strong><br />Daniel P Jeong, Saurabh Garg, Zachary Chase Lipton, Michael Oberst</p>

<p><strong>Empowering Multi-step Reasoning across Languages via Program-Aided Language Models</strong><br />Leonardo Ranaldi, Giulia Pucci</p>

<p><strong>Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models</strong><br />Yu Yuan, Lili Zhao, Kai Zhang, Guangting Zheng, Qi Liu</p>

<p><strong>ControlMath: Controllable Data Generation Promotes Math Generalist Models</strong><br />Nuo Chen, Ning Wu, Jianhui Chang, MING GONG, Linjun Shou, Dongmei Zhang, Jia Li</p>

<p><strong>Where Am I From? Identifying Origin of LLM-generated Content</strong><br />Liying LI, Yihan Bai, Minhao Cheng</p>

<p><strong>ReadMe++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment</strong><br />Tarek Naous, Michael J Ryan, Anton Lavrouk, Mohit Chandra, Wei Xu</p>

<p><strong>GlossLM: A Massively Multilingual Corpus and Pretrained Model for Interlinear Glossed Text</strong><br />Michael Ginn, Lindia Tjuatja, Taiqi He, Enora Rice, Graham Neubig, Alexis Palmer, Lori Levin</p>

<p><strong>GDTB: Genre Diverse Data for English Shallow Discourse Parsing across Modalities, Text Types, and Domains</strong><br />Yang Janet Liu, Tatsuya Aoyama, Wesley Scivetti, Yilun Zhu, Shabnam Behzad, Lauren Elizabeth Levine, Jessica Lin, Devika Tiwari, Amir Zeldes</p>

<p><strong>RA2FD: Distilling Faithfulness into Efficient Dialogue Systems</strong><br />Zhiyuan Zhu, Yusheng Liao, Chenxin Xu, Yunfeng Guan, Yanfeng Wang, Yu Wang</p>

<p><strong>Subjective Topic meets LLMs: Unleashing Comprehensive, Reflective and Creative Thinking through the Negation of Negation</strong><br />Fangrui Lv, Kaixiong Gong, Jian Liang, Xinyu Pang, Changshui Zhang</p>

<p><strong>Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently</strong><br />Kanishka Misra, Allyson Ettinger, Kyle Mahowald</p>

<p><strong>Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking</strong><br />Jun Bai, Zhuofan Chen, Zhenzi Li, Hanhua Hong, Jianfei Zhang, Chen Li, Chenghua Lin, Wenge Rong</p>

<p><strong>A Coordinate System for In-Context Learning</strong><br />Anhao Zhao, Fanghua Ye, Jinlan Fu, Xiaoyu Shen</p>

<p><strong>Self-Powered LLM Modality Expansion for Large Speech-Text Models</strong><br />Tengfei Yu, Xuebo Liu, Zhiyi Hou, Liang Ding, Dacheng Tao, Min Zhang</p>

<p><strong>ABSEval: An Agent-based Framework for Script Evaluation</strong><br />Sirui Liang, Baoli Zhang, Jun Zhao, Kang Liu</p>

<p><strong>Latent Concept-based Explanation of NLP Models</strong><br />Xuemin Yu, Fahim Dalvi, Nadir Durrani, Marzia Nouri, Hassan Sajjad</p>

<p><strong>Decoding with Limited Teacher Supervision Requires Understanding When to Trust the Teacher</strong><br />Hyunjong Ok, Jegwang Ryu, Jaeho Lee</p>

<p><strong>Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research</strong><br />Yida Mu, Mali Jin, Xingyi Song, Nikolaos Aletras</p>

<p><strong>The Mystery of the Pathological Path-star Task for Language Models</strong><br />Arvid Frydenlund</p>

<p><strong>Voices in a Crowd: Searching for clusters of unique perspectives</strong><br />Nikolas Vitsakis, Amit Parekh, Ioannis Konstas</p>

<p><strong>Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent</strong><br />Xiaoyan Yu, Tongxu Luo, Yifan Wei, Fangyu Lei, Yiming Huang, Hao Peng, Liehuang Zhu</p>

<p><strong>SLANG: New Concept Comprehension of Large Language Models</strong><br />Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Xueqi Cheng</p>

<p><strong>Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models</strong><br />Michael Lan, Philip Torr, Fazl Barez</p>

<p><strong>Why Does New Knowledge Create Messy Ripple Effects in LLMs?</strong><br />Jiaxin Qin, Zixuan Zhang, Chi Han, Pengfei Yu, Manling Li, Heng Ji</p>

<p><strong>Lifelong Event Detection via Optimal Transport</strong><br />Viet Dao, Van-Cuong Pham, Quyen Tran, Thanh-Thien Le, Linh Van Ngo, Thien Huu Nguyen</p>

<p><strong>SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories</strong><br />Ben Bogin, Kejuan Yang, Shashank Gupta, Kyle Richardson, Erin Bransom, Peter Clark, Ashish Sabharwal, Tushar Khot</p>

<p><strong>FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation</strong><br />KaShun SHUM, Minrui Xu, Jianshu Zhang, Zixin CHEN, Shizhe Diao, Hanze Dong, Jipeng Zhang, Muhammad Omer Raza</p>

<p><strong>Domain adapted machine translation: What does catastrophic forgetting forget and why?</strong><br />Danielle Saunders, Steve DeNeefe</p>

<p><strong>Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback</strong><br />Benjamin Towle, Ke Zhou</p>

<p><strong>Atomic Self-Consistency for Better Long Form Generations</strong><br />Raghuveer Thirukovalluru, Yukun Huang, Bhuwan Dhingra</p>

<p><strong>“Global is Good, Local is Bad?’’: Understanding Brand Bias in LLMs</strong><br />Mahammed Kamruzzaman, Hieu Minh Nguyen, Gene Louis Kim</p>

<p><strong>Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach</strong><br />Siqi Li, Danni Liu, Jan Niehues</p>

<p><strong>ACE: A LLM-based Negotiation Coaching System</strong><br />Ryan Shea, Aymen Kallala, Xin Lucy Liu, Michael W. Morris, Zhou Yu</p>

<p><strong>TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities</strong><br />Ming Zhang, Caishuang Huang, Yilong Wu, Shichun Liu, Huiyuan Zheng, Yurui Dong, Yujiong Shen, Shihan Dou, Jun Zhao, Junjie Ye, Qi Zhang, Tao Gui, Xuanjing Huang</p>

<p><strong>PATIENT-Ψ: Using Large Language Models to Simulate Patients for Training Mental Health Professionals</strong><br />Ruiyi Wang, Stephanie Milani, Jamie C. Chiu, Jiayin Zhi, Shaun M. Eack, Travis Labrum, Samuel M Murphy, Nev Jones, Kate V Hardy, Hong Shen, Fei Fang, Zhiyu Chen</p>

<p><strong>DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis Prediction</strong><br />Xueren Ge, Abhishek Satpathy, Ronald Dean Williams, John Stankovic, Homa Alemzadeh</p>

<p><strong>$\texttt{ModSCAN}$: Measuring Stereotypical Bias in Large Vision-Language Models from Vision and Language Modalities</strong><br />Yukun Jiang, Zheng Li, Xinyue Shen, Yugeng Liu, Michael Backes, Yang Zhang</p>

<p><strong>Large Language Models Can Self-Correct with Key Condition Verification</strong><br />Zhenyu Wu, Qingkai Zeng, Zhihan Zhang, Zhaoxuan Tan, Chao Shen, Meng Jiang</p>

<p><strong>Learning to Write Rationally: How Information Is Distributed in Non-native Speakers’ Essays</strong><br />Zixin Tang, Janet van Hell</p>

<p><strong>Defending Against Social Engineering Attacks in the Age of LLMs</strong><br />Lin Ai, Tharindu Sandaruwan Kumarage, Amrita Bhattacharjee, Zizhou Liu, Zheng Hui, Michael S. Davinroy, James Cook, Laura Cassani, Kirill Trapeznikov, Matthias Kirchner, Arslan Basharat, Anthony Hoogs, Joshua Garland, huan liu, Julia Hirschberg</p>

<p><strong>Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models</strong><br />Yae Jee Cho, Luyang Liu, Zheng Xu, Aldi Fahrezi, Gauri Joshi</p>

<p><strong>Make Some Noise: Unlocking Language Model Parallel Inference Capability through Noisy Training</strong><br />Yixuan Wang, Xianzhen Luo, Fuxuan Wei, Yijun Liu, Qingfu Zhu, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che</p>

<p><strong>Target-Aware Language Modeling via Granular Data Sampling</strong><br />Ernie Chang, Pin-Jie Lin, Yang Li, Changsheng Zhao, Daeil Kim, Rastislav Rabatin, Zechun Liu, Yangyang Shi, Vikas Chandra</p>

<p><strong>SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness</strong><br />Tanmay Parekh, Jeffrey Kwan, Jiarui Yu, Sparsh Johri, Hyosang Ahn, Sreya Muppalla, Kai-Wei Chang, Wei Wang, Nanyun Peng</p>

<p><strong>Learning from Feedback with Coupled Comprehension and Generation</strong><br />Mustafa Omer Gul, Yoav Artzi</p>

<p><strong>UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks</strong><br />Yuanhao Xiong, Yixin Nie, Haotian Liu, Boxin Wang, Jun Chen, Rong Jin, Cho-Jui Hsieh, Lorenzo Torresani, Jie Lei</p>

<p><strong>Story Morals: Surfacing value-driven narrative schemas using large language models</strong><br />David G Hobson, Haiqi Zhou, Derek Ruths, Andrew Piper</p>

<p><strong>OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants</strong><br />Jaspreet Ranjit, Brihi Joshi, Rebecca Dorn, Laura Petry, Olga Koumoundouros, Jayne Bottarini, Peichen Liu, Eric Rice, Swabha Swayamdipta</p>

<p><strong>AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies</strong><br />Xiao Ye, Andrew Wang, Jacob Choi, Yining Lu, Shreya Sharma, Lingfeng Shen, Vijay Murari Tiyyala, Nicholas Andrews, Daniel Khashabi</p>

<p><strong>SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents</strong><br />Qi Zhang, Zhijia Chen, Huitong Pan, Cornelia Caragea, Longin Jan Latecki, Eduard Dragut</p>

<p><strong>Analysis of Plan-based Retrieval for Grounded Text Generation</strong><br />Ameya Godbole, Nicholas Monath, Seungyeon Kim, Ankit Singh Rawat, Andrew McCallum, Manzil Zaheer</p>

<p><strong>Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors</strong><br />Alex Chandler, Devesh Surve, Hui Su</p>

<p><strong>RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs</strong><br />John Dang, Arash Ahmadian, Kelly Marchisio, Julia Kreutzer, Ahmet Üstün, Sara Hooker</p>

<p><strong>Improving Logical Fallacy Reasoning with Logical Structure Tree</strong><br />Yuanyuan Lei, Ruihong Huang</p>

<p><strong>Chain and Causal Attention for Efficient Entity Tracking</strong><br />Erwan Fagnou, Paul Caillon, Blaise Delattre, Alexandre Allauzen</p>

<p><strong>BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models</strong><br />Yi Zeng, Weiyu Sun, Tran Ngoc Huynh, Dawn Song, Bo Li, Ruoxi Jia</p>

<p><strong>A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution</strong><br />Zhengmian Hu, Tong Zheng, Heng Huang</p>

<p><strong>FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition</strong><br />Xiaoqiang Wang, Lingfei Wu, Tengfei Ma, Bang Liu</p>

<p><strong>OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation</strong><br />Tanvir Mahmud, Diana Marculescu</p>

<p><strong>Language Concept Erasure for Language-invariant Dense Retrieval</strong><br />Zhiqi Huang, Puxuan Yu, Shauli Ravfogel, James Allan</p>

<p><strong>Learning Personalized Alignment for Evaluating Open-ended Text Generation</strong><br />Danqing Wang, Kevin Yang, Hanlin Zhu, Xiaomeng Yang, Andrew Cohen, Lei Li, Yuandong Tian</p>

<p><strong>Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks</strong><br />Yue Zhou, Henry Peng Zou, Barbara Di Eugenio, Yang Zhang</p>

<p><strong>Turn Waste into Worth: Rectifying Top-$k$ Router of MoE</strong><br />Zhiyuan Zeng, Qipeng Guo, Zhaoye Fei, Zhangyue Yin, Yunhua Zhou, Linyang Li, Tianxiang Sun, Hang Yan, Dahua Lin, Xipeng Qiu</p>

<p><strong>Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination</strong><br />Pittawat Taveekitworachai, Febri Abdullah, Ruck Thawonmas</p>

<p><strong>CommVQA: Situating Visual Question Answering in Communicative Contexts</strong><br />Nandita Shankar Naik, Christopher Potts, Elisa Kreiss</p>

<p><strong>Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding</strong><br />Weilin Zhao, Yuxiang Huang, Xu Han, Wang Xu, Chaojun Xiao, Xinrong Zhang, Yewei Fang, Kaihuo Zhang, Zhiyuan Liu, Maosong Sun</p>

<p><strong>1+1&gt;2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?</strong><br />Yue Huang, Chenrui Fan, Yuan Li, Siyuan Wu, Tianyi Zhou, Xiangliang Zhang, Lichao Sun</p>

<p><strong>How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective</strong><br />Teng Xiao, Mingxiao Li, Yige Yuan, Huaisheng Zhu, Chao Cui, Vasant G Honavar</p>

<p><strong>Style-Specific Neurons for Steering LLMs in Text Style Transfer</strong><br />Wen Lai, Viktor Hangya, Alexander Fraser</p>

<p><strong>Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers</strong><br />Tianhua Zhang, Kun LI, Hongyin Luo, Xixin Wu, James R. Glass, Helen M. Meng</p>

<p><strong>Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction</strong><br />Sizhe Zhou, Yu Meng, Bowen Jin, Jiawei Han</p>

<p><strong>DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models</strong><br />Yiming Huang, Jianwen Luo, Yan Yu, Yitong Zhang, Fangyu Lei, Yifan Wei, Shizhu He, Lifu Huang, Xiao Liu, Jun Zhao, Kang Liu</p>

<p><strong>Leveraging Context-aware Prompting for Commit Message Generation</strong><br />Zhihua Jiang, Jianwei Chen, Dongning Rao, Guanghui Ye</p>

<p><strong>Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination</strong><br />Eve Fleisig, Genevieve Smith, Madeline Bossi, Ishita Rustagi, Xavier Yin, Dan Klein</p>

<p><strong>Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning</strong><br />Qizhou Chen, Taolin Zhang, Xiaofeng He, Dongyang Li, Chengyu Wang, Longtao Huang, Hui Xue’</p>

<p><strong>A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models</strong><br />Zhihao Wang, Shiyu Liu, Jianheng Huang, Wang Zheng, YiXuan Liao, Xiaoxin Chen, Junfeng Yao, Jinsong Su</p>

<p><strong>Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages</strong><br />Jimin Sohn, Haeji Jung, Alex Cheng, Jooeon Kang, Yilin Du, David R Mortensen</p>

<p><strong>An Analysis and Mitigation of the Reversal Curse</strong><br />Ang Lv, Kaiyi Zhang, Shufang Xie, Quan Tu, Yuhan Chen, Ji-Rong Wen, Rui Yan</p>

<p><strong>Exploring the Practicality of Generative Retrieval on Dynamic Corpora</strong><br />Soyoung Yoon, Chaeeun Kim, Hyunji Lee, Joel Jang, Sohee Yang, Minjoon Seo</p>

<p><strong>OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting</strong><br />Xukai Liu, Ye Liu, Kai Zhang, Kehang Wang, Qi Liu, Enhong Chen</p>

<p><strong>Gotcha! Don’t trick me with unanswerable questions! Self-aligning Large Language Models for Proactively Responding to Unknown Questions</strong><br />Yang Deng, Yong Zhao, Moxin Li, See-Kiong Ng, Tat-Seng Chua</p>

<p><strong>Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning</strong><br />Xijie Huang, Li Lyna Zhang, Kwang-Ting Cheng, Fan Yang, Mao Yang</p>

<p><strong>Large Language Models in the Clinic: A Comprehensive Benchmark</strong><br />Fenglin Liu, Zheng Li, Qingyu Yin, Jingfeng Yang, Xianfeng Tang, Chen Luo, Ming Zeng, Haoming Jiang, Yifan Gao, Priyanka Nigam, Sreyashi Nag, Hongjian Zhou, Yining Hua, Xuan Zhou, Omid Rohanian, Anshul Thakur, Lei Clifton, Bing Yin, David A. Clifton</p>

<p><strong>Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction</strong><br />Jinchuan Zhang, Yan Zhou, Yaxin Liu, Ziming Li, Songlin Hu</p>

<p><strong>Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective</strong><br />Van-Cuong Pham, Thien Huu Nguyen</p>

<p><strong>DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG</strong><br />Jinyoung Kim, Dayoon Ko, Gunhee Kim</p>

<p><strong>Preserving Generalization of Language models in Few-shot Continual Relation Extraction</strong><br />Quyen Tran, Nguyen Xuan Thanh, Nguyen Hoang Anh, Nam Le Hai, Trung Le, Linh Van Ngo, Thien Huu Nguyen</p>

<p><strong>A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations</strong><br />Md Tahmid Rahman Laskar, Sawsan Alqahtani, M Saiful Bari, Mizanur Rahman, Mohammad Abdullah Matin Khan, Haidar Khan, Israt Jahan, Amran Bhuiyan, Chee Wei Tan, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty, Jimmy Huang</p>

<p><strong>Consecutive Batch Model Editing with HooK Layers</strong><br />Shuaiyi Li, Yang Deng, Deng Cai, Hongyuan Lu, Liang CHEN, Wai Lam</p>

<p><strong>Topic-Oriented Open Relation Extraction with A Priori Seed Generation</strong><br />Linyi Ding, Jinfeng Xiao, Sizhe Zhou, Chaoqi Yang, Jiawei Han</p>

<p><strong>Related Work and Citation Text Generation: A Survey</strong><br />Xiangci Li, Jessica Ouyang</p>

<p><strong>Curriculum Consistency Learning for Conditional Sentence Generation</strong><br />Liangxin Liu, Xuebo Liu, Lian Lian, shengjun cheng, Jun Rao, Tengfei Yu, Hexuan Deng, Min Zhang</p>

<p><strong>A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences</strong><br />Leonardo Bertolazzi, Albert Gatt, Raffaella Bernardi</p>

<p><strong>Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision</strong><br />Fan Jiang, Tom Drummond, Trevor Cohn</p>

<p><strong>Towards an Open-Source Speech Foundation Model for EU: 950,000 Hours of Open-Source Compliant Speech Data for EU Languages</strong><br />Marco Gaido, Sara Papi, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri</p>

<p><strong>Improving Knowledge Graph Completion with Structure-Aware Supervised Contrastive Learning</strong><br />Jiashi Lin, Lifang Wang, Xinyu Lu, Zhongtian Hu, Wei Zhang, Wenxuan Lu</p>

<p><strong>Contribution of Linguistic Typology to Universal Dependency Parsing: An Empirical Investigation</strong><br />Ali Basirat, Navid Baradaran Hemmati</p>

<p><strong>TRoTR: A Framework for Evaluating the Re-contextualization of Text Reuse</strong><br />Francesco Periti, Pierluigi Cassotti, Stefano Montanelli, Nina Tahmasebi, Dominik Schlechtweg</p>

<p><strong>Structured Optimal Brain Pruning for Large Language Models</strong><br />Jiateng Wei, Quan Lu, ning jiang, Siqi Li, Jingyang Xiang, Jun Chen, Yong Liu</p>

<p><strong>Automatically Generated Definitions and their utility for Modeling Word Meaning</strong><br />Francesco Periti, David Alfter, Nina Tahmasebi</p>

<p><strong>How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data</strong><br />Yejie Wang, Keqing He, Dayuan Fu, Zhuoma GongQue, Heyang Xu, Yanxu Chen, Zhexu Wang, Yujia Fu, Guanting Dong, Muxi Diao, Jingang Wang, Mengdi Zhang, Xunliang Cai, Weiran Xu</p>

<p><strong>MINT: A Benchmark for Evaluating Instructed Information Retrieval</strong><br />Weiwei Sun, Zhengliang Shi, Wu Jiu Long, Lingyong Yan, Xinyu Ma, Yiding Liu, Min Cao, Dawei Yin, Zhaochun Ren</p>

<p><strong>Rethinking the Evaluation of In-Context Learning for LLMs</strong><br />Guoxin Yu, Lemao Liu, Mo Yu, Yue Yu, Xiang Ao</p>

<p><strong>Cluster-Norm for Unsupervised Probing of Knowledge</strong><br />Walter Laurito, Sharan Maiya, Grégoire DHIMOÏLA, Owen Ho Wan Yeung, Kaarel Hänni</p>

<p><strong>Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries</strong><br />Eden Biran, Daniela Gottesman, Sohee Yang, Mor Geva, Amir Globerson</p>

<p><strong>Enhancing Training Data Attribution for Large Language Models with Fitting Error Consideration</strong><br />Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng</p>

<p><strong>Where am I? Large Language Models Wandering between Semantics and Structures in Long Contexts</strong><br />Seonmin Koo, Jinsung Kim, YoungJoon Jang, Chanjun Park, Heuiseok Lim</p>

<p><strong>KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students</strong><br />Matthew Shu, Nishant Balepur, Shi Feng, Jordan Lee Boyd-Graber</p>

<p><strong>Large Language Models Can Be Contextual Privacy Protection Learners</strong><br />Yijia Xiao, Yiqiao Jin, Yushi Bai, Yue Wu, Xianjun Yang, Xiao Luo, Wenchao Yu, Xujiang Zhao, Yanchi Liu, Quanquan Gu, Haifeng Chen, Wei Wang, Wei Cheng</p>

<p><strong>A SMART Mnemonic Sounds like “Glue Tonic”: Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick</strong><br />Nishant Balepur, Matthew Shu, Alexander Hoyle, Alison Robey, Shi Feng, Seraphina Goldfarb-Tarrant, Jordan Lee Boyd-Graber</p>

<p><strong>Mixture-of-Skills: Learning to Optimize Data Usage for Fine-Tuning Large Language Models</strong><br />Minghao Wu, Thuy-Trang Vu, Lizhen Qu, Reza Haf</p>

<p><strong>MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction</strong><br />Jun-Hyung Park, Yeachan Kim, Mingyu Lee, Hyuntae Park, SangKeun Lee</p>

<p><strong>First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning</strong><br />Yoichi Aoki, Keito Kudo, Tatsuki Kuribayashi, Shusaku Sone, Masaya Taniguchi, Keisuke Sakaguchi, Kentaro Inui</p>

<p><strong>Tools Fail: Detecting Silent Errors in Faulty Tools</strong><br />Jimin Sun, So Yeon Min, Yingshan Chang, Yonatan Bisk</p>

<p><strong>Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity</strong><br />Bowen Zhang, Chunping Li</p>

<p><strong>Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing</strong><br />Deokhyung Kang, Seonjeong Hwang, Yunsu Kim, Gary Lee</p>

<p><strong>Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision &amp; Language Modeling</strong><br />Georgios Pantazopoulos, Malvina Nikandrou, Alessandro Suglia, Oliver Lemon, Arash Eshghi</p>

<p><strong>Are LLMs Good Zero-Shot Fallacy Classifiers?</strong><br />Fengjun Pan, Xiaobao Wu, Zongrui Li, Anh Tuan Luu</p>

<p><strong>The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis</strong><br />Yuxiang Zhou, Jiazheng Li, Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He</p>

<p><strong>More DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages</strong><br />Dominik Schlechtweg, Pierluigi Cassotti, Bill Noble, David Alfter, Sabine Schulte im Walde, Nina Tahmasebi</p>

<p><strong>Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification</strong><br />Ming Li, Jike Zhong, Chenxin Li, Liuzhuozheng Li, Nie Lin, Masashi Sugiyama</p>

<p><strong>ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos</strong><br />Arpan Phukan, Manish Gupta, Asif Ekbal</p>

<p><strong>Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation</strong><br />Elaf Alhazmi, Quan Z. Sheng, Wei Emma Zhang, Munazza Zaib, Ahoud Alhazmi</p>

<p><strong>Evaluating $n$-Gram Novelty of Language Models Using Rusty-DAWG</strong><br />William Merrill, Noah A. Smith, Yanai Elazar</p>

<p><strong>ASL STEMpedia: Dataset and Benchmark for Interpreting STEM Articles</strong><br />Kayo Yin, Chinmay Singh, Fyodor O Minakov, Vanessa Milan, Hal Daumé III, Cyril Zhang, Alex Xijie Lu, Danielle Bragg</p>

<p><strong>Can Automatic Metrics Assess High-Quality Translations?</strong><br />Sweta Agrawal, António Farinhas, Ricardo Rei, Andre Martins</p>

<p><strong>Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation</strong><br />Sweta Agrawal, José G. C. de Souza, Ricardo Rei, António Farinhas, Gonçalo Faria, Patrick Fernandes, Nuno M Guerreiro, Andre Martins</p>

<p><strong>DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding</strong><br />Bowen Xing, Lizi Liao, Minlie Huang, Ivor Tsang</p>

<p><strong>KnowTuning: Knowledge-aware Fine-tuning for Large Language Models</strong><br />Yougang Lyu, Lingyong Yan, Shuaiqiang Wang, Haibo Shi, Dawei Yin, Pengjie Ren, Zhumin Chen, Maarten de Rijke, Zhaochun Ren</p>

<p><strong>SecCoder: Towards Generalizable and Robust Secure Code Generation</strong><br />Boyu Zhang, Tianyu Du, Junkai Tong, Xuhong Zhang, Kingsum Chow, Sheng Cheng, Xun Wang, Jianwei Yin</p>

<p><strong>Nash CoT: Multi-Path Inference with Preference Equilibrium</strong><br />Ziqi Zhang, Cunxiang Wang, Xiao Xiong, Yue Zhang, Donglin Wang</p>

<p><strong>Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention</strong><br />Xingtai Lv, Ning Ding, Kaiyan Zhang, Ermo Hua, Ganqu Cui, Bowen Zhou</p>

<p><strong>Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector</strong><br />Xiaoxue Cheng, Junyi Li, Xin Zhao, Hongzhi Zhang, Fuzheng Zhang, Di ZHANG, Kun Gai, Ji-Rong Wen</p>

<p><strong>Interpretable Composition Attribution Enhancement for Visio-linguistic Compositional Understanding</strong><br />Wei Li, Zhen Huang, Xinmei Tian, Le Lu, Houqiang Li, Xu Shen, Jieping Ye</p>

<p><strong>LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History</strong><br />Akash Gupta, Ivaxi Sheth, Vyas Raina, Mark Gales, Mario Fritz</p>

<p><strong>Social Bias Probing: Fairness Benchmarking for Language Models</strong><br />Marta Marchiori Manerba, Karolina Stanczak, Riccardo Guidotti, Isabelle Augenstein</p>

<p><strong>Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models</strong><br />Wenhao Yu, Hongming Zhang, Xiaoman Pan, peixin cao, Kaixin Ma, Jian Li, Hongwei Wang, Dong Yu</p>

<p><strong>DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models</strong><br />Jiabao Pan, Yan Zhang, Chen Zhang, Zuozhu Liu, Hongwei Wang, Haizhou Li</p>

<p><strong>Revisiting Automated Evaluation for Long-form Table Question Answering in the Era of Large Language Models</strong><br />Yuqi Wang, Lyuhao Chen, Yilun Zhao</p>

<p><strong>Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems</strong><br />Italo Luis da Silva, Hanqi Yan, Lin Gui, Yulan He</p>

<p><strong>Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning</strong><br />Zhihan Zhang, Tao Ge, Zhenwen Liang, Wenhao Yu, Dian Yu, Mengzhao Jia, Dong Yu, Meng Jiang</p>

<p><strong>FinDVer: Explainable Claim Verification over Long and Hybrid-content Financial Documents</strong><br />Yilun Zhao, Yitao Long, Tintin Jiang, Weiyuan Chen, Chengye Wang, Hongjun Liu, Xiangru Tang, Yiming Zhang, Chen Zhao, Arman Cohan</p>

<p><strong>Extracting Prompts by Inverting LLM Outputs</strong><br />Collin Zhang, John Xavier Morris, Vitaly Shmatikov</p>

<p><strong>BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs</strong><br />Zhiting Fan, Ruizhe Chen, Ruiling Xu, Zuozhu Liu</p>

<p><strong>VHASR: A Multimodal Speech Recognition System With Vision Hotwords</strong><br />Jiliang Hu, Zuchao Li, Ping Wang, Haojun Ai, Lefei Zhang, hai zhao</p>

<p><strong>A Fundamental Trade-off in Aligned Language Models and its Relation to Sampling Adaptors</strong><br />Naaman Tan, Josef Valvoda, Tianyu Liu, Anej Svete, Yanxia Qin, Min-Yen Kan, Ryan Cotterell</p>

<p><strong>Bridging Local Details and Global Context in Text-Attributed Graphs</strong><br />Yaoke Wang, Yun Zhu, Wenqiao Zhang, Yueting Zhuang, liyunfei, Siliang Tang</p>

<p><strong>Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks</strong><br />Felermino D. M. A. Ali, Henrique Lopes Cardoso, Rui Sousa-Silva</p>

<p><strong>RepMatch: Quantifying Cross-Instance Similarities in Representation Space</strong><br />Mohammad Reza Modarres, Sina Abbasi, Mohammad Taher Pilehvar</p>

<p><strong>Commonsense Knowledge Editing Based on Free-Text in LLMs</strong><br />Xiusheng Huang, Yequan Wang, Jun Zhao, Kang Liu</p>

<p><strong>A Closer Look at Multidimensional Online Political Incivility</strong><br />Sagi Pendzel, Nir Lotan, Alon Zoizner, Einat Minkov</p>

<p><strong>Leveraging BERT and TFIDF Features for Short Text Clustering via Alignment-Promoting Co-Training</strong><br />Zetong Li, Qinliang Su, Shijing Si, Jianxing Yu</p>

<p><strong>Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation</strong><br />Bar Iluz, Yanai Elazar, Asaf Yehudai, Gabriel Stanovsky</p>

<p><strong>Unsupervised Named Entity Disambiguation for Low Resource Domains</strong><br />Debarghya Datta, Soumajit Pramanik</p>

<p><strong>SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers</strong><br />Viktoriia A. Chekalina, Anna Rudenko, Gleb Mezentsev, Aleksandr Mikhalev, Alexander Panchenko, Ivan Oseledets</p>

<p><strong>MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion</strong><br />Qingyang Li, Yanru Zhong, Yuchu Qin</p>

<p><strong>ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities</strong><br />Ying Su, Zhan Ling, Haochen Shi, Cheng Jiayang, Yauwai Yim, Yangqiu Song</p>

<p><strong>Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning</strong><br />Xiaopeng Xie, Ming YAN, Xiwen Zhou, Chenlong Zhao, Suli Wang, Yong Zhang, Joey Tianyi Zhou</p>

<p><strong>GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients</strong><br />Aashiq Muhamed, Oscar Li, David Woodruff, Mona T. Diab, Virginia Smith</p>

<p><strong>RaTEScore: A Metric for Entity-Aware Radiology Text Similarity</strong><br />Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Weidi Xie</p>

<p><strong>HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning</strong><br />Shayan Ali Akbar, Md Mosharaf Hossain, Tess Wood, Si-Chi Chin, Victor Alvarez, Erica M Salinas, Erwin Cornejo</p>

<p><strong>Learning to Rank Salient Content for Query-focused Summarization</strong><br />Sajad Sotudeh, Nazli Goharian</p>

<p><strong>Are Large Language Models Good Classifiers? A Study on Edit Intent Classification in Scientific Document Revisions</strong><br />Qian Ruan, Ilia Kuznetsov, Iryna Gurevych</p>

<p><strong>LitSearch: A Retrieval Benchmark for Scientific Literature Search</strong><br />Anirudh Ajith, Mengzhou Xia, Alexis Chevalier, Tanya Goyal, Danqi Chen, Tianyu Gao</p>

<p><strong>Open-world Multi-label Text Classification with Extremely Weak Supervision</strong><br />Xintong Li, Jinya Jiang, Ria Dharmani, Jayanth Srinivasa, Gaowen Liu, Jingbo Shang</p>

<p><strong>LMs learn governing principles of dynamical systems, revealing an in-context neural scaling law</strong><br />Toni J.B. Liu, Nicolas Boulle, Raphaël Sarfati, Christopher Earls</p>

<p><strong>AKEW: Assessing Knowledge Editing in the Wild</strong><br />Xiaobao Wu, Liangming Pan, William Yang Wang, Anh Tuan Luu</p>

<p><strong>CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation</strong><br />Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh</p>

<p><strong>Dense X Retrieval: What Retrieval Granularity Should We Use?</strong><br />Tong Chen, Hongwei Wang, Sihao Chen, Wenhao Yu, Kaixin Ma, Xinran Zhao, Hongming Zhang, Dong Yu</p>

<p><strong>Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach</strong><br />Yanchen Liu, Mingyu Derek Ma, Wenna Qin, Azure Zhou, Jiaao Chen, Weiyan Shi, Wei Wang, Diyi Yang</p>

<p><strong>Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models</strong><br />Zheng Zhao, Yftah Ziser, Shay B Cohen</p>

<p><strong>XDetox: Text Detoxification with Token-Level Toxicity Explanations</strong><br />Beomseok Lee, Hyunwoo Kim, Keon Kim, Yong Suk Choi</p>

<p><strong>Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach</strong><br />ZiHao Xiao, Jiefu Gong, Shijin Wang, Wei Song</p>

<p><strong>Evaluating LLMs’ Capability in Satisfying Lexical Constraints</strong><br />Bingxuan Li, Yiwei Wang, Tao Meng, Nanyun Peng, Kai-Wei Chang</p>

<p><strong>Joint Pre-Encoding Representation and Structure Embedding for Efficient and Low-Resource Knowledge Graph Completion</strong><br />Chenyu Qiu, Pengjiang Qian, Chuang Wang, Jian Yao, Li Liu, Fang wei, Eddie Y.K. Eddie</p>

<p><strong>Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning</strong><br />Lu Chen, Rui Zheng, Binghai Wang, Senjie Jin, Caishuang Huang, Junjie Ye, Zhihao Zhang, Yuhao Zhou, Zhiheng Xi, Tao Gui, Qi Zhang, Xuanjing Huang</p>

<p><strong>RoCEL: Advancing Table Entity Linking through Distinctive Row and Column Contexts</strong><br />Yuanzheng Wang, Yixing Fan, Jiafeng Guo, Ruqing Zhang, Xueqi Cheng</p>

<p><strong>Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models</strong><br />Zi’ou Zheng, Christopher Malon, Martin Renqiang Min, Xiaodan Zhu</p>

<p><strong>Efficient Overshadowed Entity Disambiguation by Mitigating Shortcut Learning</strong><br />Panuthep Tasawong, Peerat Limkonchotiwat, Potsawee Manakul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong</p>

<p><strong>MetaBench: Planning of Multiple APIs from Various APPs for Complex User Instruction</strong><br />Hongru WANG, Rui Wang, Boyang XUE, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, Kam-Fai Wong</p>

<p><strong>Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment</strong><br />Zhipeng Chen, Kun Zhou, Xin Zhao, Jingyuan Wang, Ji-Rong Wen</p>

<p><strong>AudioVSR: Enhancing Video Speech Recognition with Audio Data</strong><br />Xiaoda Yang, Xize Cheng, Jiaqi Duan, Hongshun Qiu, Minjie Hong, Minghui Fang, Shengpeng Ji, Jialong Zuo, Zhiqing Hong, Zhimeng Zhang, Tao Jin</p>

<p><strong>ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?</strong><br />Siddhant Waghjale, Vishruth Veerendranath, Zhiruo Wang, Daniel Fried</p>

<p><strong>Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level</strong><br />Zhaopeng Feng, Ruizhe Chen, Yan Zhang, Zijie Meng, Zuozhu Liu</p>

<p><strong>Re-ReST: Reflection-Reinforced Self-Training for Language Agents</strong><br />Zi-Yi Dou, Cheng-Fu Yang, Xueqing Wu, Kai-Wei Chang, Nanyun Peng</p>

<p><strong>Effective Synthetic Data and Test-Time Adaptation for OCR Correction</strong><br />Shuhao Guan, Cheng Xu, Moule Lin, Derek Greene</p>

<p><strong>SRF: Enhancing Document-Level Relation Extraction with a Novel Secondary Reasoning Framework</strong><br />Fu Zhang, Qi Miao, Jingwei Cheng, Hongsen Yu, Yi Yan, Xin Li, YongxueWu</p>

<p><strong>FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension</strong><br />Junzhuo Liu, Xuzheng Yang, WEIWEI LI, Peng Wang</p>

<p><strong>Exploring the Learning Capabilities of Language Models using LEVERWORLDS</strong><br />Eitan Wagner, Amir Feder, Omri Abend</p>

<p><strong>CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models</strong><br />Eitan Wagner, Yuli Slavutsky, Omri Abend</p>

<p><strong>DocEditAgent: Document Structure Editing Via Multimodal LLM Grounding</strong><br />Manan Suri, Puneet Mathur, Franck Dernoncourt, Rajiv Jain, Vlad I Morariu, Ramit Sawhney, Preslav Nakov, Dinesh Manocha</p>

<p><strong>DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging</strong><br />Tzu-Han Lin, Chen-An Li, Hung-yi Lee, Yun-Nung Chen</p>

<p><strong>Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing</strong><br />Ifeoluwa Wuraola, Nina Dethlefs, Daniel Marciniak</p>

<p><strong>Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding</strong><br />Lifu Tu, Semih Yavuz, Jin Qu, Jiacheng Xu, Rui Meng, Caiming Xiong, Yingbo Zhou</p>

<p><strong>Re-Reading Improves Reasoning in Large Language Models</strong><br />Xiaohan Xu, Chongyang Tao, Tao Shen, Can Xu, Hongbo Xu, Guodong Long, Jian-Guang Lou, Shuai Ma</p>

<p><strong>Adaptive Axes: A Pipeline for In-domain Social Stereotype Analysis</strong><br />Qingcheng Zeng, Mingyu Jin, Rob Voigt</p>

<p><strong>ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments</strong><br />Sourjyadip Ray, Kushal Gupta, Soumi Kundu, Dr Payal Arvind Kasat, Somak Aditya, Pawan Goyal</p>

<p><strong>Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations</strong><br />Jiyi Li</p>

<p><strong>Improve Student’s Reasoning Generalizability through Cascading Decomposed CoTs Distillation</strong><br />Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu</p>

<p><strong>Revisiting Supervised Contrastive Learning for Microblog Classification</strong><br />Junbo Huang, Ricardo Usbeck</p>

<p><strong>BaitAttack: Alleviating Intention Shift in Jailbreak Attacks via Adaptive Bait Crafting</strong><br />Rui Pu, Chaozhuo Li, Rui Ha, Litian Zhang, Lirong Qiu, Xi Zhang</p>

<p><strong>Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective</strong><br />Zhaotian Weng, Zijun Gao, Jerone Andrews, Jieyu Zhao</p>

<p><strong>Mitigating the Language Mismatch and Repetition Issues in LLM-based Machine Translation via Model Editing</strong><br />Weichuan Wang, Zhaoyi Li, Defu Lian, Chen Ma, Linqi Song, Ying Wei</p>

<p><strong>SciAgent: Tool-augmented Language Models for Scientific Reasoning</strong><br />Yubo Ma, Zhibin Gou, Junheng Hao, Ruochen Xu, Shuohang Wang, Liangming Pan, Yujiu Yang, Yixin Cao, Aixin Sun</p>

<p><strong>Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents</strong><br />Dong Won Lee, Hae Won Park, Yoon Kim, Cynthia Breazeal, Louis-Philippe Morency</p>

<p><strong>Towards Measuring and Modeling “Culture” in LLMs: A Survey</strong><br />Muhammad Farid Adilazuarda, Sagnik Mukherjee, Pradhyumna Lavania, Siddhant Shivdutt Singh, Alham Fikri Aji, Jacki O’Neill, Ashutosh Modi, Monojit Choudhury</p>

<p><strong>ESC-Eval: Evaluating Emotion Support Conversations in Large Language Models</strong><br />Haiquan Zhao, Lingyu Li, Shisong Chen, Shuqi Kong, Jiaan Wang, Kexin Huang, Tianle Gu, Yixu Wang, Jian Wang, Liang Dandan, Zhixu Li, Yan Teng, Yanghua Xiao, Yingchun Wang</p>

<p><strong>Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting</strong><br />Sagnik Mukherjee, Muhammad Farid Adilazuarda, Sunayana Sitaram, Kalika Bali, Alham Fikri Aji, Monojit Choudhury</p>

<p><strong>Text Fluoroscopy: Detecting LLM-Generated Text through Intrinsic Features</strong><br />Xiao Yu, Kejiang Chen, Qi Yang, Weiming Zhang, Nenghai Yu</p>

<p><strong>Hate Personified: Investigating the role of LLMs in content moderation pipeline for hate speech</strong><br />Sarah Masud, Sahajpreet Singh, Viktor Hangya, Alexander Fraser, Tanmoy Chakraborty</p>

<p><strong>Temporally Consistent Factuality Probing for Large Language Models</strong><br />Ashutosh Bajpai, Aaryan Goyal, Atif Anwer, Tanmoy Chakraborty</p>

<p><strong>A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives</strong><br />Zihao Li, Shaoxiong Ji, Timothee Mickus, Vincent Segonne, Jörg Tiedemann</p>

<p><strong>Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators</strong><br />Prasoon Bajpai, Niladri Chatterjee, Subhabrata Dutta, Tanmoy Chakraborty</p>

<p><strong>LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training</strong><br />Tong Zhu, Xiaoye Qu, Daize Dong, Jiacheng Ruan, Jingqi Tong, Conghui He, Yu Cheng</p>

<p><strong>Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability</strong><br />Xinyu Hu, Li Lin, Mingqi Gao, Xunjian Yin, Xiaojun Wan</p>

<p><strong>Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging</strong><br />Yiming Ju, Ziyi Ni, Xingrun Xing, Zhixiong Zeng, hanyu Zhao, Siqi Fan, Zheng Zhang</p>

<p><strong>Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning</strong><br />Sam Spilsbury, Pekka Marttinen, Alexander Ilin</p>

<p><strong>FAME: Factual Multi-task Model Editing Benchmark</strong><br />Li Zeng, Yingyu Shan, Zeming Liu, Jiashu Yao, Yuhang Guo</p>

<p><strong>MLLM-Protector: Ensuring MLLM’s Safety without Hurting Performance</strong><br />Renjie Pi, Tianyang Han, Jianshu Zhang, Yueqi XIE, Rui Pan, Qing LIAN, Hanze Dong, Jipeng Zhang, Tong Zhang</p>

<p><strong>Leveraging Large Language Models for NLG Evaluation: Advances and Challenges</strong><br />Zhen Li, Xiaohan Xu, Tao Shen, Can Xu, Jia-Chen Gu, Yuxuan Lai, Chongyang Tao, Shuai Ma</p>

<p><strong>InfiniPot: Infinite Context Processing on Memory-Constrained LLMs</strong><br />Minsoo Kim, Kyuhong Shim, Jungwook Choi, Simyung Chang</p>

<p><strong>VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP Models</strong><br />Jiapeng Wang, Chengyu Wang, Kunzhe Huang, Jun Huang, Lianwen Jin</p>

<p><strong>CorrSynth - A Correlated Sampling Method for Diverse dataset Generation from LLMs</strong><br />Abhishek Divekar, Suhas S Kowshik, Vijit Malik</p>

<p><strong>Defining Knowledge: Bridging Epistemology and Large Language Models</strong><br />Constanza Fierro, Ruchira Dhar, Filippos Stamatiou, Nicolas Garneau, Anders Søgaard</p>

<p><strong>TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs</strong><br />Peiwen Jiang, Zibo Zhao, Xinbo Lin, Ruhui Ma, Yvonne Jie Chen, Jinhua Cheng</p>

<p><strong>Free your mouse! Command Large Language Models to Generate Code to Format Word Documents</strong><br />Shihao Rao, Liang Li, Jiapeng Liu, Guan Weixin, Xiyan Gao, bing lim</p>

<p><strong>CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models</strong><br />Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan</p>

<p><strong>The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs</strong><br />Tianyang Han, Qing LIAN, Rui Pan, Renjie Pi, Jipeng Zhang, Shizhe Diao, Yong Lin, Tong Zhang</p>

<p><strong>Rationale-Aware Answer Verification by Pairwise Self-Evaluation</strong><br />Akira Kawabata, Saku Sugawara</p>

<p><strong>On the Robustness of Editing Large Language Models</strong><br />Xinbei Ma, Tianjie Ju, Jiyang Qiu, Zhuosheng Zhang, hai zhao, lifeng Liu, Yulong Wang</p>

<p><strong>IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method</strong><br />MiHyeon Kim, Juhyoung Park, YoungBin Kim</p>

<p><strong>Distract Large Language Models for Automatic Jailbreak Attack</strong><br />Zeguan Xiao, Yan Yang, Guanhua Chen, Yun Chen</p>

<p><strong>Exploring Space Efﬁciency in a Tree-based Linear Model for Extreme Multi-label Classiﬁcation</strong><br />He-Zhe Lin, Cheng-Hung Liu, Chih-Jen Lin</p>

<p><strong>WorryWords: Norms of Anxiety Association for 44,450 English Words</strong><br />Saif M. Mohammad</p>

<p><strong>Finding Blind Spots in Evaluator LLMs with Interpretable Checklists</strong><br />Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, Sshubam Verma, Mitesh M Khapra</p>

<p><strong>LONGAGENT: Achieving Question Answering for 128k-Token-Long Documents through Multi-Agent Collaboration</strong><br />Jun Zhao, Can Zu, Xu Hao, Yi Lu, Wei He, Yiwen Ding, Tao Gui, Qi Zhang, Xuanjing Huang</p>

<p><strong>AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments</strong><br />Till Raphael Saenger, Musashi Hinck, Justin Grimmer, Brandon M. Stewart</p>

<p><strong>Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs</strong><br />Simone Conia, Daniel Lee, Min Li, Umar Farooq Minhas, Saloni Potdar, Yunyao Li</p>

<p><strong>Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems</strong><br />Jun Zhao, Jingqi Tong, Yurong Mou, Ming Zhang, Qi Zhang, Xuanjing Huang</p>

<p><strong>Scaling Laws for Linear Complexity Language Models</strong><br />Xuyang Shen, Dong Li, Ruitao Leng, Zhen Qin, Weigao Sun, Yiran Zhong</p>

<p><strong>Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards</strong><br />Heejin Do, Sangwon Ryu, Gary Lee</p>

<p><strong>Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis</strong><br />Guangliang Liu, Haitao Mao, Jiliang Tang, Kristen Johnson</p>

<p><strong>ATAP: Automatic Template-Augmented Commonsense Knowledge Graph Completion via Pre-Trained Language Models</strong><br />Fu Zhang, Yifan Ding, Jingwei Cheng</p>

<p><strong>LM2: A Simple Society of Language Models Solves Complex Reasoning</strong><br />Gurusha Juneja, Subhabrata Dutta, Tanmoy Chakraborty</p>

<p><strong>Towards a Semantically-aware Surprisal Theory</strong><br />Clara Meister, Mario Giulianelli, Tiago Pimentel</p>

<p><strong>Multi-Level Information Retrieval Augmented Generation for Knowledge-based Visual Question Answering</strong><br />Adjali Omar, Olivier Ferret, Sahar Ghannay, Hervé Le Borgne</p>

<p><strong>Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?</strong><br />Jianfeng He, Runing Yang, Linlin Yu, Changbin Li, Ruoxi Jia, Feng Chen, Ming Jin, Chang-Tien Lu</p>

<p><strong>Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP</strong><br />Omer Goldman, Alon Jacovi, Aviv Slobodkin, Aviya Maimon, Ido Dagan, Reut Tsarfaty</p>

<p><strong>BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer Training</strong><br />Pavel Chizhov, Catherine Arnett, Elizaveta Korotkova, Ivan P. Yamshchikov</p>

<p><strong>SEGMENT+: Long Text Processing with Short-Context Language Models</strong><br />Wei Shi, Shuang Li, Kerun Yu, Jinglei Chen, Zujie Liang, Xinhui Wu, Yuxi Qian, Feng Wei, Bo Zheng, Jiaqing Liang, Jiangjie Chen, Yanghua Xiao</p>

<p><strong>Explicit Memory Learning with Expectation Maximization</strong><br />Zhangyue Yin, Qiushi Sun, Qipeng Guo, Zhiyuan Zeng, Qinyuan Cheng, Xipeng Qiu, Xuanjing Huang</p>

<p><strong>Learning to Generate Writing Feedback via Language Model Simulated Student Revisions</strong><br />Inderjeet Jayakumar Nair, Jiaye Tan, Xiaotian Su, Anne Gere, Xu Wang, Lu Wang</p>

<p><strong>Small LLMs Are Weak Tool Learners: A Multi-LLM Agent</strong><br />Weizhou Shen, Chenliang Li, Hongzhan Chen, Ming Yan, Xiaojun Quan, Hehong Chen, Ji Zhang, Fei Huang</p>

<p><strong>Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions</strong><br />Clement Neo, Shay B Cohen, Fazl Barez</p>

<p><strong>Still Not Quite There! Assessing Large Language Models for Comorbid Mental Health Diagnosis</strong><br />Amey Hengle, Atharva Kulkarni, Shantanu Deepak Patankar, Rashmi Gupta</p>

<p><strong>The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning</strong><br />Shaobo Cui, Zhijing Jin, Bernhard Schölkopf, Boi Faltings</p>

<p><strong>Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups</strong><br />Răzvan-Alexandru Smădu, David-Gabriel ION, Dumitru-Clementin Cercel, Florin Pop, Mihaela-Claudia Cercel</p>

<p><strong>Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue</strong><br />Jia-Chen Gu, Hao-Xiang Xu, Jun-Yu Ma, Pan Lu, Zhen-Hua Ling, Kai-Wei Chang, Nanyun Peng</p>

<p><strong>Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!</strong><br />Divya Patel, Pathik Patel, Ankush Chander, Sourish Dasgupta, Tanmoy Chakraborty</p>

<p><strong>MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations</strong><br />Vishal Vivek Saley, Goonjan Saha, Rocktim Jyoti Das, Dinesh Raghu, Mausam .</p>

<p><strong>**<em>YesBut</em></strong>: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models**<br />Abhilash Nandy, Yash Agarwal, Ashish Patwa, Millon Madhur Das, Aman Bansal, ANKIT RAJ, Pawan Goyal, Niloy Ganguly</p>

<p><strong>Scaling Cognitive Limits: Identifying Working Memory Limits in LLMs</strong><br />Chunhui Zhang, Yiren Jian, Zhongyu Ouyang, Soroush Vosoughi</p>

<p><strong>RAFT: Realistic Attacks to Fool Text Detectors</strong><br />James Liyuan Wang, Ran Li, Junfeng Yang, Chengzhi Mao</p>

<p><strong>LLM-Evolve: Evaluation for LLM’s Evolving Capability on Benchmarks</strong><br />Jiaxuan You, Mingjie Liu, Shrimai Prabhumoye, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro</p>

<p><strong>FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping</strong><br />AJAY KUMAR JAISWAL, Bodun Hu, Lu Yin, Yeonju Ro, Tianlong Chen, Shiwei Liu, Aditya Akella</p>

<p><strong>LLM-based Code-Switched Text Generation for Grammatical Error Correction</strong><br />Tom Potter, Zheng Yuan</p>

<p><strong>Deciphering the Interplay of Parametric and Non-Parametric Memory in RAG Models</strong><br />Mehrdad Farahani, Richard Johansson</p>

<p><strong>On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning</strong><br />Geewook Kim, Minjoon Seo</p>

<p><strong>Community-Cross-Instruct: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities</strong><br />Zihao He, Rebecca Dorn, Minh Duc Chu, Siyi Guo, Kristina Lerman</p>

<p><strong>Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models</strong><br />Eldar Kurtic, Amir Moeini, Dan Alistarh</p>

<p><strong>Reasoning Paths with Reference Objects Elicit Quantitative Spatial Reasoning in Large Vision-Language Models</strong><br />Yuan-Hong Liao, Rafid Mahmood, Sanja Fidler, David Acuna</p>

<p><strong>One Thousand and One Pairs: A “novel” challenge for long-context language models</strong><br />Marzena Karpinska, Katherine Thai, Kyle Lo, Tanya Goyal, Mohit Iyyer</p>

<p><strong>Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation</strong><br />Tu Vu, Kalpesh Krishna, Salaheddin Alzubi, Chris Tar, Manaal Faruqui, Yun-Hsuan Sung</p>

<p><strong>Do LLMs learn a true syntactic universal?</strong><br />John T. Hale, Miloš Stanojević</p>

<p><strong>GDPO: Learning to Align Language Models with Diversity Using GFlowNets</strong><br />Oh Joon Kwon, Daiki E. Matsunaga, Kee-Eung Kim</p>

<p><strong>How Susceptible are Large Language Models to Ideological Manipulation?</strong><br />Kai Chen, Zihao He, Jun Yan, Taiwei Shi, Kristina Lerman</p>

<p><strong>Measuring Psychological Depth in Language Models</strong><br />Fabrice Y Harel-Canada, Hanyu Zhou, Sreya Muppalla, Zeynep Senahan Yildiz, Miryung Kim, Nanyun Peng, Amit Sahai</p>

<p><strong>Media Attitude Detection via Framing Analysis with Events and their Relations</strong><br />Jin Zhao, Jingxuan Tu, Han Du, Nianwen Xue</p>

<p><strong>Fill In The Gaps: Model Calibration and Generalization with Synthetic Data</strong><br />Yang Ba, Michelle V Mancenido, Rong Pan</p>

<p><strong>Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations</strong><br />Sagi Shaier, Ari Kobren, Philip V. Ogren</p>

<p><strong>Granular Privacy Control for Geolocation with Vision Language Models</strong><br />Ethan Mendes, Yang Chen, James Hays, Sauvik Das, Wei Xu, Alan Ritter</p>

<p><strong>MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain</strong><br />Chao Jiang, Wei Xu</p>

<p><strong>MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification</strong><br />Siddhant Bikram Shah, Shuvam Shiwakoti, Maheep Chaudhary, Haohan Wang</p>

<p><strong>FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization</strong><br />Mingye Zhu, Yi Liu, Quan Wang, Junbo Guo, Zhendong Mao</p>

<p><strong>StorySpark: Expert-Annotated QA Pairs with Real-World Knowledge for Children Storytelling</strong><br />Jiaju Chen, Yuxuan Lu, Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li, Qianwen Wang, Dakuo Wang, Yuling Sun</p>

<p><strong>MedCoT: Medical Chain of Thought via Hierarchical Expert</strong><br />Jiaxiang Liu, Yuan Wang, Jiawei Du, Joey Tianyi Zhou, Zuozhu Liu</p>

<p><strong>Varying Sentence Representations via Condition-Specified Routers</strong><br />Ziyong Lin, Quansen Wang, Zixia Jia, Zilong Zheng</p>

<p><strong>Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues</strong><br />Jiao Ou, jiayu wu, Che Liu, Fuzheng Zhang, Di ZHANG, Kun Gai</p>

<p><strong>Information Flow Routes: Automatically Interpreting Language Models at Scale</strong><br />Javier Ferrando, Elena Voita</p>

<p><strong>A Simple yet Effective Training-free Prompt-free Approach to Chinese Spelling Correction Based on Large Language Models</strong><br />Houquan Zhou, Zhenghua Li, Bo Zhang, Chen Li, Shaopeng Lai, Ji Zhang, Fei Huang, Min Zhang</p>

<p><strong>Low-rank Subspace for Binding in Large Language Models</strong><br />Qin Dai, Benjamin Heinzerling, Kentaro Inui</p>

<p><strong>CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference</strong><br />Erxin Yu, Jing Li, Ming Liao, Siqi Wang, GAO Zuchen, Fei Mi, Lanqing HONG</p>

<p><strong>ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures</strong><br />Tobias Schimanski, Jingwei Ni, Roberto Spacey Martín, Nicola Ranger, Markus Leippold</p>

<p><strong>Context-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs</strong><br />LIU Ran, Zhongzhou Liu, Xiaoli Li, Yuan Fang</p>

<p><strong>Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness</strong><br />Shixuan Ma, Quan Wang</p>

<p><strong>Dual-oriented Disentangled Network with Counterfactual Intervention for Multimodal Intent Detection</strong><br />Zhanpeng Chen, Zhihong Zhu, Xianwei Zhuang, Zhiqi Huang, Yuexian Zou</p>

<p><strong>From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking</strong><br />Siyuan Wang, Zhuohan Long, Zhihao Fan, zhongyu wei</p>

<p><strong>Symbolic Working Memory Enhances Language Models for Complex Rule Application</strong><br />Siyuan Wang, zhongyu wei, Yejin Choi, Xiang Ren</p>

<p><strong>LLoCO: Learning Long Contexts Offline</strong><br />Sijun Tan, Xiuyu Li, Shishir G Patil, Ziyang Wu, Tianjun Zhang, Kurt Keutzer, Joseph E. Gonzalez, Raluca Popa</p>

<p><strong>Don’t Forget Your Reward Values: Language Model Alignment via Value-based Calibration</strong><br />Xin Mao, Feng-Lin Li, Huimin Xu, Wei Zhang, WANG CHEN, Anh Tuan Luu</p>

<p><strong>Mentor-KD: Making Small Language Models Better Multi-step Reasoners</strong><br />Hojae Lee, Junho Kim, SangKeun Lee</p>

<p><strong>Are Large Language Models Capable of Generating Human-Level Narratives?</strong><br />Yufei Tian, Tenghao Huang, Miri Liu, Derek Jiang, Alexander Spangher, Muhao Chen, Jonathan May, Nanyun Peng</p>

<p><strong>MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs</strong><br />Yerin Hwang, Yongil Kim, Yunah Jang, Jeesoo Bang, Hyunkyung Bae, Kyomin Jung</p>

<p><strong>Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction</strong><br />Haohui Lu, Usman Naseem</p>

<p><strong>Searching for Best Practices in Retrieval-Augmented Generation</strong><br />Xiaohua Wang, Zhenghua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo Xu, Tianyuan Shi, Zhengyuan Wang, Shizheng Li, Qi Qian, Ruicheng Yin, Changze Lv, Xiaoqing Zheng, Xuanjing Huang</p>

<p><strong>Moral Foundations of Large Language Models</strong><br />Marwa Abdulhai, Gregory Serapio-García, Clement CREPY, Daria Valter, John Canny, Natasha Jaques</p>

<p><strong>The Zeno’s Paradox of ‘Low-Resource’ Languages</strong><br />Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Benjamin Rosman, Thamar Solorio, Monojit Choudhury</p>

<p><strong>Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization</strong><br />Aseem Srivastava, Smriti Joshi, Tanmoy Chakraborty, Md Shad Akhtar</p>

<p><strong>Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition</strong><br />Pritika Ramu, Koustava Goswami, Apoorv Saxena, Balaji Vasan Srinivasan</p>

<p><strong>From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment</strong><br />Yusuke Hirota, Ryo Hachiuma, Chao-Han Huck Yang, Yuta Nakashima</p>

<p><strong>Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging</strong><br />Deyuan Liu, Zhanyue Qin, Hairu Wang, Zhao Yang, Zecheng Wang, Fangying Rong, Qingbin Liu, Yanchao Hao, Bo Li, Xi Chen, Cunhang Fan, Zhao Lv, Dianhui Chu, Zhiying Tu, Dianbo Sui</p>

<p><strong>Embedded Named Entity Recognition using Probing Classifiers</strong><br />Nicholas Popovic, Michael Färber</p>

<p><strong>Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training</strong><br />Zhou Zhang, Dongzeng Tan, Jiaan Wang, Yilong Chen, Jiarong Xu</p>

<p><strong>Data Contamination Can Cross Language Barriers</strong><br />Feng Yao, Yufan Zhuang, Zihao Sun, Sunan Xu, Animesh Kumar, Jingbo Shang</p>

<p><strong>Automated Essay Scoring: A Reflection on the State of the Art</strong><br />Shengjie Li, Vincent Ng</p>

<p><strong>Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate</strong><br />Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Shuming Shi, Zhaopeng Tu</p>

<p><strong>Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs</strong><br />Xin Zhou, Ping Nie, Yiwen Guo, Haojie Wei, Zhanqiu Zhang, Pasquale Minervini, Ruotian Ma, Tao Gui, Qi Zhang, Xuanjing Huang</p>

<p><strong>CURE: Context- and Uncertainty-Aware Mental Disorder Detection</strong><br />Migyeong Kang, goun choi, Hyolim Jeon, Ji hyun An, Daejin Choi, Jinyoung Han</p>

<p><strong>PepRec: Progressive Enhancement of Prompting for Recommendation</strong><br />Yakun Yu, Shi-ang Qi, Baochun Li, Di Niu</p>

<p><strong>In-Context Compositional Generalization for Large Vision-Language Models</strong><br />Chuanhao Li, Chenchen Jing, Zhen Li, Mingliang Zhai, Yuwei Wu, Yunde Jia</p>

<p><strong>Improving Zero-shot LLM Re-Ranker with Risk Minimization</strong><br />Xiaowei Yuan, Zhao Yang, Yequan Wang, Jun Zhao, Kang Liu</p>

<p><strong>Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory</strong><br />Xianwei Zhuang, Zhihong Zhu, Zhanpeng Chen, Yuxin Xie, Liming Liang, Yuexian Zou</p>

<p><strong>Label Confidence Weighted Learning for Target-level Sentence Simplification</strong><br />Jingshen Zhang, Xin Ying Qiu</p>

<p><strong>Quantum Recurrent Architectures for Text Classification</strong><br />Wenduan Xu, Stephen Clark, Douglas Brown, Gabriel Matos, Konstantinos Meichanetzidis</p>

<p><strong>Tree of Problems: Improving structured problem solving with compositionality</strong><br />Armel Randy Zebaze, Benoît Sagot, Rachel Bawden</p>

<p><strong>What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study</strong><br />Beatrice Savoldi, Sara Papi, Matteo Negri, Ana Guerberof-Arenas, Luisa Bentivogli</p>

<p><strong>Seg2Act: Global Context-aware Action Generation for Document Logical Structuring</strong><br />Zichao Li, Shaojie He, Meng Liao, Xuanang Chen, Yaojie Lu, Hongyu Lin, Yanxiong Lu, Xianpei Han, Le Sun</p>

<p><strong>Is C4 Dataset Enough for Pruning? An Investigation of Calibration Data for LLM Pruning</strong><br />Abhinav Bandari, Lu Yin, Cheng-Yu Hsieh, AJAY KUMAR JAISWAL, Tianlong Chen, Li Shen, Ranjay Krishna, Shiwei Liu</p>

<p><strong>Revisiting the Robustness of Watermarking to Paraphrasing Attacks</strong><br />Saksham Rastogi, Danish Pruthi</p>

<p><strong>A Survey of Ontology Expansion for Conversational Understanding</strong><br />Jinggui Liang, Yuxia Wu, Yuan Fang, Hao Fei, Lizi Liao</p>

<p><strong>Calibrating Language Models with Adaptive Temperature Scaling</strong><br />Johnathan Xie, Annie S Chen, Yoonho Lee, Eric Mitchell, Chelsea Finn</p>

<p><strong>Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?</strong><br />Fumiya Uchiyama, Takeshi Kojima, Andrew Gambardella, Qi Cao, Yusuke Iwasawa, Yutaka Matsuo</p>

<p><strong>Why do objects have many names? A study on word informativeness in language use and lexical systems.</strong><br />Eleonora Gualdoni, Gemma Boleda</p>

<p><strong>Dual-Space Knowledge Distillation for Large Language Models</strong><br />Songming Zhang, Xue Zhang, Zengkui Sun, Yufeng Chen, Jinan Xu</p>

<p><strong>NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition</strong><br />Elena Merdjanovska, Ansar Aynetdinov, Alan Akbik</p>

<p><strong>On the Universal Truthfulness Hyperplane Inside LLMs</strong><br />Junteng Liu, Shiqi Chen, Yu Cheng, Junxian He</p>

<p><strong>PairDistill: Pairwise Relevance Distillation for Dense Retrieval</strong><br />Chao-Wei Huang, Yun-Nung Chen</p>

<p><strong>User Inference Attacks on Large Language Models</strong><br />Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, Zheng Xu</p>

<p><strong>HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy</strong><br />YongKang Liu, Yiqun Zhang, Qian Li, Tong Liu, Shi Feng, Daling Wang, Yifei Zhang, Hinrich Schuetze</p>

<p><strong>Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models</strong><br />Yufang Liu, Tao Ji, Changzhi Sun, Yuanbin Wu, Aimin Zhou</p>

<p><strong>Simultaneous Masking, Not Prompting Optimization: A Paradigm Shift in Fine-tuning LLMs for Simultaneous Translation</strong><br />Matthew Raffel, Victor Agostinelli, Lizhong Chen</p>

<p><strong>ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback</strong><br />Qinzhuo Wu, Wei Liu, Jian Luan, Bin Wang</p>

<p><strong>Please note that I’m just an AI: Analysis of Behavior Patterns of LLMs in (Non-)offensive Speech Identification</strong><br />Esra Dönmez, Thang Vu, Agnieszka Falenska</p>

<p><strong>How to Compute the Probability of a Word</strong><br />Tiago Pimentel, Clara Meister</p>

<p><strong>A linguistically-motivated evaluation methodology for unraveling model’s abilities in reading comprehension tasks</strong><br />Elie Antoine, Frederic Bechet, Géraldine Damnati, Philippe Langlais</p>

<p><strong>GuardBench: A Large-Scale Benchmark for Guardrail Models</strong><br />Elias Bassani, Ignacio Sanchez</p>

<p><strong>Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering</strong><br />Yao Xu, Shizhu He, Jiabei Chen, Zihao Wang, Yangqiu Song, Hanghang Tong, Guang Liu, Jun Zhao, Kang Liu</p>

<p><strong>Language models and brains align due to more than next-word prediction and word-level information</strong><br />Gabriele Merlin, Mariya Toneva</p>

<p><strong>LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement</strong><br />Zijin Feng, Luyang Lin, Lingzhi Wang, Hong Cheng, Kam-Fai Wong</p>

<p><strong>CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures</strong><br />Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri</p>

<p><strong>A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache Compression</strong><br />Alessio Devoto, Yu Zhao, Simone Scardapane, Pasquale Minervini</p>

<p><strong>GOME: Grounding-based Metaphor Binding With Conceptual Elaboration For Figurative Language Illustration</strong><br />Linhao Zhang, Jintao Liu, Li Jin, Hao Wang, kaiwen wei, Guangluan Xu</p>

<p><strong>D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation</strong><br />Aida Mostafazadeh Davani, Mark Diaz, Dylan K Baker, Vinodkumar Prabhakaran</p>

<p><strong>PALM: Few-Shot Prompt Learning for Audio Language Models</strong><br />Asif Hanif, Maha Tufail Agro, Mohammad Areeb Qazi, Hanan Aldarmaki</p>

<p><strong>Annotator-Centric Active Learning for Subjective NLP Tasks</strong><br />Michiel van der Meer, Neele Falk, Pradeep K. Murukannaiah, Enrico Liscio</p>

<p><strong>Lost in Tokenization: How to Measure Word Surprisal From LM Token Probabilities</strong><br />Luca Malagutti, Juan Luis Gastaldi, Brian DuSell, Tim Vieira, Ryan Cotterell, Mario Giulianelli</p>

<p><strong>Enhanced Hallucination Detection in Neural Machine Translation through Simple Detector Aggregation</strong><br />Anas Himmi, Guillaume Staerman, Marine Picot, Pierre Colombo, Nuno M Guerreiro</p>

<p><strong>Jailbreaking LLMs with Arabic Transliteration and Arabizi</strong><br />Mansour Al Ghanim, saleh almohaimeed, Mengxin Zheng, Yan Solihin, Qian Lou</p>

<p><strong>Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models</strong><br />Zara Siddique, Liam Turner, Luis Espinosa-Anke</p>

<p><strong>Instruction Matters, a Simple yet Effective Task Selection Approach in Instruction Tuning for Specific Tasks</strong><br />Changho Lee, Janghoon Han, Seonghyeon Ye, Stanley Jungkyu Choi, Honglak Lee, Kyunghoon Bae</p>

<p><strong>Recurrent Alignment with Hard Attention for Hierarchical Text Rating</strong><br />Chenxi Lin, Ren Jiayu, Guoxiu He, Zhuoren Jiang, Haiyan yu, Xiaomin Zhu</p>

<p><strong>CHESS: Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification</strong><br />Junhui He, Shangyu Wu, Weidong Wen, Chun Jason Xue, Qingan Li</p>

<p><strong>Semformer: Transformer Language Models with Semantic Planning</strong><br />Yongjing Yin, Junran Ding, Kai Song, Yue Zhang</p>

<p><strong>DocCGen: Document-based Controlled Code Generation</strong><br />Sameer Pimparkhede, Mehant Kammakomati, Srikanth G. Tamilselvam, Prince Kumar, Ashok Pon Kumar, Pushpak Bhattacharyya</p>

<p><strong>Semantics and Sentiment: Cross-lingual Variations in Emoji Use</strong><br />Giulio Zhou, Sydelle de Souza, Ella Markham, Oghenetekevwe Kwakpovwe, Sumin Zhao</p>

<p><strong>The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations</strong><br />Daniel Akkerman, Phong Le, Raquel G. Alhama</p>

<p><strong>Transformers are Multi-State RNNs</strong><br />Matanel Oren, Michael Hassid, Nir Yarden, Yossi Adi, Roy Schwartz</p>

<p><strong>Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization</strong><br />Niyati Bafna, Kenton Murray, David Yarowsky</p>

<p><strong>Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion</strong><br />Kerem Zaman, Leshem Choshen, Shashank Srivastava</p>

<p><strong>Collective Critics for Creative Story Generation</strong><br />Minwook Bae, Hyounghun Kim</p>

<p><strong>Surprisal Curves of Discourse</strong><br />Eleftheria Tsipidi, Franz Nowak, Ryan Cotterell, Ethan Wilcox, Mario Giulianelli, Alex Warstadt</p>

<p><strong>Model-based Preference Optimization in Abstractive Summarization without Human Feedback</strong><br />Jaepill choi, Kyubyung Chae, Jiwoo Song, Yohan Jo, Taesup Kim</p>

<p><strong>Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?</strong><br />Wataru Hashimoto, Hidetaka Kamigaito, Taro Watanabe</p>

<p><strong>NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries</strong><br />Simona Emilova Doneva, Tilia Ellendorff, Jean-Philippe Goldman, Amelia Elaine Cannon, Gerold Schneider, Beate Sick, Benjamin Victor Ineichen</p>

<p><strong>Do Explanations Help or Hurt? Saliency Maps vs Natural Language Explanations in a Clinical Decision-Support Setting</strong><br />Maxime Guillaume Kayser, Bayar Menzat, Cornelius Emde, Bogdan Alexandru Bercean, Alex Novak, Abdalá Trinidad Espinosa Morgado, Bartlomiej Papiez, Susanne Gaube, Thomas Lukasiewicz, Oana-Maria Camburu</p>

<p><strong>Towards Faithful Knowledge Graph Explanation Through Deep Alignment in Commonsense Question Answering</strong><br />WEIHE ZHAI, Arkaitz Zubiaga, Bingquan Liu, Chengjie Sun, Yalong Zhao</p>

<p><strong>Generation with Dynamic Vocabulary</strong><br />Yanting Liu, Tao Ji, Yuanbin Wu, Xiaoling Wang, Changzhi Sun</p>

<p><strong>Argument Relation Classification through Discourse Markers and Adversarial Training</strong><br />Michele Luca Contalbo, Francesco Guerra, Matteo Paganelli</p>

<p><strong>Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection</strong><br />Abhishek Purushothama, Adam Wiemerslage, Katharina von der Wense</p>

<p><strong>Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval</strong><br />Dae Yon Hwang, Bilal Taha, Harshit Pande, Yaroslav Nechaev</p>

<p><strong>Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models</strong><br />Po-Heng Chen, Yun-Nung Chen</p>

<p><strong>Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation</strong><br />Ruiyu Xiao, Lei Wu, Yuhang Gou, Weinan Zhang, Ting Liu</p>

<p><strong>TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning</strong><br />Kate Sanders, Nathaniel Weir, Benjamin Van Durme</p>

<p><strong>Unsupervised Extraction of Dialogue Policies from Conversations</strong><br />Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien</p>

<p><strong>GRIZAL: Generative Prior-guided Zero-Shot Temporal Action Localization</strong><br />Onkar Kishor Susladkar, Gayatri Sudhir Deshmukh, Vandan Gorade, Sparsh Mittal</p>

<p><strong>Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality</strong><br />Youngtaek Oh, Jae Won Cho, Dong-Jin Kim, In So Kweon, Junmo Kim</p>

<p><strong>FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture</strong><br />Wenyan Li, Crystina Zhang, Jiaang Li, Qiwei Peng, Raphael Tang, Li Zhou, Weijia Zhang, Guimin Hu, Yifei Yuan, Anders Søgaard, Daniel Hershcovich, Desmond Elliott</p>

<p><strong>A Two-Step Approach for Data-Efficient French Pronunciation Learning</strong><br />Hoyeon Lee, Hyeeun Jang, JONGHWAN KIM, Jaemin Kim</p>

<p><strong>Exploring Intra and Inter-language Consistency in Embeddings with ICA</strong><br />Rongzhi Li, Takeru Matsuda, Hitomi Yanaka</p>

<p><strong>DetoxLLM: A Framework for Detoxification with Explanations</strong><br />Md Tawkat Islam Khondaker, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan</p>

<p><strong>Building a Multi-Platform, BERT Classifier for Detecting Connective Language</strong><br />Josephine Lukito, Bin Chen, Gina M. Masullo, Natalie Jomini Stroud</p>

<p><strong>ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models</strong><br />Yash Akhauri, Ahmed F AbouElhamayed, Jordan Dotzel, Zhiru Zhang, Alexander M Rush, Safeen Huda, Mohamed S Abdelfattah</p>

<p><strong>Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health</strong><br />Krishnapriya Vishnubhotla, Daniela Teodorescu, Mallory J Feldman, Kristen Lindquist, Saif M. Mohammad</p>

<p><strong>BLSP-Emo: Towards Empathetic Large Speech-Language Models</strong><br />Chen Wang, Minpeng Liao, Zhongqiang Huang, Junhong Wu, Chengqing Zong, Jiajun Zhang</p>

<p><strong>SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation</strong><br />Abhishek Divekar, Greg Durrett</p>

<p><strong>Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model</strong><br />Wenqi Zhang, Zhenglin Cheng, Yuanyu He, Mengna Wang, Yongliang Shen, Zeqi Tan, Guiyang Hou, Mingqian He, Yanna Ma, Weiming Lu, Yueting Zhuang</p>

<p><strong>DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts</strong><br />Mohammed Saidul Islam, Md Tahmid Rahman Laskar, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty</p>

<p><strong>DEM: Distribution Edited Model for Training with Mixed Data Distributions</strong><br />Dhananjay Ram, Aditya Rawal, Momchil Hardalov, Nikolaos Pappas, Sheng Zha</p>

<p><strong>Altogether: Image Captioning via Re-aligning Alt-text</strong><br />Hu Xu, Po-Yao Huang, Xiaoqing Tan, Ching-Feng Yeh, Jacob Kahn, Christine Jou, Gargi Ghosh, Omer Levy, Luke Zettlemoyer, Wen-tau Yih, Shang-Wen Li, Saining Xie, Christoph Feichtenhofer</p>

<p><strong>VerifyMatch: A Semi-Supervised Learning Paradigm for Natural Language Inference with Confidence-Aware MixUp</strong><br />Seo Yeon Park, Cornelia Caragea</p>

<p><strong>CaT-Bench: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans</strong><br />Yash Kumar Lal, Vanya Cohen, Nathanael Chambers, Niranjan Balasubramanian, Ray Mooney</p>

<p><strong>Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics</strong><br />Théo Gigant, Camille Guinaudeau, Marc decombas, Frederic Dufaux</p>

<p><strong>An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs</strong><br />Manuj Malik, Jing Jiang, Kian Ming A. Chai</p>

<p><strong>Investigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks</strong><br />Amit Parekh, Nikolas Vitsakis, Alessandro Suglia, Ioannis Konstas</p>

<p><strong>GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning</strong><br />Aleksander Ficek, Jiaqi Zeng, Oleksii Kuchaiev</p>

<p><strong>CoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing</strong><br />Xinyi He, Jiaru Zou, Yun Lin, Mengyu Zhou, Shi Han, Zejian Yuan, Dongmei Zhang</p>

<p><strong>Sequential API Function Calling Using GraphQL Schema</strong><br />Avirup Saha, Lakshmi Mandal, Balaji Ganesan, Sambit Ghosh, Renuka Sindhgatta, Carlos Eberhardt, Dan Debrunner, Sameep Mehta</p>

<p><strong>The Illusion of Competence: Evaluating the Effect of Explanations on Users’ Mental Models of Visual Question Answering Systems</strong><br />Judith Sieker, Simeon Junker, Ronja Utescher, Nazia Attari, Heiko Wersing, Hendrik Buschmeier, Sina Zarrieß</p>

<p><strong>Re-Evaluating Evaluation for Multilingual Summarization</strong><br />Jessica Zosa Forde, Ruochen Zhang, Lintang Sutawika, Alham Fikri Aji, Samuel Cahyawijaya, Genta Indra Winata, Minghao Wu, Carsten Eickhoff, Stella Biderman, Ellie Pavlick</p>

<p><strong>Video-Text Prompting for Weakly Supervised Spatio-Temporal Video Grounding</strong><br />Heng zhao, Zhao Yinjie, Bihan Wen, Yew-Soon Ong, Joey Tianyi Zhou</p>

<p><strong>A Fast and Sound Tagging Method for Discontinuous Named-Entity Recognition</strong><br />Caio Filippo Corro</p>

<p><strong>Factuality of Large Language Models in the Year 2024</strong><br />Yuxia Wang, Minghan Wang, Muhammad Arslan Manzoor, Fei Liu, Georgi Nenkov Georgiev, Rocktim Jyoti Das, Preslav Nakov</p>

<p><strong>Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation</strong><br />Youngwoo Kim, Razieh Rahimi, James Allan</p>

<p><strong>Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse</strong><br />Rongchen Guo, Isar Nejadgholi, Hillary Dawkins, Kathleen C. Fraser, Svetlana Kiritchenko</p>

<p><strong>DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers</strong><br />Rakesh R Menon, Shashank Srivastava</p>

<p><strong>IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning</strong><br />Soumya Suvra Ghosal, Samyadeep Basu, Soheil Feizi, Dinesh Manocha</p>

<p><strong>Scope-enhanced Compositional Semantic Parsing for DRT</strong><br />Xiulin Yang, Jonas Groschwitz, Alexander Koller, Johan Bos</p>

<p><strong>The Generation Gap: Exploring Age Bias Underlying in the Value Systems of Large Language Models</strong><br />Siyang Liu, Trisha Maturi, Bowen Yi, Siqi Shen, Rada Mihalcea</p>

<p><strong>TempoFormer: A Transformer for Temporally-aware Representations in Change Detection</strong><br />Talia Tseriotou, Adam Tsakalidis, Maria Liakata</p>

<p><strong>Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?</strong><br />Guillermo Marco, Julio Gonzalo, M.Teresa Mateo-Girona, Ramón del Castillo Santos</p>

<p><strong>Evaluating Diversity in Automatic Poetry Generation</strong><br />Yanran Chen, Hannes Gröner, Sina Zarrieß, Steffen Eger</p>

<p><strong>Evaluating Short-Term Temporal Fluctuations of Social Biases in Social Media Data and Masked Language Models</strong><br />Yi Zhou, Danushka Bollegala, Jose Camacho-Collados</p>

<p><strong>Delving into Qualitative Implications of Synthetic Data for Hate Speech Detection</strong><br />Camilla Casula, Sebastiano Vecellio Salto, Alan Ramponi, Sara Tonelli</p>

<p><strong>Grounding Language in Multi-Perspective Referential Communication</strong><br />Zineng Tang, Lingjun Mao, Alane Suhr</p>

<p><strong>Threshold-driven Pruning with Segmented Maximum Term Weights for Approximate Cluster-based Sparse Retrieval</strong><br />Yifan Qiao, Parker Carlson, Shanxiu He, Yingrui Yang, Tao Yang</p>

<p><strong>Error Analysis of Multilingual Language Models in Machine Translation for Low-resource Languages: A Case Study of Amharic to English Bi-directional Machine Translation</strong><br />Hizkiel Mitiku Alemayehu, Hamada M Zahera, Axel-Cyrille Ngonga Ngomo</p>

<p><strong>MIPD: Exploring Manipulation and Intention In a Novel Corpus of Polish Disinformation</strong><br />Arkadiusz Modzelewski, Giovanni Da San Martino, Pavel Savov, Magdalena Anna Wilczyńska, Adam Wierzbicki</p>

<p><strong>Unsupervised Discrete Representations of American Sign Language</strong><br />Artem Abzaliev, Rada Mihalcea</p>

<p><strong>Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models</strong><br />Chani Jung, Dongkwan Kim, Jiho Jin, Jiseon Kim, Yeon Seonwoo, Yejin Choi, Alice Oh, Hyunwoo Kim</p>

<p><strong>Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs</strong><br />Mihir Parmar, Hanieh Deilamsalehy, Franck Dernoncourt, Seunghyun Yoon, Ryan A. Rossi, Trung Bui</p>

<p><strong>Jump Starting Bandits with LLM-Generated Prior Knowledge</strong><br />Parand A. Alamdari, Yanshuai Cao, Kevin H. Wilson</p>

<p><strong>Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?</strong><br />Fırat Öncel, Matthias Bethge, Beyza Ermis, Mirco Ravanelli, Cem Subakan, Çağatay Yıldız</p>

<p><strong>Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation</strong><br />Ruotong Pan, Boxi Cao, Hongyu Lin, Xianpei Han, Jia Zheng, Sirui Wang, Xunliang Cai, Le Sun</p>

<p><strong>Virtual Personas for Language Models via an Anthology of Backstories</strong><br />Suhong Moon, Marwa Abdulhai, Minwoo Kang, Joseph Suh, Widyadewi Soedarmadji, Eran Kohen Behar, David Chan</p>

<p><strong>Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?</strong><br />Nemika Tyagi, Mihir Parmar, Mohith Kulkarni, Aswin RRV, Nisarg Patel, Mutsumi Nakamura, Arindam Mitra, Chitta Baral</p>

<p><strong>Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies</strong><br />Junlin Wang, Siddhartha Jain, Dejiao Zhang, Baishakhi Ray, Varun Kumar, Ben Athiwaratkun</p>

<p><strong>The Empirical Variability of Narrative Perceptions of Social Media Texts</strong><br />Joel Mire, Maria Antoniak, Elliott Ash, Andrew Piper, Maarten Sap</p>

<p><strong>Which questions should I answer? Salience Prediction of Inquisitive Questions</strong><br />Yating Wu, Ritika Rajesh Mangla, Alex Dimakis, Greg Durrett, Junyi Jessy Li</p>

<p><strong>Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues</strong><br />Lei Sun, Jinming Zhao, Qin Jin</p>

<p><strong>Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech</strong><br />Guan-Ting Lin, Wei Ping Huang, Hung-yi Lee</p>

<p><strong>Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities</strong><br />Sachit Menon, Richard Zemel, Carl Vondrick</p>

<p><strong>CodeJudge: Evaluating Code Generation with Large Language Models</strong><br />Weixi Tong, Tianyi Zhang</p>

<p><strong>Self-Training Large Language and Vision Assistant for Medical</strong><br />Guohao Sun, Can Qin, Huazhu Fu, Linwei Wang, ZHIQIANG TAO</p>

<p><strong>SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization</strong><br />Prakamya Mishra, Zonghai Yao, Parth Vashisht, Feiyun Ouyang, Beining Wang, Vidhi Dhaval Mody, hong yu</p>

<p><strong>Defending Jailbreak Prompts via In-Context Adversarial Game</strong><br />Yujun Zhou, Yufei Han, Haomin Zhuang, Kehan Guo, Zhenwen Liang, Hongyan Bao, Xiangliang Zhang</p>

<p><strong>Detecting Online Community Practices with Large Language Models: A Case Study of Pro-Ukrainian Publics on Twitter</strong><br />Kateryna Kasianenko, Shima Khanehzar, Stephen Wan, Ehsan Dehghan, Axel Bruns</p>

<p><strong>Multilingual Topic Classification in X: Dataset and Analysis</strong><br />Dimosthenis Antypas, Asahi Ushio, Francesco Barbieri, Jose Camacho-Collados</p>

<p><strong>MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models</strong><br />Wai-Chung Kwan, Xingshan Zeng, Yuxin Jiang, Yufei Wang, Liangyou Li, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong</p>

<p><strong>Updating CLIP to Prefer Descriptions Over Captions</strong><br />Amir Zur, Elisa Kreiss, Karel D’Oosterlinck, Christopher Potts, Atticus Geiger</p>

<p><strong>CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research</strong><br />Sian-Yao Huang, Cheng-Lin Yang, Che-Yu Lin, Chun-Ying Huang</p>

<p><strong>Back to School: Translation Using Grammar Books</strong><br />Jonathan Hus, Antonios Anastasopoulos</p>

<p><strong>VIEWS: Entity-Aware News Video Captioning</strong><br />Hammad Ayyubi, Tianqi Liu, Arsha Nagrani, Xudong Lin, Mingda Zhang, Anurag Arnab, feng han, Yukun Zhu, Xuande Feng, Kevin Zhang, Jialu Liu, Shih-Fu Chang</p>

<p><strong>Towards Aligning Language Models with Textual Feedback</strong><br />Saüc Abadal Lloret, Shehzaad Dhuliawala, Keerthiram Murugesan, Mrinmaya Sachan</p>

<p><strong>ATPO: Automatic Tree-Structured Prompt Optimization</strong><br />Sheng Yang, Yurong Wu, Yan Gao, Zineng Zhou, Xiaodi Sun, Bin Benjamin Zhu, Jian-Guang Lou, Zhiming Ding, Anbang Hu, Yuan Fang, Yunsong Li, Junyan Chen, Linjun Yang</p>

<p><strong>DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators</strong><br />Xinglin Lyu, Junhui Li, Yanqing Zhao, Min Zhang, Daimeng Wei, shimin tao, Hao Yang, Min Zhang</p>

<p><strong>DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection</strong><br />Devleena Das, Vivek Khetan</p>

<p><strong>Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models</strong><br />Yuko Nakagi, Takuya Matsuyama, Naoko Koide-Majima, Hiroto Q. Yamaguchi, Rieko Kubo, Shinji Nishimoto, Yu Takagi</p>

<p><strong>“They are uncultured”: Unveiling Covert Harms and Social Threats in LLM Generated Conversations</strong><br />Preetam Prabhu Srikar Dammu, Hayoung Jung, Anjali Singh, Monojit Choudhury, Tanu Mitra</p>

<p><strong>Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models</strong><br />Do Xuan Long, Duong Ngoc Yen, Anh Tuan Luu, Kenji Kawaguchi, Min-Yen Kan, Nancy F. Chen</p>

<p><strong>Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?</strong><br />Gabriel Roccabruna, Massimo Rizzoli, giuseppe riccardi</p>

<p><strong>Eliciting In-Context Learning in Vision-Language Models for Videos Through Curated Data Distributional Properties</strong><br />Keunwoo Peter Yu, Zheyuan Zhang, Fengyuan Hu, Shane Storks, Joyce Chai</p>

<p><strong>Framework for Robust and Scalable Text Watermarking</strong><br />Gregory Kang Ruey Lau, Xinyuan Niu, Hieu Dao, Jiangwei Chen, Chuan-Sheng Foo, Bryan Kian Hsiang Low</p>

<p><strong>MASIVE: Open-Ended Affective State Identification in English and Spanish</strong><br />Nicholas Deas, Elsbeth Turcan, Ivan Ernesto Perez Mejia, Kathleen McKeown</p>

<p><strong>You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions</strong><br />Tasnim Kabir, Yoo Yeon Sung, Saptarashmi Bandyopadhyay, Hao Zou, Abhranil Chandra, Jordan Lee Boyd-Graber</p>

<p><strong>AlphaExpert: Assigning LoRA Experts Based on Layer Training Quality</strong><br />Peijun Qing, Chongyang Gao, Yefan Zhou, Xingjian Diao, Yaoqing Yang, Soroush Vosoughi</p>

<p><strong>Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling</strong><br />Irfan Robbani, Paul Reisert, Surawat Pothong, Naoya Inoue, Camélia Guerraoui, Wenzhi Wang, Shoichi Naito, Jungmin Choi, Kentaro Inui</p>

<p><strong>Advancing Social Intelligence in AI Agents: Technical Challenges and Open Question</strong><br />Leena Mathur, Paul Pu Liang, Louis-Philippe Morency</p>

<p><strong>RAt: Injecting Implicit Bias for Text-To-Image Prompt Refinement Models</strong><br />Ziyi Kou, Shichao Pei, Meng Jiang, Xiangliang Zhang</p>

<p><strong>Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese</strong><br />Rifki Afina Putri, Faiz Ghifari Haznitrama, Dea Adhista, Alice Oh</p>

<p><strong>Learnability of Indirect Evidence in Language Models</strong><br />Miyu Oba, Yohei Oseki, Akiyo Fukatsu, Akari Haga, Hiroki Ouchi, Taro Watanabe, Saku Sugawara</p>

<p><strong>Do LLMs Know to Respect Copyright Notice?</strong><br />Jialiang Xu, SHENGLAN LI, Zhaozhuo Xu, Denghui Zhang</p>

<p><strong>SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding</strong><br />Hanchi Sun, Tianyi Zhou, Xun Chen, Lichao Sun</p>

<p><strong>Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding</strong><br />YeonJoon Jung, Jaeseong Lee, Seungtaek Choi, Dohyeon Lee, Minsoo Kim, seung-won hwang</p>

<p><strong>Rethinking the Role of Proxy Rewards in Language Model Alignment</strong><br />Sungdong Kim, Minjoon Seo</p>

<p><strong>Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant</strong><br />Abhirama Subramanyam Penamakuri, Anand Mishra</p>

<p><strong>How Good is my MT Metric? A Framework for the Interpretation of Metric Assessments</strong><br />Stefano Perrella, Lorenzo Proietti, Pere-Lluís Huguet Cabot, Edoardo Barba, Roberto Navigli</p>

<p><strong>IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning</strong><br />Soeun Lee, Si-Woo Kim, Taewhan Kim, Dong-Jin Kim</p>

<p><strong>SPREADSHEETLLM: Encoding Spreadsheets for Large Language Models</strong><br />Haoyu Dong, Jianbo Zhao, Yuzhang Tian, Junyu Xiong, Shiyu Xia, Mengyu Zhou, Yun Lin, José Cambronero, Yeye He, Shi Han, Dongmei Zhang</p>

<p><strong>Let’s discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality</strong><br />Rositsa V Ivanova, Thomas Huber, Christina Niklaus</p>

<p><strong>Automatic sentence segmentation of clinical record narratives in real-world data</strong><br />Dongfang Xu, Davy Weissenbacher, Karen O’Connor, Siddharth Rawal, Graciela Gonzalez Hernandez</p>

<p><strong>One-to-Many Communication and Compositionality in Emergent Communication</strong><br />Heeyoung Lee</p>

<p><strong>Bayesian Example Selection Improves In-Context Learning for Speech, Text, and Visual Modalities</strong><br />Siyin Wang, Chao-Han Huck Yang, Ji Wu, Chao Zhang</p>

<p><strong>Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand for Multilingual Instructions?</strong><br />Alexander Arno Weber, Klaudia Thellmann, Jan Ebert, Nicolas Flores-Herr, Jens Lehmann, Michael Fromm, Mehdi Ali</p>

<p><strong>Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models</strong><br />Nisarg Patel, Mohith Kulkarni, Mihir Parmar, Aashna Budhiraja, Mutsumi Nakamura, Neeraj Varshney, Chitta Baral</p>

<p><strong>Contrastive Classification via Linear Layer Extrapolation</strong><br />Mayukh Sharma, Sean O’Brien, Julian McAuley</p>

<p><strong>Task Oriented In-Domain Data Augmentation</strong><br />Xiao Liang, Xinyu Hu, Simiao Zuo, Yeyun Gong, Qiang Lou, Yi Liu, Shao-Lun Huang, Jian Jiao</p>

<p><strong>SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers</strong><br />Shruti Singh, Nandan Sarkar, Arman Cohan</p>

<p><strong>Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules</strong><br />Zhuocheng Gong, Ang Lv, Jian Guan, Wei Wu, Huishuai Zhang, Minlie Huang, Dongyan Zhao, Rui Yan</p>

<p><strong>No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages</strong><br />Youssef Mohamed, Runjia Li, Ibrahim Said Ahmad, Kilichbek Haydarov, Philip Torr, Kenneth Church, Mohamed Elhoseiny</p>

<p><strong>PREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection</strong><br />Someen Park, Jaehoon Kim, Seungwan Jin, Sohyun Park, Kyungsik Han</p>

<p><strong>TokenVerse: Unifying Speech and NLP Tasks via Transducer-based ASR</strong><br />Shashi Kumar, Srikanth Madikeri, Juan Pablo Zuluaga Gomez, Iuliia Thorbecke, Esaú VILLATORO-TELLO, Sergio Burdisso, Petr Motlicek, Karthik Pandia D S, Aravind Ganapathiraju</p>

<p><strong>ApiQ: Finetuning of 2-Bit Quantized Large Language Model</strong><br />Baohao Liao, Christian Herold, Shahram Khadivi, Christof Monz</p>

<p><strong>Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk</strong><br />Zhiyuan Zeng, Qipeng Guo, Xiaoran Liu, Zhangyue Yin, Wentao Shu, Mianqiu Huang, Bo Wang, Yunhua Zhou, Linlin Li, Qun Liu, Xipeng Qiu</p>

<p><strong>A Morphology-Based Investigation of Positional Encodings</strong><br />Poulami Ghosh, Shikhar Vashishth, Raj Dabre, Pushpak Bhattacharyya</p>

<p><strong>I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining</strong><br />Vahid Ghafouri, Jose M. Such, Guillermo Suarez-Tangil</p>

<p><strong>BiasWipe: Mitigating Unintended Bias in Text Classifiers through Model Interpretability</strong><br />Mamta Mamta, Rishikant Chigrupaatii, Asif Ekbal</p>

<p><strong>ArMeme: Propagandistic Content in Arabic Memes</strong><br />Firoj Alam, Abul Hasnat, Fatema Ahmad, Md. Arid Hasan, Maram Hasanain</p>

<p><strong>Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts</strong><br />Arianna Muti, Federico Ruggeri, Khalid Al Khatib, Alberto Barrón-Cedeño, Tommaso Caselli</p>

<p><strong>Thoughts to Target: Enhance Planning for Target-driven Conversation</strong><br />Zhonghua Zheng, Lizi Liao, Yang Deng, Ee-Peng Lim, Minlie Huang, Liqiang Nie</p>

<p><strong>Scalable Data Ablation Approximations for Language Models through Modular Training and Merging</strong><br />Clara Na, Ian Magnusson, Ananya Harsh Jha, Tom Sherborne, Emma Strubell, Jesse Dodge, Pradeep Dasigi</p>

<p><strong>Exploring Intrinsic Language-specific Subspaces in Fine-tuning Multilingual Neural Machine Translation</strong><br />Zhe Cao, Zhi Qu, Hidetaka Kamigaito, Taro Watanabe</p>

<p><strong>Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters</strong><br />Zhiyu Guo, Hidetaka Kamigaito, Taro Watanabe</p>

<p><strong>Generative Subgraph Retrieval for Knowledge Graph–Grounded Dialog Generation</strong><br />Jinyoung Park, Minseok Joo, Joo-Kyung Kim, Hyunwoo J. Kim</p>

<p><strong>Adapters Mixup: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers</strong><br />Tuc Van Nguyen, Thai Le</p>

<p><strong>Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4</strong><br />Woojin Kim, Sungeun Hahm, Jaejin Lee</p>

<p><strong>Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game</strong><br />Prisha Samdarshi, Mariam Mustafa, Anushka Kulkarni, Raven Rothkopf, Tuhin Chakrabarty, Smaranda Muresan</p>

<p><strong>GottBERT: a pure German Language Model</strong><br />Raphael Scheible, Johann Frei, Fabian Thomczyk, Henry He, Patric Tippmann, Jochen Knaus, Victor Jaravine, Frank Kramer, Martin Boeker</p>

<p><strong>Computational Meme Understanding: A Survey</strong><br />Khoi P. N. Nguyen, Vincent Ng</p>

<p><strong>CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage</strong><br />Costas Mavromatis, Balasubramaniam Srinivasan, Zhengyuan Shen, Jiani Zhang, Huzefa Rangwala, Christos Faloutsos, George Karypis</p>

<p><strong>Retrieval-enriched zero-shot image classification in low-resource domains</strong><br />Nicola Dall’Asen, Yiming Wang, Enrico Fini, Elisa Ricci</p>

<p><strong>I-AM-G: Interest Augmented Multimodal Generator for Item Personalization</strong><br />Xianquan Wang, Likang Wu, Shukang Yin, Zhi Li, Yanjiang Chen, hufeng, Yu Su, Qi Liu</p>

<p><strong>Twists, Humps, and Pebbles: Multilingual Speech Recognition Models Exhibit Gender Performance Gaps</strong><br />Giuseppe Attanasio, Beatrice Savoldi, Dennis Fucci, Dirk Hovy</p>

<p><strong>Enhancing Language Model Alignment: A Confidence-Based Approach to Label Smoothing</strong><br />Baihe Huang, Hiteshi Sharma, Yi Mao</p>

<p><strong>Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion</strong><br />Yannis Flet-Berliac, Nathan Grinsztajn, Florian Strub, Eugene Choi, Bill Wu, Chris Cremer, Arash Ahmadian, Yash Chandak, Mohammad Gheshlaghi Azar, Olivier Pietquin, Matthieu Geist</p>

<p><strong>Show and Guide: Instructional-Plan Grounded Vision and Language Model</strong><br />Diogo Glória-Silva, David Semedo, Joao Magalhaes</p>

<p><strong>Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents</strong><br />Bandhav Veluri, Benjamin N Peloquin, Bokai YU, Hongyu Gong, Shyamnath Gollakota</p>

<p><strong>QuBE: Question-based Belief Enhancement for Agentic LLM</strong><br />Minsoo Kim, Jongyoon Kim, Jihyuk Kim, seung-won hwang</p>

<p><strong>COMPACT: Compressing Retrieved Documents Actively for Question Answering</strong><br />Chanwoong Yoon, Taewhoo Lee, Hyeon Hwang, Minbyul Jeong, Jaewoo Kang</p>

<p><strong>An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models</strong><br />Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Reza Haf, Yuan-Fang Li</p>

<p><strong>Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models</strong><br />Jiaxin Zhang, Wendi Cui, Yiran Huang, Kamalika Das, Sricharan Kumar</p>

<p><strong>Local Contrastive Editing of Gender Stereotypes</strong><br />Marlene Lutz, Rochelle Choenni, Markus Strohmaier, Anne Lauscher</p>

<p><strong>De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP</strong><br />Stefan Larson, Nicole Cornehl Lima, Santiago Pedroza Diaz, Amogh Manoj Joshi, Siddharth Betala, Jamiu Tunde Suleiman, Yash Mathur, Kaushal Kumar Prajapati, Ramla Alakraa, Junjie Shen, Temi Okotore, Kevin Leach</p>

<p><strong>RAR: Retrieval Augmented Retrieval for Code Generation in Low Resource Languages</strong><br />Avik Dutta, Mukul Singh, Gust Verbruggen, Sumit Gulwani, Vu Le</p>

<p><strong>STAR: SocioTechnical Approach to Red Teaming Language Models</strong><br />Laura Weidinger, John F J Mellor, Bernat Guillén Pegueroles, Nahema Marchal, Ravin Kumar, Kristian Lum, Canfer Akbulut, Mark Diaz, A. Stevie Bergman, Mikel D. Rodriguez, Verena Rieser, William Isaac</p>

<p><strong>Do great minds think alike? Investigating Human-AI Complementarity for Question Answering</strong><br />Maharshi Gor, Hal Daumé III, Tianyi Zhou, Jordan Lee Boyd-Graber</p>

<p><strong>Memory-Efficient Fine-Tuning of Transformers via Token Selection</strong><br />Antoine Simoulin, Namyong Park, Xiaoyi Liu, Grey Yang</p>

<p><strong>Unveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories</strong><br />Tarun Tater, Sabine Schulte im Walde, Diego Frassinelli</p>

<p><strong>Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark</strong><br />Elizabeth Fons, Rachneet Kaur, Soham Palande, Zhen Zeng, Tucker Balch, Manuela Veloso, Svitlana Vyetrenko</p>

<p><strong>Can LLMs Learn Uncertainty on Their Own? Expressing Uncertainty Effectively in A Self-Training Manner</strong><br />Shudong Liu, Zhaocong Li, Xuebo Liu, Runzhe Zhan, Derek F. Wong, Lidia S. Chao, Min zhang</p>

<p><strong>Preference-Guided Reflective Sampling for Aligning Language Models</strong><br />Hai Ye, Hwee Tou Ng</p>

<p><strong>Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP</strong><br />Pieter Delobelle, Giuseppe Attanasio, Debora Nozza, Su Lin Blodgett, Zeerak Talat</p>

<p><strong>Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs</strong><br />Xuhui Zhou, Zhe Su, Tiwalayo Eisape, Hyunwoo Kim, Maarten Sap</p>

<p><strong>A Simple LLM Framework for Long-Range Video Question-Answering</strong><br />Ce Zhang, Taixi Lu, Md Mohaiminul Islam, Ziyang Wang, Shoubin Yu, Mohit Bansal, Gedas Bertasius</p>

<p><strong>Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing</strong><br />Akshat Gupta, Sidharth Baskaran, Gopala Anumanchipalli</p>

<p><strong>Casablanca: Data and Models for Multidialectal Arabic Speech Recognition</strong><br />Bashar Talafha, Karima Kadaoui, Samar Mohamed Magdy, Mariem Habiboullah, Chafei Mohamed Chafei, Ahmed Oumar El-Shangiti, Hiba Zayed, Mohamedou cheikh tourad, Rahaf Alhamouri, Rwaa Assi, Aisha Alraeesi, Hour Mohamed, Fakhraddin Alwajih, Abdelrahman Mohamed, Abdellah EL MEKKI, El Moatez Billah Nagoudi, Benelhadj Djelloul Mama Saadia, Hamzah A. Alsayadi, Walid Al-Dhabyani, Sara Shatnawi, Yasir ECH-CHAMMAKHY, AMAL MAKOUAR, Yousra Berrachedi, Mustafa Jarrar, Shady Shehata, Ismail Berrada, Muhammad Abdul-Mageed</p>

<p><strong>Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations</strong><br />Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria</p>

<p><strong>Communicating with Speakers and Listeners of Different Pragmatic Levels</strong><br />Kata Naszadi, Frans A Oliehoek, Christof Monz</p>

<p><strong>RECANTFormer: Referring Expression Comprehension with Varying Numbers of Targets</strong><br />Bhathiya Hemanthage, Hakan Bilen, Phil Bartie, Christian Dondrup, Oliver Lemon</p>

<p><strong>Sprout: Green Generative AI with Carbon-Efficient LLM Inference</strong><br />Baolin Li, Yankai Jiang, Vijay Gadepally, Devesh Tiwari</p>

<p><strong>Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs</strong><br />Alexander Spangher, Nanyun Peng, Sebastian Gehrmann, Mark Dredze</p>

<p><strong>T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings</strong><br />Björn Deiseroth, Manuel Brack, Samuel Weinbach, Patrick Schramowski, Kristian Kersting</p>

<p><strong>SpeechQE: Estimating the Quality of Direct Speech Translation</strong><br />HyoJung Han, Kevin Duh, Marine Carpuat</p>

<p><strong>Assessing and Verifying Task Utility in LLM-Powered Applications</strong><br />Negar Arabzadeh, Siqing Huo, Nikhil Mehta, Qingyun Wu, Chi Wang, Ahmed Hassan Awadallah, Charles L. A. Clarke, Julia Kiseleva</p>

<p><strong>Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models</strong><br />Somanshu Singla, Zhen Wang, Tianyang Liu, Abdullah Ashfaq, Zhiting Hu, Eric P. Xing</p>

<p><strong>Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree</strong><br />Harbani Jaggi, Kashyap Coimbatore Murali, Eve Fleisig, Erdem Biyik</p>

<p><strong>Adversarial Text Generation using Large Language Models for Dementia Detection</strong><br />Youxiang Zhu, Nana Lin, Kiran Sandilya Balivada, Daniel Haehn, Xiaohui Liang</p>

<p><strong>xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics</strong><br />Daniil Larionov, Mikhail Seleznyov, Vasiliy Viskov, Alexander Panchenko, Steffen Eger</p>

<p><strong>The Greatest Good Benchmark: Measuring LLMs’ Alignment with Utilitarian Moral Dilemmas</strong><br />Giovanni Franco Gabriel Marraffini, Andrés Cotton, Noe Fabian Hsueh, Juan Wisznia, Axel Fridman, Luciano Del Corro</p>

<p><strong>FairFlow: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding</strong><br />Jiali Cheng, Hadi Amiri</p>

<p><strong>Style-Shifting Behaviour of the Manosphere on Reddit</strong><br />Jai Aggarwal, Suzanne Stevenson</p>

<p><strong>The Death and Life of Great Prompts: Analyzing the Evolution of LLM Prompts from the Structural Perspective</strong><br />Yihan Ma, Xinyue Shen, Yixin Wu, Boyang Zhang, Michael Backes, Yang Zhang</p>

<p><strong>Holistic Evaluation for Interleaved Text-and-Image Generation</strong><br />Minqian Liu, Zhiyang Xu, Zihao Lin, Trevor Ashby, Joy Rimchala, Jiaxin Zhang, Lifu Huang</p>

<p><strong>FOLIO: Natural Language Reasoning with First-Order Logic</strong><br />SIMENG HAN, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Wenfei Zhou, James Coady, David Peng, Yujie Qiao, Luke Benson, Lucy Sun, Alexander Wardle-Solano, Hannah Szabó, Ekaterina Zubova, Matthew Burtell, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Alexander Fabbri, Wojciech Maciej Kryscinski, Semih Yavuz, Ye Liu, Xi Victoria Lin, Shafiq Joty, Yingbo Zhou, Caiming Xiong, Rex Ying, Arman Cohan, Dragomir Radev</p>

<p><strong>The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?</strong><br />Alexander Choi, Syeda Sabrina Akter, J.P. Singh, Antonios Anastasopoulos</p>

<p><strong>Is Child-Directed Speech Effective Training Data for Language Models?</strong><br />Steven Y. Feng, Noah Goodman, Michael Frank</p>

<p><strong>RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference</strong><br />Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao</p>

<p><strong>HCEG: Improving the Abstraction Ability of Language Models with Hierarchical Conceptual Entailment Graphs</strong><br />Juncai Li, Ru Li, Xiaoli Li, Qinghua Chai, Jeff Z. Pan</p>

<p><strong>M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought</strong><br />Gitanjali Kumari, Kirtan Jain, Asif Ekbal</p>

<p><strong>GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation</strong><br />Govind Ramesh, Yao Dou, Wei Xu</p>

<p><strong>RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation</strong><br />Kiseung Kim, Jay-Yoon Lee</p>

<p><strong>Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets</strong><br />Vatsal Gupta, Pranshu Pandya, Tushar Kataria, Vivek Gupta, Dan Roth</p>

<p><strong>Simul-MuST-C: Simultaneous Multilingual Speech Translation Corpus Using Large Language Model</strong><br />Mana Makinae, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe</p>

<p><strong>Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text</strong><br />Pritika Ramu, Aparna Garimella, Sambaran Bandyopadhyay</p>

<p><strong>On the Fragility of Active Learners for Text Classification</strong><br />Abhishek Ghose, Emma Thuong Nguyen</p>

<p><strong>BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers</strong><br />Ran Xu, Wenqi Shi, Yue Yu, Yuchen Zhuang, Yanqiao Zhu, May Dongmei Wang, Joyce C. Ho, Chao Zhang, Carl Yang</p>

<p><strong>Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval</strong><br />Jonghyun Song, Cheyon Jin, Wenlong Zhao, Jay-Yoon Lee</p>

<p><strong>M3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection</strong><br />Chia-Wei Tang, Ting-Chih Chen, Alvi Md Ishmam, Kiet A. Nguyen, Kazi Sajeed Mehrab, Chris Thomas</p>

<p><strong>MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning</strong><br />Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Haotian Sun, Hang Wu, Carl Yang, May Dongmei Wang</p>

<p><strong>EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records</strong><br />Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda Zhu, Joyce C. Ho, Carl Yang, May Dongmei Wang</p>

<p><strong>SimLLM: Detecting Sentences Generated by Large Language Models Using Similarity between the Generation and its Re-generation</strong><br />Hoang-Quoc Nguyen-Son, Minh-Son Dao, Koji Zettsu</p>

<p><strong>CELLO: Causal Evaluation of Large Vision-Language Models</strong><br />Meiqi Chen, Bo Peng, Yan Zhang, Chaochao Lu</p>

<p><strong>Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair</strong><br />Yusuke Sakai, Mana Makinae, Hidetaka Kamigaito, Taro Watanabe</p>

<p><strong>Training-free Deep Concept Injection Enables Language Models for Video Question Answering</strong><br />Xudong Lin, Manling Li, Richard Zemel, Heng Ji, Shih-Fu Chang</p>

<p><strong>MIBench: Evaluating Multimodal Large Language Models over Multiple Images</strong><br />Haowei Liu, Xi Zhang, Haiyang Xu, Yaya Shi, Chaoya Jiang, Ming Yan, Ji Zhang, Fei Huang, Chunfeng Yuan, Bing Li, Weiming Hu</p>

<p><strong>ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering</strong><br />Francesco Maria Molfese, Simone Conia, Riccardo Orlando, Roberto Navigli</p>

<p><strong>ABLE: Personalized Disability Support with Politeness and Empathy Integration</strong><br />Kshitij Mishra, Manisha Burja, Asif Ekbal</p>

<p><strong>Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models</strong><br />Hyungjoo Chae, Yeonghyeon Kim, Seungone Kim, Kai Tzu-iunn Ong, Beong-woo Kwak, Moohyeon Kim, Sunghwan Kim, Taeyoon Kwon, Jiwan Chung, Youngjae Yu, Jinyoung Yeo</p>

<p><strong>Coffee-Gym: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code</strong><br />Hyungjoo Chae, Taeyoon Kwon, Seungjun Moon, Yongho Song, Dongjin Kang, Kai Tzu-iunn Ong, Beong-woo Kwak, Seonghyeon Bae, seung-won hwang, Jinyoung Yeo</p>

<p><strong>Improving Minimum Bayes Risk Decoding with Multi-Prompt</strong><br />David Heineman, Yao Dou, Wei Xu</p>

<p><strong>Deciphering Cognitive Distortions in Patient-Doctor Mental Health Conversations: A Multimodal LLM-Based Detection and Reasoning Framework</strong><br />gopendra Vikram singh, Sai Vardhan Vemulapalli, Mauajama Firdaus, Asif Ekbal</p>

<p><strong>Nearest Neighbor Normalization Improves Multimodal Retrieval</strong><br />Neil Chowdhury, Franklin Wang, Sumedh Shenoy, Douwe Kiela, Sarah Schwettmann, Tristan Thrush</p>

<p><strong>Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning</strong><br />Shengguang Wu, Shusheng Yang, Zhenglun Chen, Qi Su</p>

<p><strong>LongRAG: A Dual-perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering</strong><br />Qingfei Zhao, Ruobing Wang, Yukuo Cen, Daren Zha, Shicheng Tan, Yuxiao Dong, Jie Tang</p>

<p><strong>Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models</strong><br />Yuxuan Guo, Zhiliang Tian, YIPING SONG, Tianlun Liu, Liang Ding, Dongsheng Li</p>

<p><strong>Knowledge Graph Enhanced Large Language Model Editing</strong><br />Mengqi Zhang, Xiaotian Ye, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen</p>

<p><strong>Quis custodiet ipsos custodes?’ Who will watch the watchmen? On Detecting AI-generated peer-reviews</strong><br />Sandeep Kumar, Mohit Sahu, Vardhan Gacche, Tirthankar Ghosal, Asif Ekbal</p>

<p><strong>Mitigating Open-Vocabulary Caption Hallucinations</strong><br />Assaf Ben-Kish, Moran Yanuka, Morris Alper, Raja Giryes, Hadar Averbuch-Elor</p>

<p><strong>Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes</strong><br />Kosuke Nishida, Kyosuke Nishida, Kuniko Saito</p>

<p><strong>ALVIN: Active Learning Via INterpolation</strong><br />Michalis Korakakis, Andreas Vlachos</p>

<p><strong>Filtered Direct Preference Optimization</strong><br />Tetsuro Morimura, Mitsuki Sakamoto, Yuu Jinnai, Kenshi Abe, Kaito Ariu</p>

<p><strong>Instruction Fine-Tuning: Does Prompt Loss Matter?</strong><br />Mathew Huerta-Enochian, Seung Yong Ko</p>

<p><strong>Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia</strong><br />Tomás Feith, Akhil Arora, Martin Gerlach, Debjit Paul, Robert West</p>

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/emnlpmeeting" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/shyyhs/emnlp-2025/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    <li><a href="_pages/home.md"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 emnlp. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>













  </body>
</html>
