<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" /><updated>2025-09-18T20:39:36-05:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">EMNLP 2025</title><subtitle>Official website for the 2025 Conference on Empirical Methods in Natural Language Processing</subtitle><author><name>Haiyue Song</name></author><entry><title type="html">New Desk Rejection Practice for EMNLP 2025</title><link href="http://0.0.0.0:4000/desk-rejection/" rel="alternate" type="text/html" title="New Desk Rejection Practice for EMNLP 2025" /><published>2025-08-19T00:00:00-05:00</published><updated>2025-08-19T00:00:00-05:00</updated><id>http://0.0.0.0:4000/desk-rejection</id><content type="html" xml:base="http://0.0.0.0:4000/desk-rejection/"><![CDATA[<p>For some time there has been substantial concern within the community regarding many aspects of reviewing, from poor quality, to too few reviewers in the pool, to poor quality reviews, to reviewers not even doing their reviews or resorting to AI generated reviews. In light of these circumstances, this year’s EMNLP PCs are taking reviewer responsibility very seriously as a step towards incentivizing more conscientious reviewer behavior.</p>

<p>In our communication with the community, we – the EMNLP 2025 PC chairs – have already indicated that desk rejections would be levied in the case of reviewer irresponsibility.  As a first step, in this cycle, we are only desk-rejecting (and disallowing submission to the next ARR cycle) papers where at least one author met all the following criteria, as these represent severe violations of our reviewer policy <a href="https://2025.emnlp.org/reviewer-policies">https://2025.emnlp.org/reviewer-policies</a>:</p>

<ul>
  <li>They were assigned papers to review at the beginning of the review cycle (i.e. not emergency reviews).</li>
  <li>They were a reviewer with at least 3 assigned papers and failed to submit 100% of their reviews despite multiple reminders.</li>
  <li>They did not submit an Emergency declaration or a Delay notification.
In future cycles, this effort will extend more broadly to include those with a reduced workload, or did some portion, but not enough, of what they were assigned.  So be mindful in order to avoid suffering one or more desk rejections.</li>
</ul>

<p>We hope that this measure will ultimately help improve the overall quality and consistency of reviews, benefiting both authors and the community as a whole.</p>

<hr />

<p><em>The following is our reply to the authors who have requested an appeal of our decision.</em></p>

<p>We understand that receiving a desk rejection, particularly after the considerable time, effort, and care invested in preparing and submitting your work, as well as going through the initial review and author response process, can be deeply disappointing. Please know that these enforcement actions were not taken lightly and were reached after two months of careful discussion among the EMNLP PCs, the ARR EiCs, and the ACL Publication Ethics Committee. Out of the 13,048 reviewers recruited this year, only 69 were deemed “highly irresponsible” under our standards, and enforcement was applied solely in those cases. We truly recognize the contributions these community members intended to make when they committed to the role of reviewer. These reviewers were contacted multiple times regarding their review duties, as well as being personally contacted  by the area chairs and senior area chairs, but still failed to fulfill them. It is regrettable that co-authors of these reviewers were also affected by these consequences, and we acknowledge the impact this has on authors who fulfilled their own obligations.</p>

<p>Following the notifications, some authors asked whether it would be possible to remove the irresponsible reviewer(s) from the author list so the paper may proceed. This would have allowed the paper to be considered for EMNLP or resubmitted to ARR. Though we seriously considered this, we and the ACL Publication Ethics Committee determined that this would be in violation of the ACL Authorship guidelines.</p>

<p>We do want to emphasize that the consequences for highly irresponsible reviewing behavior were explicitly stated on the <a href="https://aclrollingreview.org/incentives2025">ACL Rolling Review’s 2025 Incentives page</a> - although we acknowledge that clearer alignment between ACL’s policy language (“not be able to commit […] to EMNLP”) and the term “desk rejection” could help avoid confusion:</p>

<p>“The reviewers or chairs deemed ‘highly irresponsible’ by the program chairs will not be able to commit their work to EMNLP, or (re-)submit their work to the subsequent ARR cycle.”</p>

<p>In addition, shortly after the submission deadline, on May 22, we sent reminder emails to all authors whose co-authors had not yet completed the author registration form. These emails explicitly mentioned the consequence of desk rejection if the form was not submitted, and encouraged submitting authors to ensure that all co-authors were aware of and completed the requirement. Importantly, the author registration form explicitly asked each author to confirm their availability and consent to serving as a reviewer. This step was a key part of ensuring that all authors were aware of and agreed to the reviewing requirements before the process began.</p>

<p>We recognize that more frequent reminders throughout the process may help reinforce these expectations. We will take these into account for future communications. Our goal remains to maintain fairness in the process while upholding the integrity and timeliness of the review cycle.</p>

<p>Regards,
Christos, Tanmoy, Carolyn, Violet - EMNLP PCs</p>]]></content><author><name>Haiyue Song</name></author><summary type="html"><![CDATA[For some time there has been substantial concern within the community regarding many aspects of reviewing, from poor quality, to too few reviewers in the pool, to poor quality reviews, to reviewers not even doing their reviews or resorting to AI generated reviews. In light of these circumstances, this year’s EMNLP PCs are taking reviewer responsibility very seriously as a step towards incentivizing more conscientious reviewer behavior.]]></summary></entry><entry><title type="html">New Tracks at EMNLP 2025 and Their Relationship to ARR Tracks</title><link href="http://0.0.0.0:4000/track-changes/" rel="alternate" type="text/html" title="New Tracks at EMNLP 2025 and Their Relationship to ARR Tracks" /><published>2025-05-06T00:00:00-05:00</published><updated>2025-05-06T00:00:00-05:00</updated><id>http://0.0.0.0:4000/track-changes</id><content type="html" xml:base="http://0.0.0.0:4000/track-changes/"><![CDATA[<p>As we prepare for EMNLP 2025, many of you may have noticed that we are introducing several new tracks and making adjustments to our area list. You might also notice that there are some differences between the EMNLP tracks and those currently reflected in the ACL Rolling Review (ARR) system. Note that the EMNLP tracks will apply only at the commitment stage, i.e. after the ARR reviewing cycle is finished. At initial submission time you will need to choose among the ARR tracks. To help with this transition, the ARR area keywords have been updated to better align with the new EMNLP tracks. You can search for your preferred sub-areas and their associated ARR track here: <a href="https://aclrollingreview.org/areas">https://aclrollingreview.org/areas</a>. We wanted to take a moment to explain the motivations behind these decisions and how they fit into the broader picture of our field’s evolution.</p>

<h2 id="why-we-are-adding-new-tracks">Why We Are Adding New Tracks</h2>

<p>The field of NLP is rapidly evolving. Areas that were once niche have grown into major subfields, and entirely new topics have emerged. To encourage cutting-edge research, EMNLP 2025 will:</p>

<ul>
  <li>
    <p><strong>Create space and foster community for fast-growing and emerging research areas</strong> that deserve focused attention.</p>
  </li>
  <li>
    <p><strong>Experiment with track structure</strong> in a way that informs <strong>future ARR reforms</strong>.<br />
EMNLP, as a one-off event, gives us the flexibility to pilot changes that can later help ARR evolve thoughtfully and responsibly.</p>
  </li>
</ul>

<p>While <strong>ARR needs to maintain long-term stability</strong>, commitment stages of individual conferences can be <strong>more agile</strong> – and the lessons from this conference will provide valuable feedback and inform more permanent changes to the ARR tracks going forward.</p>

<h2 id="whats-being-added-and-the-relationship-with-arr-existing-tracks">What’s Being Added and The Relationship with ARR Existing Tracks</h2>

<p>Here’s a summary of the new or adjusted tracks, organized by the reasoning behind them:</p>

<h3 id="1-recognizing-emerging-research-areas">1. Recognizing Emerging Research Areas</h3>

<p>We are creating or highlighting tracks to reflect research areas that have recently expanded rapidly:</p>

<ul>
  <li><strong>Safety and Alignment in LLMs</strong></li>
  <li><strong>AI/LLM Agents</strong></li>
  <li><strong>Code Models</strong></li>
  <li><strong>Neurosymbolic Approaches to NLP</strong></li>
  <li><strong>Mathematical, Symbolic, and Logical Reasoning</strong></li>
  <li><strong>Generalizability and Transfer</strong></li>
  <li><strong>LLM Efficiency</strong></li>
</ul>

<h3 id="2-expandingclarifying-existing-areas">2. Expanding/Clarifying Existing Areas</h3>

<p>To clarify reviewer expertise and topic boundaries, we also propose the following changes:</p>

<ul>
  <li>
    <p><strong>Information Extraction and Retrieval</strong><br />
Merged from the tracks of <em>information extraction and Information Retrieval and Text Mining</em> tracks</p>
  </li>
  <li>
    <p><strong>Interpretability, Model Editing, and Explainability</strong>:<br />
Expanded from the <em>Interpretability and Analysis</em> track</p>
  </li>
  <li>
    <p><strong>Hierarchical Structure Prediction, Syntax, and Parsing</strong>:<br />
Added hierarchical structure prediction as a keyword under the <em>Syntax and Parsing</em> track to better reflect current research directions.</p>
  </li>
</ul>

<h3 id="3-mapping-to-arr-tracks">3. Mapping to ARR Tracks</h3>

<p>The following EMNLP 2025 tracks will be organized as sub-areas under the ARR track <strong>Language Modeling:</strong></p>

<ul>
  <li><strong>Safety and Alignment in LLMs</strong></li>
  <li><strong>AI/LLM Agents</strong></li>
  <li><strong>Code Models</strong></li>
  <li><strong>Neurosymbolic Approaches to NLP</strong></li>
</ul>

<p>The following EMNLP 2025 tracks will be organized as sub-areas under the ARR track <strong>Machine Learning for NLP:</strong></p>

<ul>
  <li><strong>Mathematical, Symbolic, and Logical Reasoning</strong></li>
  <li><strong>Generalizability and Transfer</strong></li>
</ul>

<p>The EMNLP 2025 track of <strong>LLM Efficiency</strong> will be organized as sub-areas under the ARR track <strong>Efficient/Low-Resource Methods for NLP.</strong></p>

<p>The EMNLP 2025 track of <strong>Information Extraction and Retrieval</strong> essentially merged the ARR tracks of <strong>Information Extraction</strong> and <strong>Information Retrieval and Text Mining.</strong></p>

<h2 id="closing-remarks">Closing Remarks</h2>

<p>The track updates at EMNLP 2025 are more than just adjustments for this year — they are an opportunity to <strong>proactively shape the future of our community</strong>.</p>

<p>By experimenting with new tracks and structures now, we hope to <strong>gain valuable insights</strong> into submission patterns, reviewing quality, and community needs — insights that can <strong>inform the evolution of the ACL Rolling Review</strong> for the better.</p>

<p>We look forward to your submissions and to working together to build the next generation of conferences!</p>]]></content><author><name>Haiyue Song</name></author><summary type="html"><![CDATA[As we prepare for EMNLP 2025, many of you may have noticed that we are introducing several new tracks and making adjustments to our area list. You might also notice that there are some differences between the EMNLP tracks and those currently reflected in the ACL Rolling Review (ARR) system. Note that the EMNLP tracks will apply only at the commitment stage, i.e. after the ARR reviewing cycle is finished. At initial submission time you will need to choose among the ARR tracks. To help with this transition, the ARR area keywords have been updated to better align with the new EMNLP tracks. You can search for your preferred sub-areas and their associated ARR track here: https://aclrollingreview.org/areas. We wanted to take a moment to explain the motivations behind these decisions and how they fit into the broader picture of our field’s evolution.]]></summary></entry><entry><title type="html">Criteria for Determining Irresponsible Reviewers</title><link href="http://0.0.0.0:4000/reviewer-policies/" rel="alternate" type="text/html" title="Criteria for Determining Irresponsible Reviewers" /><published>2025-05-06T00:00:00-05:00</published><updated>2025-05-06T00:00:00-05:00</updated><id>http://0.0.0.0:4000/reviewer-policies</id><content type="html" xml:base="http://0.0.0.0:4000/reviewer-policies/"><![CDATA[<p>This post accompanies the ARR post <a href="https://aclrollingreview.org/incentives2025">Changes to reviewer volunteering requirement and incentives</a>, and defines the specific criteria for what we will deem as “Highly Irresponsible” reviewers. While the focus here is <em>reviewers</em>, we will use similar criteria for determining irresponsible <em>Area chairs (ACs)</em>.</p>

<h3 id="1-non-submitted-reviews">1. Non-submitted reviews</h3>

<p>If a reviewer fails to submit their reviews by the official deadline and has not submitted a <a href="https://aclrollingreview.org/reviewerguidelines#q-what-should-i-do-if-i-cannot-complete-my-assignment-due-to-a-personal-emergency">personal emergency declaration</a> (<strong>note</strong>: declaring a personal emergency after the review deadline will not be considered) will automatically be flagged as “Highly Irresponsible”.</p>

<h3 id="2-extremely-terse-or-unprofessional-reviews">2. Extremely terse or unprofessional reviews</h3>

<p>Where the submissions are good-faith work that merits a serious review (otherwise a short review can suffice, assuming it clearly explains the fundamental problems with that work), reviews that only contain a single argument (1-2 sentences) and no constructive feedback should be flagged. We may also penalize reviews that are extremely unprofessional in tone (e.g., rude, racist, sexist, ableist, etc. content; I4 in the list of <a href="https://aclrollingreview.org/authors#step2.2">12 commonly reported issues</a>), even if they are otherwise detailed.</p>

<p>Here are some guidelines for determining whether to consider a submission to be in good faith: At minimum, a good faith article states the contribution up front and provides an evaluation that supports that. If the writing is so poor that the intended contribution can’t be identified or the article is missing an evaluation positioned as supporting that, then the article does not warrant a serious review. If the issue is just that the stated contribution is not clear, or the evaluation is not sufficient or rigorous enough, that does warrant a serious review. Furthermore, if the paper shows a naivete about the state of the art, the paper still warrants a serious review, but if the paper shows a complete lack of awareness of work in the field (for example, if virtually all of the citations are from another field), then the paper is not a good faith submission. Even interdisciplinary papers should show an awareness of the audience they are submitting their work to.</p>

<h3 id="3-llm-generated-reviews">3. LLM-generated reviews</h3>

<p>As per the <a href="https://www.aclweb.org/adminwiki/index.php/ACL_Policy_on_Publication_Ethics#Guidelines_for_Generative_Assistance_in_Peer_Review">ACL Policy on Publication Ethics</a>, it is acceptable to use LLMs for paraphrasing, grammatical checks and proof-reading, but not for the content of the (meta-)reviews. Furthermore, the content of both the submission and (meta-)review is confidential. Therefore, even for acceptable purposes such as proofreading, it <strong>must not</strong> be passed on to non-privacy-preserving third parties, such as commercial LLM services, which may store it.</p>

<p>Authors will be able to flag such cases and present any evidence they have to support their allegation. While there is no definitive way of determining whether a review was (entirely) generated by an LLM, the Program Chairs will review the evidence and only proceed in cases where there is no reasonable doubt.</p>

<h2 id="flagging-review-process">Flagging review process</h2>

<p>The process is specified in the <a href="https://aclrollingreview.org/incentives2025">ARR post</a>. Ultimately, all decisions will be made by the Program Chairs after a careful review of all evidence. Reviewers/ACs will be able to appeal to the publication ethics committee<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> if they want to dispute the Program Chairs decisions.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p><a href="https://www.aclweb.org/adminwiki/index.php/Process_for_ACL_Publication_Ethics_Review">https://www.aclweb.org/adminwiki/index.php/Process_for_ACL_Publication_Ethics_Review</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Haiyue Song</name></author><summary type="html"><![CDATA[This post accompanies the ARR post Changes to reviewer volunteering requirement and incentives, and defines the specific criteria for what we will deem as “Highly Irresponsible” reviewers. While the focus here is reviewers, we will use similar criteria for determining irresponsible Area chairs (ACs).]]></summary></entry></feed>